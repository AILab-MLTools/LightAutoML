{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47595/3481341590.py:1: DtypeWarning: Columns (329,331,333,336,338,344,345,346,348,354,355,356,357,358,361,362,364,367,372,377,380,383,385,387,390,392,399,400,406,408,409,413,416,418,419,431,433,437,438,442,448,449,450,453,457,464,473,478,479,481,483,485,486,489,492,495,496,497,498,499,500,503,507,508,510,511,514,515,517,519,520,521,522,523,524,526,527,530,534,537,538,539,541,544,547,548,549,550,551,557,558,560,564,569,572,573,576,577,579,583,596,597,598,600,601,602,604,605,606,608,609,613,619,620,625,627,628,629,631,632,633,636,641,642,643,645,646,647,648,651,655,661,662,665,668,675,676,679,682,685,687,689,690,691,694,698,701,702,703,706,711,712,713,719,720,721,733,735,737,738,742,746,747,748,749,752,754,755,760,764,768,770,781,782,789,797,807,812,814,817,818,822,823,824,825,832,840,843,844,845,850,853,857,858,861,867,868,873,874,876,877,879,880,881,883,886,890,893,897,899,900,901,902,904,905,908,909,910,912,913,914,915,916,922,923,931,933,935,937,939,942,943,946,951,955,960,964,965,968,969,970,973,974,977,980,987,994,995,996,999,1000,1008,1014,1015,1016,1017,1020,1021,1023,1028,1031,1035,1036,1037,1039,1040,1043,1048,1051,1055,1058,1059,1072,1073,1074,1081,1090,1097,1098,1103,1104,1109,1112,1113,1114,1118,1120,1130,1134,1135,1139,1140,1147,1148,1149,1152,1154,1157,1158,1162,1163,1164,1166,1169,1174,1177,1180,1181,1182,1183,1185,1188,1189,1195,1197,1198,1200,1203,1208,1210,1212,1215,1217,1220,1222,1225,1229,1230,1233,1234,1241,1243,1246,1250,1251,1252,1254,1259,1262,1263,1265,1266,1269,1270,1273,1274,1276,1277,1279,1280,1282,1284,1285,1286,1289,1291,1292,1293,1294,1295,1301,1302,1304,1305,1306,1308,1309,1311,1313,1316,1318,1320,1322,1323,1325,1330,1335,1337,1340,1341,1343,1345,1350,1351,1352,1354,1357,1358,1359,1360,1361,1368,1369,1372,1377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features = pd.read_csv('../data/multilabel/train Data.csv')\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('../data/multilabel/train Data.csv')\n",
    "labels = pd.read_csv('../data/multilabel/train labels.csv')\n",
    "labels.drop(columns='id', inplace=True)\n",
    "data = pd.concat([features, labels], axis=1)\n",
    "data = data[['n_0000','n_0001','n_0002','n_0003',\n",
    "             'n_0004','n_0005','n_0006','n_0007',\n",
    "             'service_a', 'service_b', 'service_c', \n",
    "             'service_d', 'service_e', 'service_f',\n",
    "             'service_g', 'service_h', 'service_i',\n",
    "             'service_j', 'service_k', 'service_l',\n",
    "             'service_m', 'service_n']]\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'service_a', 'service_b', 'service_c',\n",
    "               'service_d', 'service_e', 'service_f',\n",
    "               'service_g', 'service_h', 'service_i',\n",
    "               'service_j', 'service_k', 'service_l',\n",
    "               'service_m', 'service_n'},\n",
    "    \"drop\" : ['id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "\n",
    "from lightautoml.automl.presets.gpu.tabular_gpu_presets import TabularAutoML_gpu, TabularUtilizedAutoML_gpu\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "from lightautoml.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeatures_gpu, LGBAdvancedPipeline_gpu\n",
    "from lightautoml.pipelines.features.gpu.linear_pipeline_gpu import LinearFeatures_gpu\n",
    "\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml.ml_algo.gpu.boost_cb_gpu import BoostCB_gpu\n",
    "from lightautoml.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "#from lightautoml.ml_algo.gpu.boost_xgb_gpu import BoostXGB_dask\n",
    "from lightautoml.ml_algo.gpu.linear_gpu import LinearLBFGS_gpu\n",
    "#from lightautoml.ml_algo.gpu.linear_gpu import LinearL1CD_gpu\n",
    "#from lightautoml.ml_algo.gpu.linear_gpu import LinearL1CD_mgpu\n",
    "\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "#from lightautoml.ml_algo.boost_lgbm import BoostLGBM\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearL1CD\n",
    "\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:13] Stdout logging level is INFO2.\n",
      "[00:45:13] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[00:45:13] Task: multilabel\n",
      "\n",
      "[00:45:13] Start automl preset with listed constraints:\n",
      "[00:45:13] - time: 3600.00 seconds\n",
      "[00:45:13] - CPU: 4 cores\n",
      "[00:45:13] - memory: 16 GB\n",
      "\n",
      "[00:45:13] \u001b[1mTrain data shape: (14644, 22)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feats was rejected during automatic roles guess: []\n",
      "[00:45:17] Layer \u001b[1m1\u001b[0m train process start. Time left 3595.81 secs\n",
      "[00:45:18] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[00:45:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:20] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[00:45:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[00:45:25] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-7.350126454317156\u001b[0m\n",
      "[00:45:25] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[00:45:25] Time left 3587.94 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:34] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[00:45:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[00:45:34] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:42] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:49] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-7.319639588152897\u001b[0m\n",
      "[00:45:57] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[00:45:57] Time left 3556.55 secs\n",
      "\n",
      "[00:45:57] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[00:45:57] Blending: optimization starts with equal weights and score \u001b[1m-7.314001499011002\u001b[0m\n",
      "[00:45:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-7.313942541306997\u001b[0m, weights = \u001b[1m[0.54370874 0.45629123]\u001b[0m\n",
      "[00:45:57] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-7.313942541306997\u001b[0m, weights = \u001b[1m[0.54370874 0.45629123]\u001b[0m\n",
      "[00:45:57] Blending: no score update. Terminated\n",
      "\n",
      "[00:45:57] \u001b[1mAutoml preset training completed in 43.85 seconds\u001b[0m\n",
      "\n",
      "[00:45:57] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.54371 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.45629 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoML_gpu(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:59] Stdout logging level is INFO2.\n",
      "[00:45:59] Task: multilabel\n",
      "\n",
      "[00:45:59] Start automl preset with listed constraints:\n",
      "[00:45:59] - time: 3600.00 seconds\n",
      "[00:45:59] - CPU: 1 cores\n",
      "[00:45:59] - memory: 16 GB\n",
      "\n",
      "[00:45:59] Train data shape: (14644, 22)\n",
      "[00:46:01] Feats was rejected during automatic roles guess: []\n",
      "[00:46:01] Layer \u001b[1m1\u001b[0m train process start. Time left 3597.70 secs\n",
      "[00:46:01] Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "[00:46:01] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "3.1099989428184927e-06 getting data\n",
      "1.0070771559985587 transfering model\n",
      "[00:46:04] Linear model: C = 1e-05 score = -7.597471214498179\n",
      "[00:46:04] Linear model: C = 5e-05 score = -7.577931617601442\n",
      "[00:46:05] Linear model: C = 0.0001 score = -7.56158490673727\n",
      "[00:46:05] Linear model: C = 0.0005 score = -7.507866641797281\n",
      "[00:46:05] Linear model: C = 0.001 score = -7.484747159632441\n",
      "[00:46:06] Linear model: C = 0.005 score = -7.434628401121024\n",
      "[00:46:06] Linear model: C = 0.01 score = -7.434627236413057\n",
      "[00:46:07] Linear model: C = 0.05 score = -7.409680975308823\n",
      "[00:46:07] Linear model: C = 0.1 score = -7.409680975308823\n",
      "[00:46:07] Linear model: C = 0.5 score = -7.409680975308823\n",
      "4.4320626170010655 fit data\n",
      "0.0010788180006784387 predict data\n",
      "[00:46:07] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "6.941998435650021e-06 getting data\n",
      "0.0008471949986414984 transfering model\n",
      "[00:46:08] Linear model: C = 1e-05 score = -7.47811715626321\n",
      "[00:46:08] Linear model: C = 5e-05 score = -7.458469003982364\n",
      "[00:46:08] Linear model: C = 0.0001 score = -7.441819696415646\n",
      "[00:46:09] Linear model: C = 0.0005 score = -7.388757782987678\n",
      "[00:46:09] Linear model: C = 0.001 score = -7.365624480927926\n",
      "[00:46:09] Linear model: C = 0.005 score = -7.317331709741594\n",
      "[00:46:10] Linear model: C = 0.01 score = -7.317330435171794\n",
      "[00:46:10] Linear model: C = 0.05 score = -7.291625388123856\n",
      "[00:46:10] Linear model: C = 0.1 score = -7.291625388123856\n",
      "[00:46:10] Linear model: C = 0.5 score = -7.291625388123856\n",
      "3.3980759320038487 fit data\n",
      "0.0010691129937185906 predict data\n",
      "[00:46:10] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "3.6030032788403332e-06 getting data\n",
      "0.0005765129972132854 transfering model\n",
      "[00:46:11] Linear model: C = 1e-05 score = -7.512965864833323\n",
      "[00:46:11] Linear model: C = 5e-05 score = -7.495558697873025\n",
      "[00:46:12] Linear model: C = 0.0001 score = -7.484495111516547\n",
      "[00:46:12] Linear model: C = 0.0005 score = -7.463682518967063\n",
      "[00:46:13] Linear model: C = 0.001 score = -7.457166151887562\n",
      "[00:46:13] Linear model: C = 0.005 score = -7.436322788843193\n",
      "[00:46:14] Linear model: C = 0.01 score = -7.431561482609649\n",
      "[00:46:15] Linear model: C = 0.05 score = -7.425667691486606\n",
      "[00:46:15] Linear model: C = 0.1 score = -7.425667691486606\n",
      "[00:46:16] Linear model: C = 0.5 score = -7.4249638242449\n",
      "[00:46:16] Linear model: C = 1 score = -7.4249638242449\n",
      "[00:46:16] Linear model: C = 5 score = -7.4249628593786845\n",
      "[00:46:16] Linear model: C = 10 score = -7.424963541870795\n",
      "[00:46:16] Linear model: C = 50 score = -7.424965310502165\n",
      "5.796627048999653 fit data\n",
      "0.0010543099997448735 predict data\n",
      "[00:46:16] Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "[00:46:16] Time left 3582.97 secs\n",
      "\n",
      "[00:46:16] Start fitting Selector_XGB ...\n",
      "[00:46:16] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mSelector_XGB\u001b[0m (orig) =====\n",
      "20.68231985300372 xgb single fold time\n",
      "[00:46:37] Selector_XGB fitting and predicting completed\n",
      "[00:46:37] Start fitting Lvl_0_Pipe_1_Mod_0_XGB ...\n",
      "[00:46:37] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "24.5068028819951 xgb single fold time\n",
      "[00:47:01] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "24.405400955001824 xgb single fold time\n",
      "[00:47:26] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "24.29111918599665 xgb single fold time\n",
      "[00:47:50] Lvl_0_Pipe_1_Mod_0_XGB fitting and predicting completed\n",
      "[00:47:50] Time left 3488.96 secs\n",
      "\n",
      "[00:47:50] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[00:47:50] Blending: Optimization starts with equal weights and score -7.367915501232455\n",
      "[00:47:50] Blending, iter 0: score = -7.330667464700073, weights = [0.90282214 0.09717787]\n",
      "[00:47:50] Blending, iter 1: score = -7.330667464700073, weights = [0.90282214 0.09717787]\n",
      "[00:47:50] No score update. Terminated\n",
      "[00:47:50] \u001b[1mAutoml preset training completed in 111.26 seconds\u001b[0m\n",
      "\n",
      "[00:47:50] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.90282 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09718 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70394263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 47595. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-11-09 00:47:52,673 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-11-09 00:47:52,673 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:45599': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "CatBoost uses as obj. MultiCrossEntropy.\n",
      "[00:47:53] Stdout logging level is INFO2.\n",
      "[00:47:53] Task: multilabel\n",
      "\n",
      "[00:47:53] Start automl preset with listed constraints:\n",
      "[00:47:53] - time: 3600.00 seconds\n",
      "[00:47:53] - CPU: 1 cores\n",
      "[00:47:53] - memory: 16 GB\n",
      "\n",
      "[00:47:53] Train data shape: (14644, 22)\n",
      "[00:47:55] Feats was rejected during automatic roles guess: []\n",
      "[00:47:55] Layer \u001b[1m1\u001b[0m train process start. Time left 3597.73 secs\n",
      "[00:47:55] Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "[00:47:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "3.0759983928874135e-06 getting data\n",
      "0.0008817380003165454 transfering model\n",
      "Score: -7.597470760345459\n",
      "Score: -7.5779314041137695\n",
      "Score: -7.561585426330566\n",
      "Score: -7.507866859436035\n",
      "Score: -7.484776496887207\n",
      "Score: -7.434499263763428\n",
      "Score: -7.434499263763428\n",
      "Score: -7.4097137451171875\n",
      "Score: -7.4097137451171875\n",
      "Score: -7.4097137451171875\n",
      "3.7005546700020204 fit data\n",
      "0.0007950609942781739 predict data\n",
      "[00:47:59] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "4.67000063508749e-06 getting data\n",
      "0.0008336619939655066 transfering model\n",
      "Score: -7.478116512298584\n",
      "Score: -7.458469390869141\n",
      "Score: -7.44182014465332\n",
      "Score: -7.388891696929932\n",
      "Score: -7.365650177001953\n",
      "Score: -7.316925525665283\n",
      "Score: -7.316925525665283\n",
      "Score: -7.2916107177734375\n",
      "Score: -7.2916107177734375\n",
      "Score: -7.2916107177734375\n",
      "3.418586984000285 fit data\n",
      "0.0008292919956147671 predict data\n",
      "[00:48:02] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "5.253998097032309e-06 getting data\n",
      "0.0008099359984043986 transfering model\n",
      "Score: -7.512965679168701\n",
      "Score: -7.495558261871338\n",
      "Score: -7.484495162963867\n",
      "Score: -7.463695526123047\n",
      "Score: -7.457135200500488\n",
      "Score: -7.436175346374512\n",
      "Score: -7.431407451629639\n",
      "Score: -7.426091194152832\n",
      "Score: -7.42609167098999\n",
      "Score: -7.424917697906494\n",
      "Score: -7.424917697906494\n",
      "Score: -7.424916744232178\n",
      "Score: -7.424916744232178\n",
      "Score: -7.4249186515808105\n",
      "5.504032217999338 fit data\n",
      "0.0009427249970030971 predict data\n",
      "[00:48:08] Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "[00:48:08] Time left 3585.03 secs\n",
      "\n",
      "[00:48:08] Start fitting Selector_XGB ...\n",
      "[00:48:08] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mSelector_XGB\u001b[0m (orig) =====\n",
      "20.84612677399855 xgb single fold time\n",
      "[00:48:29] Selector_XGB fitting and predicting completed\n",
      "[00:48:29] Start fitting Lvl_0_Pipe_1_Mod_0_XGB ...\n",
      "[00:48:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[00:48:32] task [xgboost.dask-0]:ucx://127.0.0.1:45599 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:58] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[00:48:58] task [xgboost.dask-0]:ucx://127.0.0.1:45599 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:23] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[00:49:23] task [xgboost.dask-0]:ucx://127.0.0.1:45599 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:49] Lvl_0_Pipe_1_Mod_0_XGB fitting and predicting completed\n",
      "[00:49:49] Time left 3484.04 secs\n",
      "\n",
      "[00:49:49] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[00:49:49] Blending: Optimization starts with equal weights and score -7.369941477394924\n",
      "[00:49:49] Blending, iter 0: score = -7.331666605422419, weights = [0.90983003 0.09016994]\n",
      "[00:49:49] Blending, iter 1: score = -7.331666605422419, weights = [0.90983003 0.09016994]\n",
      "[00:49:49] No score update. Terminated\n",
      "[00:49:49] \u001b[1mAutoml preset training completed in 116.16 seconds\u001b[0m\n",
      "\n",
      "[00:49:49] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.90983 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09017 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoML_gpu(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

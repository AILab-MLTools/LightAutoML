{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21513/705777730.py:1: DtypeWarning: Columns (329,331,333,336,338,344,345,346,348,354,355,356,357,358,361,362,364,367,372,377,380,383,385,387,390,392,399,400,406,408,409,413,416,418,419,431,433,437,438,442,448,449,450,453,457,464,473,478,479,481,483,485,486,489,492,495,496,497,498,499,500,503,507,508,510,511,514,515,517,519,520,521,522,523,524,526,527,530,534,537,538,539,541,544,547,548,549,550,551,557,558,560,564,569,572,573,576,577,579,583,596,597,598,600,601,602,604,605,606,608,609,613,619,620,625,627,628,629,631,632,633,636,641,642,643,645,646,647,648,651,655,661,662,665,668,675,676,679,682,685,687,689,690,691,694,698,701,702,703,706,711,712,713,719,720,721,733,735,737,738,742,746,747,748,749,752,754,755,760,764,768,770,781,782,789,797,807,812,814,817,818,822,823,824,825,832,840,843,844,845,850,853,857,858,861,867,868,873,874,876,877,879,880,881,883,886,890,893,897,899,900,901,902,904,905,908,909,910,912,913,914,915,916,922,923,931,933,935,937,939,942,943,946,951,955,960,964,965,968,969,970,973,974,977,980,987,994,995,996,999,1000,1008,1014,1015,1016,1017,1020,1021,1023,1028,1031,1035,1036,1037,1039,1040,1043,1048,1051,1055,1058,1059,1072,1073,1074,1081,1090,1097,1098,1103,1104,1109,1112,1113,1114,1118,1120,1130,1134,1135,1139,1140,1147,1148,1149,1152,1154,1157,1158,1162,1163,1164,1166,1169,1174,1177,1180,1181,1182,1183,1185,1188,1189,1195,1197,1198,1200,1203,1208,1210,1212,1215,1217,1220,1222,1225,1229,1230,1233,1234,1241,1243,1246,1250,1251,1252,1254,1259,1262,1263,1265,1266,1269,1270,1273,1274,1276,1277,1279,1280,1282,1284,1285,1286,1289,1291,1292,1293,1294,1295,1301,1302,1304,1305,1306,1308,1309,1311,1313,1316,1318,1320,1322,1323,1325,1330,1335,1337,1340,1341,1343,1345,1350,1351,1352,1354,1357,1358,1359,1360,1361,1368,1369,1372,1377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n",
    "labels = pd.read_csv('../../data/small_new/multilabel/train labels.csv')\n",
    "labels.drop(columns='id', inplace=True)\n",
    "data = pd.concat([features, labels], axis=1)\n",
    "data = data[['n_0000','n_0001','n_0002','n_0003',\n",
    "             'n_0004','n_0005','n_0006','n_0007',\n",
    "             'service_a', 'service_b', 'service_c', \n",
    "             'service_d', 'service_e', 'service_f',\n",
    "             'service_g', 'service_h', 'service_i',\n",
    "             'service_j', 'service_k', 'service_l',\n",
    "             'service_m', 'service_n']]\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'service_a', 'service_b', 'service_c',\n",
    "               'service_d', 'service_e', 'service_f',\n",
    "               'service_g', 'service_h', 'service_i',\n",
    "               'service_j', 'service_k', 'service_l',\n",
    "               'service_m', 'service_n'},\n",
    "    \"drop\" : ['id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "\n",
    "from lightautoml.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "from lightautoml.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:43] Stdout logging level is INFO2.\n",
      "[15:33:43] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:33:43] Task: multilabel\n",
      "\n",
      "[15:33:43] Start automl preset with listed constraints:\n",
      "[15:33:43] - time: 3600.00 seconds\n",
      "[15:33:43] - CPU: 4 cores\n",
      "[15:33:43] - memory: 16 GB\n",
      "\n",
      "[15:33:43] \u001b[1mTrain data shape: (14644, 22)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:46] Feats was rejected during automatic roles guess: []\n",
      "[15:33:46] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.44 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:33:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:51] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-7.350364600194018\u001b[0m\n",
      "[15:33:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:33:53] Time left 3589.44 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:01] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:34:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[15:34:01] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:10] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:20] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-7.322678702153068\u001b[0m\n",
      "[15:34:30] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:34:30] Time left 3552.29 secs\n",
      "\n",
      "[15:34:30] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:34:30] Blending: optimization starts with equal weights and score \u001b[1m-7.316146249899412\u001b[0m\n",
      "[15:34:31] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-7.315961742736511\u001b[0m, weights = \u001b[1m[0.5746675 0.4253325]\u001b[0m\n",
      "[15:34:31] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-7.315961742736511\u001b[0m, weights = \u001b[1m[0.5746675 0.4253325]\u001b[0m\n",
      "[15:34:31] Blending: no score update. Terminated\n",
      "\n",
      "[15:34:31] \u001b[1mAutoml preset training completed in 48.12 seconds\u001b[0m\n",
      "\n",
      "[15:34:31] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.57467 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.42533 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[15:34:33] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'pb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:33] Stdout logging level is INFO2.\n",
      "[15:34:33] Task: multilabel\n",
      "\n",
      "[15:34:33] Start automl preset with listed constraints:\n",
      "[15:34:33] - time: 3600.00 seconds\n",
      "[15:34:33] - CPU: 1 cores\n",
      "[15:34:33] - memory: 16 GB\n",
      "\n",
      "[15:34:33] Train data shape: (14644, 22)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[15:34:34] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.30 secs\n",
      "[15:34:35] Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "[15:34:35] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[15:34:39] Linear model: C = 1e-05 score = -7.597461111034735\n",
      "[15:34:39] Linear model: C = 5e-05 score = -7.577959523074991\n",
      "[15:34:39] Linear model: C = 0.0001 score = -7.561262455376285\n",
      "[15:34:40] Linear model: C = 0.0005 score = -7.507907961783278\n",
      "[15:34:40] Linear model: C = 0.001 score = -7.48459065165592\n",
      "[15:34:41] Linear model: C = 0.005 score = -7.434500157601128\n",
      "[15:34:41] Linear model: C = 0.01 score = -7.434500157601128\n",
      "[15:34:41] Linear model: C = 0.05 score = -7.409913456449739\n",
      "[15:34:41] Linear model: C = 0.1 score = -7.409913456449739\n",
      "[15:34:42] Linear model: C = 0.5 score = -7.409913456449739\n",
      "[15:34:42] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[15:34:43] Linear model: C = 1e-05 score = -7.478099591369097\n",
      "[15:34:43] Linear model: C = 5e-05 score = -7.458440090051271\n",
      "[15:34:43] Linear model: C = 0.0001 score = -7.44199347264013\n",
      "[15:34:44] Linear model: C = 0.0005 score = -7.388836991259417\n",
      "[15:34:44] Linear model: C = 0.001 score = -7.365666374738185\n",
      "[15:34:45] Linear model: C = 0.005 score = -7.31718860969903\n",
      "[15:34:45] Linear model: C = 0.01 score = -7.31718860969903\n",
      "[15:34:46] Linear model: C = 0.05 score = -7.291663084465371\n",
      "[15:34:46] Linear model: C = 0.1 score = -7.291663084465371\n",
      "[15:34:46] Linear model: C = 0.5 score = -7.291663084465371\n",
      "[15:34:46] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[15:34:47] Linear model: C = 1e-05 score = -7.512927937229206\n",
      "[15:34:48] Linear model: C = 5e-05 score = -7.495558559857927\n",
      "[15:34:48] Linear model: C = 0.0001 score = -7.484427592715775\n",
      "[15:34:48] Linear model: C = 0.0005 score = -7.463707694987969\n",
      "[15:34:49] Linear model: C = 0.001 score = -7.457068242630666\n",
      "[15:34:50] Linear model: C = 0.005 score = -7.436229642774452\n",
      "[15:34:50] Linear model: C = 0.01 score = -7.431183782576159\n",
      "[15:34:51] Linear model: C = 0.05 score = -7.426157924803987\n",
      "[15:34:52] Linear model: C = 0.1 score = -7.425357852588299\n",
      "[15:34:53] Linear model: C = 0.5 score = -7.425959426289185\n",
      "[15:34:53] Linear model: C = 1 score = -7.425959426289185\n",
      "[15:34:53] Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "[15:34:54] Time left 3579.18 secs\n",
      "\n",
      "[15:34:54] Start fitting Selector_XGB ...\n",
      "[15:34:54] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mSelector_XGB\u001b[0m (orig) =====\n",
      "[15:35:17] Selector_XGB fitting and predicting completed\n",
      "[15:35:17] Start fitting Lvl_0_Pipe_1_Mod_0_PB ...\n",
      "[15:35:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[15:35:19] Stdout logging level is INFO.\n",
      "[15:35:19] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[15:35:19] Iter 0; Sample 0, BCE = 0.3791767522991384; \n",
      "[15:35:20] Iter 99; Sample 0, BCE = 0.35317920625777316; \n",
      "[15:35:20] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[15:35:20] Stdout logging level is INFO.\n",
      "[15:35:20] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[15:35:20] Iter 0; Sample 0, BCE = 0.3718852195360335; \n",
      "[15:35:21] Iter 99; Sample 0, BCE = 0.34552351282223837; \n",
      "[15:35:21] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[15:35:21] Stdout logging level is INFO.\n",
      "[15:35:21] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[15:35:21] Iter 0; Sample 0, BCE = 0.3754651329420038; \n",
      "[15:35:22] Iter 99; Sample 0, BCE = 0.34924692545313635; \n",
      "[15:35:22] Lvl_0_Pipe_1_Mod_0_PB fitting and predicting completed\n",
      "[15:35:22] Time left 3550.67 secs\n",
      "\n",
      "[15:35:22] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:35:22] Blending: Optimization starts with equal weights and score -7.315835464980816\n",
      "[15:35:22] Blending, iter 0: score = -7.315728552572326, weights = [0.56589407 0.43410593]\n",
      "[15:35:22] Blending, iter 1: score = -7.315728552572326, weights = [0.56589407 0.43410593]\n",
      "[15:35:22] No score update. Terminated\n",
      "[15:35:22] \u001b[1mAutoml preset training completed in 49.59 seconds\u001b[0m\n",
      "\n",
      "[15:35:22] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.56589 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.43411 * (3 averaged models Lvl_0_Pipe_1_Mod_0_PB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad158c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7748506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularAutoMLGPU\n",
      "{'_binary': False, 'data_size': 15, 'categorical_idx': {'int': [12, 13, 14], 'str': ['le__n_0000', 'le__n_0003', 'inter__(n_0000__n_0003)']}, 'embed_sizes': array([ 2, 12, 12], dtype=int32), 'output_size': 14, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'max_iter': 100, 'tol': 1e-06, 'early_stopping': 2, 'loss': TorchLossWrapper(\n",
      "  (base_loss): BCELoss()\n",
      "), 'metric': <lightautoml.tasks.losses.base.MetricFunc object at 0x7f62a113f670>, 'model': CatMulticlass(\n",
      "  (linear): Linear(in_features=12, out_features=14, bias=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")}\n",
      "TorchBasedLogisticRegression\n",
      "{'_name': 'multilabel', 'device': 'gpu', 'losses': {'lgb': <lightautoml.tasks.losses.lgb.LGBLoss object at 0x7f62a0e673a0>, 'sklearn': <lightautoml.tasks.losses.sklearn.SKLoss object at 0x7f62a0e67190>, 'torch': <lightautoml.tasks.losses.torch.TORCHLoss object at 0x7f62a113f040>, 'cb': <lightautoml.tasks.losses.cb.CBLoss object at 0x7f62a113fe80>, 'torch_gpu': <lightautoml.tasks.losses.gpu.torch_gpu.TORCHLossGPU object at 0x7f62a113ffa0>, 'cuml': <lightautoml.tasks.losses.gpu.cuml.CUMLLoss object at 0x7f62a113f850>, 'xgb': <lightautoml.tasks.losses.gpu.xgb_gpu.XGBLoss object at 0x7f62a113fbe0>, 'pb': <lightautoml.tasks.losses.gpu.pb_gpu.PBLoss object at 0x7f62a113f160>}, 'metric_params': {}, 'metric_func': functools.partial(<function log_loss_gpu at 0x7f6322deadc0>, eps=1e-07), 'metric_name': 'logloss', 'greater_is_better': False}\n",
      "multilabel isn`t supported in lgb\n",
      "[15:35:22] CatBoost uses as obj. MultiCrossEntropy.\n",
      "cpu\n",
      "PB: {'task': <lightautoml.tasks.base.Task object at 0x7f62a0e675b0>, 'optimization_search_space': {}, 'freeze_defaults': False, 'default_params': {'ntrees': 100, 'lr': 0.05, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 100, 'seed': 42, 'verbose': 10}, 'models': [<py_boost.gpu.boosting.GradientBoosting object at 0x7f62a05b0910>, <py_boost.gpu.boosting.GradientBoosting object at 0x7f62a0285760>, <py_boost.gpu.boosting.GradientBoosting object at 0x7f647d021220>], '_features': ['inter__(n_0000__n_0003)', 'n_0001', 'n_0002', 'n_0004', 'n_0005', 'n_0006', 'n_0007', 'ord__n_0000', 'ord__n_0003'], 'timer': <lightautoml.utils.timer.TaskTimer object at 0x7f62a1112190>, '_nan_rate': None, 'gpu_ids': None, 'parallel_folds': False, '_name': 'Lvl_0_Pipe_1_Mod_0_PB', '_params': {'ntrees': 3000, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 200, 'seed': 42, 'verbose': 10}, 'n_classes': 14}\n",
      "PB model type: GradientBoosting\n",
      "PB model: {'models': [<py_boost.gpu.tree.Tree object at 0x7f62a65300d0>, <py_boost.gpu.tree.Tree object at 0x7f62a01d4040>, <py_boost.gpu.tree.Tree object at 0x7f647d18ecd0>, <py_boost.gpu.tree.Tree object at 0x7f647d18e550>, <py_boost.gpu.tree.Tree object at 0x7f647d18ed90>, <py_boost.gpu.tree.Tree object at 0x7f647d18ee80>, <py_boost.gpu.tree.Tree object at 0x7f647d18efd0>, <py_boost.gpu.tree.Tree object at 0x7f647d18ef70>, <py_boost.gpu.tree.Tree object at 0x7f647d18ec40>, <py_boost.gpu.tree.Tree object at 0x7f647d18e490>, <py_boost.gpu.tree.Tree object at 0x7f647d18e5e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0670>, <py_boost.gpu.tree.Tree object at 0x7f647d33f3a0>, <py_boost.gpu.tree.Tree object at 0x7f647d266df0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0310>, <py_boost.gpu.tree.Tree object at 0x7f647d1a06d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0820>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0640>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0370>, <py_boost.gpu.tree.Tree object at 0x7f62a0285370>, <py_boost.gpu.tree.Tree object at 0x7f62a02853d0>, <py_boost.gpu.tree.Tree object at 0x7f62a0285d00>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1a00>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1f40>, <py_boost.gpu.tree.Tree object at 0x7f62a01f17f0>, <py_boost.gpu.tree.Tree object at 0x7f62a01f17c0>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1e20>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1f70>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1700>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1b80>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcbb0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcac0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc8e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcb80>, <py_boost.gpu.tree.Tree object at 0x7f647d1bca90>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc850>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcc10>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcf40>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcf10>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcca0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcee0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc910>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc790>, <py_boost.gpu.tree.Tree object at 0x7f647d1bceb0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc2e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc9d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcfd0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc0d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc4f0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc580>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc1c0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc340>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcd30>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc280>, <py_boost.gpu.tree.Tree object at 0x7f647d17a0a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc9a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc2b0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc6a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcd60>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc940>, <py_boost.gpu.tree.Tree object at 0x7f647d17cb80>, <py_boost.gpu.tree.Tree object at 0x7f647d17cee0>, <py_boost.gpu.tree.Tree object at 0x7f647d17cf10>, <py_boost.gpu.tree.Tree object at 0x7f647d17cf70>, <py_boost.gpu.tree.Tree object at 0x7f647d17c850>, <py_boost.gpu.tree.Tree object at 0x7f647d17c8e0>, <py_boost.gpu.tree.Tree object at 0x7f647d17cbe0>, <py_boost.gpu.tree.Tree object at 0x7f647d175790>, <py_boost.gpu.tree.Tree object at 0x7f647d175700>, <py_boost.gpu.tree.Tree object at 0x7f647d173e50>, <py_boost.gpu.tree.Tree object at 0x7f647d173340>, <py_boost.gpu.tree.Tree object at 0x7f647d173ee0>, <py_boost.gpu.tree.Tree object at 0x7f62a05aff10>, <py_boost.gpu.tree.Tree object at 0x7f62a05aff40>, <py_boost.gpu.tree.Tree object at 0x7f62a05b2970>, <py_boost.gpu.tree.Tree object at 0x7f62a05b26d0>, <py_boost.gpu.tree.Tree object at 0x7f647d173df0>, <py_boost.gpu.tree.Tree object at 0x7f647d173670>, <py_boost.gpu.tree.Tree object at 0x7f647d173370>, <py_boost.gpu.tree.Tree object at 0x7f647d170a30>, <py_boost.gpu.tree.Tree object at 0x7f647d170ac0>, <py_boost.gpu.tree.Tree object at 0x7f647d170370>, <py_boost.gpu.tree.Tree object at 0x7f647d1709a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1701c0>, <py_boost.gpu.tree.Tree object at 0x7f647d1709d0>, <py_boost.gpu.tree.Tree object at 0x7f647d170250>, <py_boost.gpu.tree.Tree object at 0x7f647d170580>, <py_boost.gpu.tree.Tree object at 0x7f647d17e1c0>, <py_boost.gpu.tree.Tree object at 0x7f647d17ebe0>, <py_boost.gpu.tree.Tree object at 0x7f647d17eac0>, <py_boost.gpu.tree.Tree object at 0x7f647d17eb20>, <py_boost.gpu.tree.Tree object at 0x7f647d17e190>, <py_boost.gpu.tree.Tree object at 0x7f647d17e700>, <py_boost.gpu.tree.Tree object at 0x7f647d17e520>, <py_boost.gpu.tree.Tree object at 0x7f647d17e670>, <py_boost.gpu.tree.Tree object at 0x7f647d17e790>, <py_boost.gpu.tree.Tree object at 0x7f647d17e6a0>, <py_boost.gpu.tree.Tree object at 0x7f647d17e070>, <py_boost.gpu.tree.Tree object at 0x7f647d17e0d0>, <py_boost.gpu.tree.Tree object at 0x7f647d17e640>], 'nfeats': 9, 'postprocess_fn': <bound method BCELoss.postprocess_output of <py_boost.gpu.losses.losses.BCELoss object at 0x7f62a0a8cbe0>>, 'base_score': array([ 1.2744273 , -0.88346356, -4.1533837 , -2.9211771 , -0.7037684 ,\n",
      "       -2.1483364 , -2.8961174 , -3.5005257 , -4.194554  , -1.5248097 ,\n",
      "        1.7412851 , -1.0348811 , -0.10745831, -2.3499177 ], dtype=float32), '_on_device': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'params': {'loss': 'logloss', 'metric': None, 'ntrees': 100, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'multioutput_sketch': <py_boost.multioutput.sketching.RandomProjectionSketch object at 0x7f62a05b0640>, 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 100, 'seed': 42, 'verbose': 100, 'callbacks': None}, 'ntrees': 100, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'use_hess': True, 'colsample': <py_boost.sampling.bagging.BaseSampler object at 0x7f62a05b00d0>, 'subsample': <py_boost.sampling.bagging.BaseSampler object at 0x7f62a057a100>, 'target_splitter': <py_boost.multioutput.target_splitter.SingleSplitter object at 0x7f62a057a040>, 'multioutput_sketch': <py_boost.multioutput.sketching.RandomProjectionSketch object at 0x7f62a05b0640>, 'es': 100, 'verbose': 100, 'loss': <py_boost.gpu.losses.losses.BCELoss object at 0x7f62a0a8cbe0>, 'metric': <py_boost.gpu.losses.metrics.BCEMetric object at 0x7f62a0576df0>, 'seed': 42, 'history': [[0.3791767522991384], [0.3778416120752246], [0.3762674118738236], [0.37514040717926267], [0.37416972910751045], [0.37321100253399625], [0.37204776209683177], [0.37124094911654487], [0.37041730463987543], [0.36978657801783166], [0.36892871863965426], [0.3680218382829175], [0.36722533037437743], [0.36653690507570086], [0.3659066383129189], [0.3651784657803058], [0.3645622214007063], [0.36408055783859966], [0.36351199715648574], [0.36301823044411013], [0.36246650380450207], [0.36208665737738055], [0.36170642099751377], [0.36124463456873107], [0.36088624389267765], [0.3605031153441547], [0.36017062322123616], [0.3598390672032548], [0.35949904860956117], [0.35924612959789476], [0.3589941399965245], [0.3587827823000444], [0.35852464714127996], [0.35830522637873685], [0.358087019871591], [0.3578593743364027], [0.35762406422313664], [0.35745768869813327], [0.3573011911694761], [0.3570795397969606], [0.35695875008929473], [0.35678372184820356], [0.35656185976580806], [0.3563773658716894], [0.3562291636750396], [0.3560540624957311], [0.3559737730648791], [0.35580729604079725], [0.3556632508605666], [0.35558251276525693], [0.3554693948953833], [0.3553672590520818], [0.35527167498912726], [0.3551784769430135], [0.3550456225527433], [0.35496720828514433], [0.3548836755350177], [0.3547905032234891], [0.3547267937118343], [0.3546829252843606], [0.3546157485234878], [0.3545751889228638], [0.35445996529998314], [0.3543893989541639], [0.35434003067485736], [0.3542782006045622], [0.3542461649025937], [0.35420695658697765], [0.3541381623806585], [0.35408436256315684], [0.3540361107599926], [0.3539656358261486], [0.3539428939023407], [0.35389726906457364], [0.35388151780846705], [0.3538530697691564], [0.35383322607822826], [0.35380162338178434], [0.35377454748022386], [0.3537380815753694], [0.3536971916197887], [0.35364178332508683], [0.3536282761422021], [0.35359999721650864], [0.3535571494795898], [0.35352073745278095], [0.3534704647587743], [0.3534277953264103], [0.3534133832027478], [0.353377778464938], [0.35334014404965125], [0.35333011331372666], [0.35330182346342004], [0.3532637754343206], [0.35326911671001004], [0.35326739974841986], [0.3532416904374764], [0.3532250495275617], [0.3532018709334216], [0.35317920625777316]], 'callbacks': <py_boost.callbacks.callback.CallbackPipeline object at 0x7f62a05762b0>, 'best_round': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109bf25283a404fa5f861be42cf1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d05adae4414910a81142d53d7fd3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3243fcbb9c24b3ca0a0aa72c284479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[15:35:24] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "cpu_inf = automl.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70394263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 21513. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-11-30 15:35:26,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wf7z6oqf', purging\n",
      "2022-11-30 15:35:26,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-11-30 15:35:26,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:60617': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[15:35:27] CatBoost uses as obj. MultiCrossEntropy.\n",
      "[15:35:27] Stdout logging level is INFO2.\n",
      "[15:35:27] Task: multilabel\n",
      "\n",
      "[15:35:27] Start automl preset with listed constraints:\n",
      "[15:35:27] - time: 3600.00 seconds\n",
      "[15:35:27] - CPU: 1 cores\n",
      "[15:35:27] - memory: 16 GB\n",
      "\n",
      "[15:35:27] Train data shape: (14644, 22)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[15:35:29] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.23 secs\n",
      "[15:35:29] Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "[15:35:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.597461223602295\n",
      "Score: -7.577960014343262\n",
      "Score: -7.561263084411621\n",
      "Score: -7.507802963256836\n",
      "Score: -7.484713554382324\n",
      "Score: -7.434474468231201\n",
      "Score: -7.434474468231201\n",
      "Score: -7.409946441650391\n",
      "Score: -7.409946441650391\n",
      "Score: -7.409946441650391\n",
      "[15:35:33] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.4780988693237305\n",
      "Score: -7.458440780639648\n",
      "Score: -7.44199275970459\n",
      "Score: -7.3888373374938965\n",
      "Score: -7.365793228149414\n",
      "Score: -7.317152976989746\n",
      "Score: -7.317152976989746\n",
      "Score: -7.292194843292236\n",
      "Score: -7.292194843292236\n",
      "Score: -7.292194843292236\n",
      "[15:35:39] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.512928009033203\n",
      "Score: -7.495559215545654\n",
      "Score: -7.4844279289245605\n",
      "Score: -7.463672161102295\n",
      "Score: -7.457089900970459\n",
      "Score: -7.435981750488281\n",
      "Score: -7.431396007537842\n",
      "Score: -7.425570964813232\n",
      "Score: -7.425786972045898\n",
      "Score: -7.425788402557373\n",
      "[15:35:46] Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "[15:35:46] Time left 3581.28 secs\n",
      "\n",
      "[15:35:46] Start fitting Selector_XGB ...\n",
      "[15:35:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mSelector_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:35:50] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:15] Selector_XGB fitting and predicting completed\n",
      "[15:36:15] Start fitting Lvl_0_Pipe_1_Mod_0_XGB ...\n",
      "[15:36:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:36:16] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:36:43] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:37:11] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:39] Lvl_0_Pipe_1_Mod_0_XGB fitting and predicting completed\n",
      "[15:37:39] Time left 3467.91 secs\n",
      "\n",
      "[15:37:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:37:39] Blending: Optimization starts with equal weights and score -7.369040055931575\n",
      "[15:37:39] Blending, iter 0: score = -7.332288272275898, weights = [0.90295106 0.09704894]\n",
      "[15:37:39] Blending, iter 1: score = -7.332288272275898, weights = [0.90295106 0.09704894]\n",
      "[15:37:39] No score update. Terminated\n",
      "[15:37:39] \u001b[1mAutoml preset training completed in 132.30 seconds\u001b[0m\n",
      "\n",
      "[15:37:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.90295 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09705 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5572413  0.5140602  0.554345   ... 0.32615978 0.55932724 0.5283271 ]\n",
      " [0.10613684 0.15360174 0.10628839 ... 0.24034458 0.10660344 0.13533857]\n",
      " [0.01066768 0.01306654 0.01075604 ... 0.00172346 0.01067023 0.00936168]\n",
      " ...\n",
      " [0.0912509  0.11758646 0.09017038 ... 0.2209489  0.08924023 0.12009337]\n",
      " [0.18382518 0.22122423 0.17709294 ... 0.3786014  0.16766214 0.22966513]\n",
      " [0.02809653 0.04665985 0.02616439 ... 0.04066981 0.02415165 0.05030812]]\n",
      "\n",
      "[[0.56842893 0.5196632  0.5663695  ... 0.32545125 0.5775144  0.5322845 ]\n",
      " [0.10147692 0.16129875 0.10777053 ... 0.24136236 0.10288282 0.12789753]\n",
      " [0.01173552 0.01505887 0.01187614 ... 0.00313549 0.00997119 0.00903109]\n",
      " ...\n",
      " [0.09023867 0.1269161  0.08745717 ... 0.24356261 0.07901268 0.11170406]\n",
      " [0.18878452 0.23331442 0.17551136 ... 0.39841276 0.15086576 0.21826142]\n",
      " [0.0252515  0.05333086 0.02523747 ... 0.04038102 0.01980539 0.04349071]]\n",
      "\n",
      "[[0.5664643  0.5166605  0.5704907  ... 0.33915734 0.57409036 0.5306796 ]\n",
      " [0.09986173 0.16810127 0.10628133 ... 0.20926563 0.10062604 0.12780127]\n",
      " [0.01196821 0.01398394 0.01322161 ... 0.00280323 0.01032557 0.01050191]\n",
      " ...\n",
      " [0.09180846 0.13396505 0.09454171 ... 0.2606958  0.07511169 0.12074684]\n",
      " [0.18628407 0.22799858 0.17925116 ... 0.41266233 0.1433349  0.23176786]\n",
      " [0.02698906 0.04811605 0.02420964 ... 0.03835659 0.0200704  0.04737411]]\n",
      "\n",
      "[[0.5566101  0.5167476  0.5587     ... 0.3180616  0.55953795 0.52395034]\n",
      " [0.10735844 0.14981753 0.10365902 ... 0.24246103 0.10839043 0.13269033]\n",
      " [0.01044928 0.01220986 0.0094422  ... 0.00169395 0.01090351 0.01022525]\n",
      " ...\n",
      " [0.09026912 0.11811364 0.08929776 ... 0.20285338 0.087581   0.12475552]\n",
      " [0.18097366 0.2176568  0.17152062 ... 0.37750742 0.16242473 0.23077025]\n",
      " [0.02716871 0.0458691  0.02571099 ... 0.03726    0.021709   0.04831092]]\n",
      "\n",
      "[[0.38230485 0.33360735 0.37970474 ... 0.18429603 0.39537454 0.35456634]\n",
      " [0.06503995 0.09911688 0.07147714 ... 0.12759788 0.0726622  0.0630847 ]\n",
      " [0.00721015 0.00751541 0.00580979 ... 0.00213916 0.0090256  0.00684993]\n",
      " ...\n",
      " [0.05489378 0.07309221 0.06428277 ... 0.14156312 0.04322646 0.06683876]\n",
      " [0.1101869  0.13309942 0.10156783 ... 0.23032379 0.09343332 0.1422773 ]\n",
      " [0.01629821 0.0290544  0.0159301  ... 0.01993656 0.01690265 0.03529549]]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(oof_pred_mgpu.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

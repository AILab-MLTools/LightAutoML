{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18644/705777730.py:1: DtypeWarning: Columns (329,331,333,336,338,344,345,346,348,354,355,356,357,358,361,362,364,367,372,377,380,383,385,387,390,392,399,400,406,408,409,413,416,418,419,431,433,437,438,442,448,449,450,453,457,464,473,478,479,481,483,485,486,489,492,495,496,497,498,499,500,503,507,508,510,511,514,515,517,519,520,521,522,523,524,526,527,530,534,537,538,539,541,544,547,548,549,550,551,557,558,560,564,569,572,573,576,577,579,583,596,597,598,600,601,602,604,605,606,608,609,613,619,620,625,627,628,629,631,632,633,636,641,642,643,645,646,647,648,651,655,661,662,665,668,675,676,679,682,685,687,689,690,691,694,698,701,702,703,706,711,712,713,719,720,721,733,735,737,738,742,746,747,748,749,752,754,755,760,764,768,770,781,782,789,797,807,812,814,817,818,822,823,824,825,832,840,843,844,845,850,853,857,858,861,867,868,873,874,876,877,879,880,881,883,886,890,893,897,899,900,901,902,904,905,908,909,910,912,913,914,915,916,922,923,931,933,935,937,939,942,943,946,951,955,960,964,965,968,969,970,973,974,977,980,987,994,995,996,999,1000,1008,1014,1015,1016,1017,1020,1021,1023,1028,1031,1035,1036,1037,1039,1040,1043,1048,1051,1055,1058,1059,1072,1073,1074,1081,1090,1097,1098,1103,1104,1109,1112,1113,1114,1118,1120,1130,1134,1135,1139,1140,1147,1148,1149,1152,1154,1157,1158,1162,1163,1164,1166,1169,1174,1177,1180,1181,1182,1183,1185,1188,1189,1195,1197,1198,1200,1203,1208,1210,1212,1215,1217,1220,1222,1225,1229,1230,1233,1234,1241,1243,1246,1250,1251,1252,1254,1259,1262,1263,1265,1266,1269,1270,1273,1274,1276,1277,1279,1280,1282,1284,1285,1286,1289,1291,1292,1293,1294,1295,1301,1302,1304,1305,1306,1308,1309,1311,1313,1316,1318,1320,1322,1323,1325,1330,1335,1337,1340,1341,1343,1345,1350,1351,1352,1354,1357,1358,1359,1360,1361,1368,1369,1372,1377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n",
    "labels = pd.read_csv('../../data/small_new/multilabel/train labels.csv')\n",
    "labels.drop(columns='id', inplace=True)\n",
    "data = pd.concat([features, labels], axis=1)\n",
    "data = data[['n_0000','n_0001','n_0002','n_0003',\n",
    "             'n_0004','n_0005','n_0006','n_0007',\n",
    "             'service_a', 'service_b', 'service_c', \n",
    "             'service_d', 'service_e', 'service_f',\n",
    "             'service_g', 'service_h', 'service_i',\n",
    "             'service_j', 'service_k', 'service_l',\n",
    "             'service_m', 'service_n']]\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'service_a', 'service_b', 'service_c',\n",
    "               'service_d', 'service_e', 'service_f',\n",
    "               'service_g', 'service_h', 'service_i',\n",
    "               'service_j', 'service_k', 'service_l',\n",
    "               'service_m', 'service_n'},\n",
    "    \"drop\" : ['id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "\n",
    "from lightautoml.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "from lightautoml.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:43] Stdout logging level is INFO2.\n",
      "[15:33:43] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:33:43] Task: multilabel\n",
      "\n",
      "[15:33:43] Start automl preset with listed constraints:\n",
      "[15:33:43] - time: 3600.00 seconds\n",
      "[15:33:43] - CPU: 4 cores\n",
      "[15:33:43] - memory: 16 GB\n",
      "\n",
      "[15:33:43] \u001b[1mTrain data shape: (14644, 22)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:46] Feats was rejected during automatic roles guess: []\n",
      "[15:33:46] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.44 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:33:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:51] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[15:33:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-7.350364600194018\u001b[0m\n",
      "[15:33:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:33:53] Time left 3589.44 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:01] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:34:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[15:34:01] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:10] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:20] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-7.322678702153068\u001b[0m\n",
      "[15:34:30] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:34:30] Time left 3552.29 secs\n",
      "\n",
      "[15:34:30] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:34:30] Blending: optimization starts with equal weights and score \u001b[1m-7.316146249899412\u001b[0m\n",
      "[15:34:31] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-7.315961742736511\u001b[0m, weights = \u001b[1m[0.5746675 0.4253325]\u001b[0m\n",
      "[15:34:31] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-7.315961742736511\u001b[0m, weights = \u001b[1m[0.5746675 0.4253325]\u001b[0m\n",
      "[15:34:31] Blending: no score update. Terminated\n",
      "\n",
      "[15:34:31] \u001b[1mAutoml preset training completed in 48.12 seconds\u001b[0m\n",
      "\n",
      "[15:34:31] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.57467 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.42533 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['pb', 'pb_tuned']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:32] Stdout logging level is INFO2.\n",
      "[13:40:32] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:40:32] Task: multilabel\n",
      "\n",
      "[13:40:32] Start automl preset with listed constraints:\n",
      "[13:40:32] - time: 3600.00 seconds\n",
      "[13:40:32] - CPU: 1 cores\n",
      "[13:40:32] - memory: 16 GB\n",
      "\n",
      "[13:40:32] Train data shape: (14644, 22)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[13:40:34] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.38 secs\n",
      "[13:40:55] \u001b[1mSelector_XGB\u001b[0m fitting and predicting completed\n",
      "[13:40:55] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m ...\n",
      "[13:40:55] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m (orig) =====\n",
      "[13:40:57] Stdout logging level is INFO.\n",
      "[13:40:57] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:40:58] Iter 0; Sample 0, BCE = 0.3789424276385505; \n",
      "[13:40:58] Iter 100; Sample 0, BCE = 0.35316098700961457; \n",
      "[13:40:59] Iter 200; Sample 0, BCE = 0.35308152496791867; \n",
      "[13:40:59] Iter 300; Sample 0, BCE = 0.35371504848952195; \n",
      "[13:41:00] Early stopping at iter 333, best iter 133, best_score 0.35293886413183423\n",
      "[13:41:00] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m (orig) =====\n",
      "[13:41:00] Stdout logging level is INFO.\n",
      "[13:41:00] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:00] Iter 0; Sample 0, BCE = 0.3719367201841013; \n",
      "[13:41:01] Iter 100; Sample 0, BCE = 0.34545536150352724; \n",
      "[13:41:01] Iter 200; Sample 0, BCE = 0.34547856229896684; \n",
      "[13:41:02] Iter 300; Sample 0, BCE = 0.3461807437792049; \n",
      "[13:41:02] Early stopping at iter 332, best iter 132, best_score 0.3452909531303995\n",
      "[13:41:02] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m (orig) =====\n",
      "[13:41:02] Stdout logging level is INFO.\n",
      "[13:41:02] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:02] Iter 0; Sample 0, BCE = 0.3755538659113185; \n",
      "[13:41:03] Iter 100; Sample 0, BCE = 0.349250025444595; \n",
      "[13:41:04] Iter 200; Sample 0, BCE = 0.3493107281808578; \n",
      "[13:41:04] Iter 300; Sample 0, BCE = 0.3500493748204057; \n",
      "[13:41:04] Early stopping at iter 323, best iter 123, best_score 0.34905652255703995\n",
      "[13:41:04] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m finished. score = \u001b[1m-7.315918581036719\u001b[0m\n",
      "[13:41:04] \u001b[1mLvl_0_Pipe_0_Mod_0_PB\u001b[0m fitting and predicting completed\n",
      "[13:41:04] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m ... Time budget is 300.00 secs\n",
      "[13:41:04] Stdout logging level is INFO.\n",
      "[13:41:04] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:04] Iter 0; Sample 0, BCE = 0.3793668776436931; \n",
      "[13:41:05] Iter 100; Sample 0, BCE = 0.35423638206500724; \n",
      "[13:41:06] Iter 200; Sample 0, BCE = 0.35254550777059945; \n",
      "[13:41:06] Iter 300; Sample 0, BCE = 0.35230368120998035; \n",
      "[13:41:06] Iter 400; Sample 0, BCE = 0.35233203117317163; \n",
      "[13:41:07] Iter 500; Sample 0, BCE = 0.35241093025713593; \n",
      "[13:41:07] Early stopping at iter 510, best iter 310, best_score 0.352280064815066\n",
      "[13:41:07] Stdout logging level is INFO.\n",
      "[13:41:07] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:07] Iter 0; Sample 0, BCE = 0.37919630825519124; \n",
      "[13:41:08] Iter 100; Sample 0, BCE = 0.35338598351004896; \n",
      "[13:41:09] Iter 200; Sample 0, BCE = 0.3526815228109326; \n",
      "[13:41:09] Iter 300; Sample 0, BCE = 0.3529770920233793; \n",
      "[13:41:10] Early stopping at iter 371, best iter 171, best_score 0.3526163274879408\n",
      "[13:41:10] Stdout logging level is INFO.\n",
      "[13:41:10] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:10] Iter 0; Sample 0, BCE = 0.3794072943151126; \n",
      "[13:41:10] Iter 100; Sample 0, BCE = 0.3548822747246202; \n",
      "[13:41:11] Iter 200; Sample 0, BCE = 0.3527493470858399; \n",
      "[13:41:11] Iter 300; Sample 0, BCE = 0.35230364721246393; \n",
      "[13:41:11] Iter 400; Sample 0, BCE = 0.35219903258373647; \n",
      "[13:41:12] Iter 500; Sample 0, BCE = 0.35221911391707766; \n",
      "[13:41:12] Iter 600; Sample 0, BCE = 0.3522684155609657; \n",
      "[13:41:12] Early stopping at iter 622, best iter 422, best_score 0.35218676577137126\n",
      "[13:41:12] Stdout logging level is INFO.\n",
      "[13:41:12] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:12] Iter 0; Sample 0, BCE = 0.3791303996348345; \n",
      "[13:41:13] Iter 100; Sample 0, BCE = 0.3533434905168852; \n",
      "[13:41:13] Iter 200; Sample 0, BCE = 0.35323794092563005; \n",
      "[13:41:14] Iter 300; Sample 0, BCE = 0.3539037658837372; \n",
      "[13:41:14] Early stopping at iter 345, best iter 145, best_score 0.35298309092269387\n",
      "[13:41:15] Stdout logging level is INFO.\n",
      "[13:41:15] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:15] Iter 0; Sample 0, BCE = 0.37901500290987233; \n",
      "[13:41:15] Iter 100; Sample 0, BCE = 0.3536356114261504; \n",
      "[13:41:16] Iter 200; Sample 0, BCE = 0.3541286448373241; \n",
      "[13:41:17] Iter 300; Sample 0, BCE = 0.3551616825041508; \n",
      "[13:41:17] Early stopping at iter 317, best iter 117, best_score 0.35354498262450684\n",
      "[13:41:17] Stdout logging level is INFO.\n",
      "[13:41:17] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:17] Iter 0; Sample 0, BCE = 0.37938873421589686; \n",
      "[13:41:17] Iter 100; Sample 0, BCE = 0.3547875498213274; \n",
      "[13:41:18] Iter 200; Sample 0, BCE = 0.3527943927342022; \n",
      "[13:41:18] Iter 300; Sample 0, BCE = 0.3524262742323478; \n",
      "[13:41:19] Iter 400; Sample 0, BCE = 0.35230217421024274; \n",
      "[13:41:19] Iter 500; Sample 0, BCE = 0.35234642656624665; \n",
      "[13:41:19] Iter 600; Sample 0, BCE = 0.352439728550401; \n",
      "[13:41:19] Early stopping at iter 627, best iter 427, best_score 0.35228441419110984\n",
      "[13:41:20] Stdout logging level is INFO.\n",
      "[13:41:20] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:20] Iter 0; Sample 0, BCE = 0.3791963087394007; \n",
      "[13:41:20] Iter 100; Sample 0, BCE = 0.3533850608711716; \n",
      "[13:41:21] Iter 200; Sample 0, BCE = 0.35268043774977254; \n",
      "[13:41:21] Iter 300; Sample 0, BCE = 0.35297509180988573; \n",
      "[13:41:21] Early stopping at iter 371, best iter 171, best_score 0.3526153594255507\n",
      "[13:41:22] Stdout logging level is INFO.\n",
      "[13:41:22] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:22] Iter 0; Sample 0, BCE = 0.3793887340480985; \n",
      "[13:41:22] Iter 100; Sample 0, BCE = 0.3547875494292575; \n",
      "[13:41:22] Iter 200; Sample 0, BCE = 0.35279439227984727; \n",
      "[13:41:23] Iter 300; Sample 0, BCE = 0.35242645000063066; \n",
      "[13:41:23] Iter 400; Sample 0, BCE = 0.3523026686188703; \n",
      "[13:41:23] Iter 500; Sample 0, BCE = 0.3523469237813554; \n",
      "[13:41:24] Iter 600; Sample 0, BCE = 0.35244021723142255; \n",
      "[13:41:24] Early stopping at iter 627, best iter 427, best_score 0.3522849082427131\n",
      "[13:41:24] Stdout logging level is INFO.\n",
      "[13:41:24] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:24] Iter 0; Sample 0, BCE = 0.37920769869041865; \n",
      "[13:41:24] Iter 100; Sample 0, BCE = 0.3533101964489201; \n",
      "[13:41:25] Iter 200; Sample 0, BCE = 0.3526126171149827; \n",
      "[13:41:26] Iter 300; Sample 0, BCE = 0.3528745830815952; \n",
      "[13:41:26] Iter 400; Sample 0, BCE = 0.3532738382407221; \n",
      "[13:41:26] Early stopping at iter 402, best iter 202, best_score 0.35260608092183704\n",
      "[13:41:26] Stdout logging level is INFO.\n",
      "[13:41:26] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:26] Iter 0; Sample 0, BCE = 0.37919655113994916; \n",
      "[13:41:27] Iter 100; Sample 0, BCE = 0.3534143992989526; \n",
      "[13:41:27] Iter 200; Sample 0, BCE = 0.3527083394077269; \n",
      "[13:41:28] Iter 300; Sample 0, BCE = 0.35294346150455314; \n",
      "[13:41:28] Early stopping at iter 375, best iter 175, best_score 0.35266932645623067\n",
      "[13:41:28] Stdout logging level is INFO.\n",
      "[13:41:28] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:28] Iter 0; Sample 0, BCE = 0.37938874983847237; \n",
      "[13:41:29] Iter 100; Sample 0, BCE = 0.35479025404475784; \n",
      "[13:41:29] Iter 200; Sample 0, BCE = 0.35278919242569745; \n",
      "[13:41:30] Iter 300; Sample 0, BCE = 0.35243380469383445; \n",
      "[13:41:30] Iter 400; Sample 0, BCE = 0.352319263748428; \n",
      "[13:41:30] Iter 500; Sample 0, BCE = 0.35235783686232036; \n",
      "[13:41:31] Iter 600; Sample 0, BCE = 0.3524264104659922; \n",
      "[13:41:31] Early stopping at iter 607, best iter 407, best_score 0.35231064813999274\n",
      "[13:41:31] Stdout logging level is INFO.\n",
      "[13:41:31] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:31] Iter 0; Sample 0, BCE = 0.3793887350048003; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:31] Iter 100; Sample 0, BCE = 0.3547875670015221; \n",
      "[13:41:32] Iter 200; Sample 0, BCE = 0.35279406745567377; \n",
      "[13:41:32] Iter 300; Sample 0, BCE = 0.3524260047308684; \n",
      "[13:41:32] Iter 400; Sample 0, BCE = 0.3523019752745216; \n",
      "[13:41:33] Iter 500; Sample 0, BCE = 0.3523465918328254; \n",
      "[13:41:33] Iter 600; Sample 0, BCE = 0.35243949489674004; \n",
      "[13:41:33] Early stopping at iter 627, best iter 427, best_score 0.3522842078653014\n",
      "[13:41:33] Stdout logging level is INFO.\n",
      "[13:41:33] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:33] Iter 0; Sample 0, BCE = 0.37929389701453603; \n",
      "[13:41:34] Iter 100; Sample 0, BCE = 0.3537212303618661; \n",
      "[13:41:34] Iter 200; Sample 0, BCE = 0.3523936308820458; \n",
      "[13:41:35] Iter 300; Sample 0, BCE = 0.3523387433086477; \n",
      "[13:41:35] Iter 400; Sample 0, BCE = 0.35249046995321504; \n",
      "[13:41:35] Early stopping at iter 455, best iter 255, best_score 0.35228731166978755\n",
      "[13:41:35] Stdout logging level is INFO.\n",
      "[13:41:35] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:35] Iter 0; Sample 0, BCE = 0.37929236472654737; \n",
      "[13:41:36] Iter 100; Sample 0, BCE = 0.3537775700255413; \n",
      "[13:41:36] Iter 200; Sample 0, BCE = 0.3524347660741229; \n",
      "[13:41:37] Iter 300; Sample 0, BCE = 0.35243920011394236; \n",
      "[13:41:37] Iter 400; Sample 0, BCE = 0.3525645397049774; \n",
      "[13:41:38] Early stopping at iter 477, best iter 277, best_score 0.35238519123015793\n",
      "[13:41:38] Stdout logging level is INFO.\n",
      "[13:41:38] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:38] Iter 0; Sample 0, BCE = 0.3794638846573479; \n",
      "[13:41:38] Iter 100; Sample 0, BCE = 0.3556082164390217; \n",
      "[13:41:38] Iter 200; Sample 0, BCE = 0.3531066826982035; \n",
      "[13:41:39] Iter 300; Sample 0, BCE = 0.35249081823382605; \n",
      "[13:41:39] Iter 400; Sample 0, BCE = 0.35226923290391604; \n",
      "[13:41:39] Iter 500; Sample 0, BCE = 0.3521891909843992; \n",
      "[13:41:40] Iter 600; Sample 0, BCE = 0.3521581920312622; \n",
      "[13:41:40] Iter 700; Sample 0, BCE = 0.3521915992752423; \n",
      "[13:41:41] Iter 800; Sample 0, BCE = 0.3522590744558317; \n",
      "[13:41:41] Early stopping at iter 822, best iter 622, best_score 0.3521421192732397\n",
      "[13:41:41] Stdout logging level is INFO.\n",
      "[13:41:41] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:41] Iter 0; Sample 0, BCE = 0.3793992648318166; \n",
      "[13:41:42] Iter 100; Sample 0, BCE = 0.3548647976065858; \n",
      "[13:41:42] Iter 200; Sample 0, BCE = 0.35290014308356327; \n",
      "[13:41:42] Iter 300; Sample 0, BCE = 0.3524998240888487; \n",
      "[13:41:43] Iter 400; Sample 0, BCE = 0.3523949225699536; \n",
      "[13:41:43] Iter 500; Sample 0, BCE = 0.35241897973062275; \n",
      "[13:41:44] Early stopping at iter 592, best iter 392, best_score 0.35237881374387614\n",
      "[13:41:44] Stdout logging level is INFO.\n",
      "[13:41:44] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:44] Iter 0; Sample 0, BCE = 0.3793923107463978; \n",
      "[13:41:44] Iter 100; Sample 0, BCE = 0.3548283613916871; \n",
      "[13:41:45] Iter 200; Sample 0, BCE = 0.35269299761540135; \n",
      "[13:41:45] Iter 300; Sample 0, BCE = 0.3522903978977581; \n",
      "[13:41:45] Iter 400; Sample 0, BCE = 0.3521851555665141; \n",
      "[13:41:46] Iter 500; Sample 0, BCE = 0.35222543711216087; \n",
      "[13:41:46] Iter 600; Sample 0, BCE = 0.3522584367497545; \n",
      "[13:41:46] Early stopping at iter 622, best iter 422, best_score 0.35217935273730117\n",
      "[13:41:46] Stdout logging level is INFO.\n",
      "[13:41:46] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:46] Iter 0; Sample 0, BCE = 0.3791082327691716; \n",
      "[13:41:47] Iter 100; Sample 0, BCE = 0.3533144072966377; \n",
      "[13:41:47] Iter 200; Sample 0, BCE = 0.352972079071273; \n",
      "[13:41:48] Iter 300; Sample 0, BCE = 0.3535740429537689; \n",
      "[13:41:49] Early stopping at iter 366, best iter 166, best_score 0.35292057799563314\n",
      "[13:41:49] Stdout logging level is INFO.\n",
      "[13:41:49] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:49] Iter 0; Sample 0, BCE = 0.379292808033453; \n",
      "[13:41:49] Iter 100; Sample 0, BCE = 0.3537924921645434; \n",
      "[13:41:50] Iter 200; Sample 0, BCE = 0.3524575717657674; \n",
      "[13:41:50] Iter 300; Sample 0, BCE = 0.35244900168786536; \n",
      "[13:41:50] Iter 400; Sample 0, BCE = 0.3525606337279662; \n",
      "[13:41:51] Early stopping at iter 455, best iter 255, best_score 0.35238944053380683\n",
      "[13:41:51] Stdout logging level is INFO.\n",
      "[13:41:51] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:51] Iter 0; Sample 0, BCE = 0.37941964079877233; \n",
      "[13:41:51] Iter 100; Sample 0, BCE = 0.3550326484297149; \n",
      "[13:41:51] Iter 200; Sample 0, BCE = 0.35280220324114; \n",
      "[13:41:52] Iter 300; Sample 0, BCE = 0.35229207333921564; \n",
      "[13:41:52] Iter 400; Sample 0, BCE = 0.3521491579959741; \n",
      "[13:41:52] Iter 500; Sample 0, BCE = 0.3521028945398503; \n",
      "[13:41:53] Iter 600; Sample 0, BCE = 0.3521194873104332; \n",
      "[13:41:53] Iter 700; Sample 0, BCE = 0.35217526188558124; \n",
      "[13:41:53] Early stopping at iter 765, best iter 565, best_score 0.35207896306119685\n",
      "[13:41:54] Stdout logging level is INFO.\n",
      "[13:41:54] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:54] Iter 0; Sample 0, BCE = 0.379132113315149; \n",
      "[13:41:54] Iter 100; Sample 0, BCE = 0.35339127411031523; \n",
      "[13:41:55] Iter 200; Sample 0, BCE = 0.3531906613248772; \n",
      "[13:41:56] Iter 300; Sample 0, BCE = 0.3538322404240755; \n",
      "[13:41:56] Early stopping at iter 345, best iter 145, best_score 0.3529891782225286\n",
      "[13:41:56] Stdout logging level is INFO.\n",
      "[13:41:56] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:56] Iter 0; Sample 0, BCE = 0.37941584888234503; \n",
      "[13:41:56] Iter 100; Sample 0, BCE = 0.35495691089951303; \n",
      "[13:41:57] Iter 200; Sample 0, BCE = 0.35277625258794165; \n",
      "[13:41:57] Iter 300; Sample 0, BCE = 0.3523289053719617; \n",
      "[13:41:58] Iter 400; Sample 0, BCE = 0.3521913006904596; \n",
      "[13:41:58] Iter 500; Sample 0, BCE = 0.3521612558383596; \n",
      "[13:41:58] Iter 600; Sample 0, BCE = 0.3521775929803548; \n",
      "[13:41:59] Early stopping at iter 677, best iter 477, best_score 0.3521326246638508\n",
      "[13:41:59] Stdout logging level is INFO.\n",
      "[13:41:59] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:41:59] Iter 0; Sample 0, BCE = 0.3794095737531391; \n",
      "[13:41:59] Iter 100; Sample 0, BCE = 0.354844239539515; \n",
      "[13:42:00] Iter 200; Sample 0, BCE = 0.3527239730462295; \n",
      "[13:42:00] Iter 300; Sample 0, BCE = 0.35227562782138183; \n",
      "[13:42:00] Iter 400; Sample 0, BCE = 0.3521722045627091; \n",
      "[13:42:01] Iter 500; Sample 0, BCE = 0.35217090199085455; \n",
      "[13:42:01] Iter 600; Sample 0, BCE = 0.35221401958311216; \n",
      "[13:42:01] Early stopping at iter 647, best iter 447, best_score 0.352143988055503\n",
      "[13:42:01] Stdout logging level is INFO.\n",
      "[13:42:01] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:01] Iter 0; Sample 0, BCE = 0.37934132974858564; \n",
      "[13:42:02] Iter 100; Sample 0, BCE = 0.3539624864154937; \n",
      "[13:42:02] Iter 200; Sample 0, BCE = 0.3524084247043141; \n",
      "[13:42:03] Iter 300; Sample 0, BCE = 0.3522285465797841; \n",
      "[13:42:03] Iter 400; Sample 0, BCE = 0.3523219145626026; \n",
      "[13:42:04] Iter 500; Sample 0, BCE = 0.3524827908048515; \n",
      "[13:42:04] Early stopping at iter 526, best iter 326, best_score 0.3521926737469607\n",
      "[13:42:04] Stdout logging level is INFO.\n",
      "[13:42:04] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:04] Iter 0; Sample 0, BCE = 0.3793898985789764; \n",
      "[13:42:04] Iter 100; Sample 0, BCE = 0.3547577898695061; \n",
      "[13:42:05] Iter 200; Sample 0, BCE = 0.35274576553367043; \n",
      "[13:42:05] Iter 300; Sample 0, BCE = 0.35232678813810536; \n",
      "[13:42:05] Iter 400; Sample 0, BCE = 0.3522229139773942; \n",
      "[13:42:06] Iter 500; Sample 0, BCE = 0.3522714279380283; \n",
      "[13:42:06] Iter 600; Sample 0, BCE = 0.3523298116256559; \n",
      "[13:42:06] Early stopping at iter 609, best iter 409, best_score 0.3522165325591598\n",
      "[13:42:06] Stdout logging level is INFO.\n",
      "[13:42:06] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:06] Iter 0; Sample 0, BCE = 0.3792929975554612; \n",
      "[13:42:07] Iter 100; Sample 0, BCE = 0.35376832340111636; \n",
      "[13:42:07] Iter 200; Sample 0, BCE = 0.3524422201389456; \n",
      "[13:42:08] Iter 300; Sample 0, BCE = 0.3523977846255959; \n",
      "[13:42:08] Iter 400; Sample 0, BCE = 0.3525448099946683; \n",
      "[13:42:08] Early stopping at iter 459, best iter 259, best_score 0.35235746578696014\n",
      "[13:42:08] Stdout logging level is INFO.\n",
      "[13:42:08] GDBT train starts. Max iter 3000, early stopping rounds 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:08] Iter 0; Sample 0, BCE = 0.3794120082671062; \n",
      "[13:42:09] Iter 100; Sample 0, BCE = 0.3549137037341633; \n",
      "[13:42:09] Iter 200; Sample 0, BCE = 0.35274286342711714; \n",
      "[13:42:09] Iter 300; Sample 0, BCE = 0.3522570424169081; \n",
      "[13:42:10] Iter 400; Sample 0, BCE = 0.35212915780069526; \n",
      "[13:42:10] Iter 500; Sample 0, BCE = 0.35212918003596694; \n",
      "[13:42:10] Iter 600; Sample 0, BCE = 0.3522037441256741; \n",
      "[13:42:11] Early stopping at iter 675, best iter 475, best_score 0.35210327812358483\n",
      "[13:42:11] Stdout logging level is INFO.\n",
      "[13:42:11] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:11] Iter 0; Sample 0, BCE = 0.37906035280929584; \n",
      "[13:42:12] Iter 100; Sample 0, BCE = 0.3535995602508987; \n",
      "[13:42:13] Iter 200; Sample 0, BCE = 0.3539212128991216; \n",
      "[13:42:13] Iter 300; Sample 0, BCE = 0.3549163979089165; \n",
      "[13:42:13] Early stopping at iter 318, best iter 118, best_score 0.35349410655816055\n",
      "[13:42:14] Stdout logging level is INFO.\n",
      "[13:42:14] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:14] Iter 0; Sample 0, BCE = 0.3792924405508247; \n",
      "[13:42:14] Iter 100; Sample 0, BCE = 0.35377713519046916; \n",
      "[13:42:14] Iter 200; Sample 0, BCE = 0.3524373391571258; \n",
      "[13:42:15] Iter 300; Sample 0, BCE = 0.352418537946915; \n",
      "[13:42:15] Iter 400; Sample 0, BCE = 0.3525405963788829; \n",
      "[13:42:16] Early stopping at iter 455, best iter 255, best_score 0.3523494195459984\n",
      "[13:42:16] Stdout logging level is INFO.\n",
      "[13:42:16] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:16] Iter 0; Sample 0, BCE = 0.37944654319699533; \n",
      "[13:42:16] Iter 100; Sample 0, BCE = 0.35539146197661203; \n",
      "[13:42:16] Iter 200; Sample 0, BCE = 0.352989074969724; \n",
      "[13:42:17] Iter 300; Sample 0, BCE = 0.352433932752846; \n",
      "[13:42:17] Iter 400; Sample 0, BCE = 0.35221975283391416; \n",
      "[13:42:17] Iter 500; Sample 0, BCE = 0.35218185586076184; \n",
      "[13:42:18] Iter 600; Sample 0, BCE = 0.35217512133394113; \n",
      "[13:42:18] Early stopping at iter 674, best iter 474, best_score 0.35216399288003597\n",
      "[13:42:18] Stdout logging level is INFO.\n",
      "[13:42:18] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:18] Iter 0; Sample 0, BCE = 0.3793484252623225; \n",
      "[13:42:19] Iter 100; Sample 0, BCE = 0.35401062974841085; \n",
      "[13:42:19] Iter 200; Sample 0, BCE = 0.35248206775449215; \n",
      "[13:42:19] Iter 300; Sample 0, BCE = 0.35228401070095394; \n",
      "[13:42:20] Iter 400; Sample 0, BCE = 0.3523137102047418; \n",
      "[13:42:20] Iter 500; Sample 0, BCE = 0.35247654069522977; \n",
      "[13:42:20] Early stopping at iter 526, best iter 326, best_score 0.3522509121603378\n",
      "[13:42:21] Stdout logging level is INFO.\n",
      "[13:42:21] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:21] Iter 0; Sample 0, BCE = 0.3794163323031175; \n",
      "[13:42:21] Iter 100; Sample 0, BCE = 0.3549725408004014; \n",
      "[13:42:21] Iter 200; Sample 0, BCE = 0.35277362405575613; \n",
      "[13:42:22] Iter 300; Sample 0, BCE = 0.3523081469512177; \n",
      "[13:42:22] Iter 400; Sample 0, BCE = 0.35215885969032074; \n",
      "[13:42:22] Iter 500; Sample 0, BCE = 0.3521292605026675; \n",
      "[13:42:23] Iter 600; Sample 0, BCE = 0.3521411616245586; \n",
      "[13:42:23] Iter 700; Sample 0, BCE = 0.3522069827669868; \n",
      "[13:42:23] Early stopping at iter 759, best iter 559, best_score 0.3521031909716062\n",
      "[13:42:23] Stdout logging level is INFO.\n",
      "[13:42:23] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:23] Iter 0; Sample 0, BCE = 0.3794144314063093; \n",
      "[13:42:24] Iter 100; Sample 0, BCE = 0.3549464185225872; \n",
      "[13:42:24] Iter 200; Sample 0, BCE = 0.3527633906324229; \n",
      "[13:42:24] Iter 300; Sample 0, BCE = 0.3523153364103004; \n",
      "[13:42:25] Iter 400; Sample 0, BCE = 0.35217968298484087; \n",
      "[13:42:25] Iter 500; Sample 0, BCE = 0.35215713554001365; \n",
      "[13:42:25] Iter 600; Sample 0, BCE = 0.3521881155457859; \n",
      "[13:42:26] Iter 700; Sample 0, BCE = 0.35224444000020405; \n",
      "[13:42:26] Early stopping at iter 737, best iter 537, best_score 0.3521396746717749\n",
      "[13:42:26] Stdout logging level is INFO.\n",
      "[13:42:26] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:26] Iter 0; Sample 0, BCE = 0.37938925696477466; \n",
      "[13:42:26] Iter 100; Sample 0, BCE = 0.3548091465647328; \n",
      "[13:42:27] Iter 200; Sample 0, BCE = 0.3528076492474327; \n",
      "[13:42:27] Iter 300; Sample 0, BCE = 0.3524083947722293; \n",
      "[13:42:27] Iter 400; Sample 0, BCE = 0.3522688414623371; \n",
      "[13:42:28] Iter 500; Sample 0, BCE = 0.3523054382856741; \n",
      "[13:42:28] Iter 600; Sample 0, BCE = 0.3524041239559125; \n",
      "[13:42:28] Early stopping at iter 637, best iter 437, best_score 0.3522513372603674\n",
      "[13:42:28] Stdout logging level is INFO.\n",
      "[13:42:28] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:28] Iter 0; Sample 0, BCE = 0.37942419197335103; \n",
      "[13:42:29] Iter 100; Sample 0, BCE = 0.3551003327847906; \n",
      "[13:42:29] Iter 200; Sample 0, BCE = 0.35279904802657186; \n",
      "[13:42:29] Iter 300; Sample 0, BCE = 0.35229616270094277; \n",
      "[13:42:30] Iter 400; Sample 0, BCE = 0.3521689182154825; \n",
      "[13:42:30] Iter 500; Sample 0, BCE = 0.35212665756190625; \n",
      "[13:42:30] Iter 600; Sample 0, BCE = 0.35214000809815077; \n",
      "[13:42:31] Early stopping at iter 678, best iter 478, best_score 0.3521089420961341\n",
      "[13:42:31] Stdout logging level is INFO.\n",
      "[13:42:31] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:31] Iter 0; Sample 0, BCE = 0.37939290970676465; \n",
      "[13:42:31] Iter 100; Sample 0, BCE = 0.3548303962742254; \n",
      "[13:42:32] Iter 200; Sample 0, BCE = 0.352700639530288; \n",
      "[13:42:32] Iter 300; Sample 0, BCE = 0.3523029665499928; \n",
      "[13:42:32] Iter 400; Sample 0, BCE = 0.3521984329972364; \n",
      "[13:42:33] Iter 500; Sample 0, BCE = 0.35223509940609804; \n",
      "[13:42:33] Early stopping at iter 569, best iter 369, best_score 0.3521834474206238\n",
      "[13:42:33] Stdout logging level is INFO.\n",
      "[13:42:33] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:33] Iter 0; Sample 0, BCE = 0.3792977257854072; \n",
      "[13:42:34] Iter 100; Sample 0, BCE = 0.35367754488497954; \n",
      "[13:42:34] Iter 200; Sample 0, BCE = 0.3523733655654813; \n",
      "[13:42:34] Iter 300; Sample 0, BCE = 0.35231220317585593; \n",
      "[13:42:35] Iter 400; Sample 0, BCE = 0.35245293086447677; \n",
      "[13:42:35] Early stopping at iter 455, best iter 255, best_score 0.3522830591363425\n",
      "[13:42:35] Stdout logging level is INFO.\n",
      "[13:42:35] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:35] Iter 0; Sample 0, BCE = 0.379388737548601; \n",
      "[13:42:36] Iter 100; Sample 0, BCE = 0.35478946851269366; \n",
      "[13:42:36] Iter 200; Sample 0, BCE = 0.35281599927595686; \n",
      "[13:42:36] Iter 300; Sample 0, BCE = 0.3524548107010216; \n",
      "[13:42:37] Iter 400; Sample 0, BCE = 0.3523342089120386; \n",
      "[13:42:37] Iter 500; Sample 0, BCE = 0.35236249355404; \n",
      "[13:42:37] Iter 600; Sample 0, BCE = 0.3524135214622204; \n",
      "[13:42:37] Early stopping at iter 667, best iter 467, best_score 0.35231385944800325\n",
      "[13:42:38] Stdout logging level is INFO.\n",
      "[13:42:38] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:38] Iter 0; Sample 0, BCE = 0.3791303997104668; \n",
      "[13:42:38] Iter 100; Sample 0, BCE = 0.3533451982770993; \n",
      "[13:42:39] Iter 200; Sample 0, BCE = 0.35323911494416255; \n",
      "[13:42:39] Iter 300; Sample 0, BCE = 0.3539051777751621; \n",
      "[13:42:40] Early stopping at iter 345, best iter 145, best_score 0.35298478500381003\n",
      "[13:42:40] Stdout logging level is INFO.\n",
      "[13:42:40] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:40] Iter 0; Sample 0, BCE = 0.37936082309457503; \n",
      "[13:42:40] Iter 100; Sample 0, BCE = 0.35419659119122865; \n",
      "[13:42:41] Iter 200; Sample 0, BCE = 0.3525260784091368; \n",
      "[13:42:41] Iter 300; Sample 0, BCE = 0.3522844321437281; \n",
      "[13:42:41] Iter 400; Sample 0, BCE = 0.35231082832312055; \n",
      "[13:42:42] Iter 500; Sample 0, BCE = 0.3524204367968418; \n",
      "[13:42:42] Early stopping at iter 526, best iter 326, best_score 0.3522612216844687\n",
      "[13:42:42] Stdout logging level is INFO.\n",
      "[13:42:42] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:42] Iter 0; Sample 0, BCE = 0.3794118960135551; \n",
      "[13:42:43] Iter 100; Sample 0, BCE = 0.35490442954380164; \n",
      "[13:42:43] Iter 200; Sample 0, BCE = 0.3527528741003301; \n",
      "[13:42:43] Iter 300; Sample 0, BCE = 0.35228824448688784; \n",
      "[13:42:44] Iter 400; Sample 0, BCE = 0.35215226756052453; \n",
      "[13:42:44] Iter 500; Sample 0, BCE = 0.3521376831814618; \n",
      "[13:42:44] Iter 600; Sample 0, BCE = 0.3521739201345454; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:44] Early stopping at iter 680, best iter 480, best_score 0.35211480727351385\n",
      "[13:42:45] Stdout logging level is INFO.\n",
      "[13:42:45] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:45] Iter 0; Sample 0, BCE = 0.37941098618416447; \n",
      "[13:42:45] Iter 100; Sample 0, BCE = 0.35490669347519876; \n",
      "[13:42:45] Iter 200; Sample 0, BCE = 0.3527619651981761; \n",
      "[13:42:46] Iter 300; Sample 0, BCE = 0.35229019910355813; \n",
      "[13:42:46] Iter 400; Sample 0, BCE = 0.35217539904144474; \n",
      "[13:42:46] Iter 500; Sample 0, BCE = 0.35215955434096313; \n",
      "[13:42:47] Iter 600; Sample 0, BCE = 0.3522079793505275; \n",
      "[13:42:47] Early stopping at iter 675, best iter 475, best_score 0.35213785598743047\n",
      "[13:42:47] Stdout logging level is INFO.\n",
      "[13:42:47] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:47] Iter 0; Sample 0, BCE = 0.37939156554883746; \n",
      "[13:42:48] Iter 100; Sample 0, BCE = 0.3547736968873892; \n",
      "[13:42:48] Iter 200; Sample 0, BCE = 0.35271303090202627; \n",
      "[13:42:48] Iter 300; Sample 0, BCE = 0.3523204661179884; \n",
      "[13:42:49] Iter 400; Sample 0, BCE = 0.35216753256687333; \n",
      "[13:42:49] Iter 500; Sample 0, BCE = 0.35221537238613243; \n",
      "[13:42:49] Iter 600; Sample 0, BCE = 0.3522789048315999; \n",
      "[13:42:49] Early stopping at iter 607, best iter 407, best_score 0.3521607375356945\n",
      "[13:42:49] Stdout logging level is INFO.\n",
      "[13:42:49] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:49] Iter 0; Sample 0, BCE = 0.37943109344948606; \n",
      "[13:42:50] Iter 100; Sample 0, BCE = 0.35519078900182405; \n",
      "[13:42:50] Iter 200; Sample 0, BCE = 0.35287102184414915; \n",
      "[13:42:50] Iter 300; Sample 0, BCE = 0.35236019765198334; \n",
      "[13:42:51] Iter 400; Sample 0, BCE = 0.3521926608623607; \n",
      "[13:42:51] Iter 500; Sample 0, BCE = 0.3521607276052621; \n",
      "[13:42:51] Iter 600; Sample 0, BCE = 0.3521742649598804; \n",
      "[13:42:52] Iter 700; Sample 0, BCE = 0.35221957229249634; \n",
      "[13:42:52] Early stopping at iter 730, best iter 530, best_score 0.35213291999556634\n",
      "[13:42:52] Stdout logging level is INFO.\n",
      "[13:42:52] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:52] Iter 0; Sample 0, BCE = 0.37938937969414877; \n",
      "[13:42:52] Iter 100; Sample 0, BCE = 0.3548186121693197; \n",
      "[13:42:53] Iter 200; Sample 0, BCE = 0.3527871749654983; \n",
      "[13:42:53] Iter 300; Sample 0, BCE = 0.35237738579071975; \n",
      "[13:42:53] Iter 400; Sample 0, BCE = 0.35224393169862933; \n",
      "[13:42:54] Iter 500; Sample 0, BCE = 0.35228738009026495; \n",
      "[13:42:54] Iter 600; Sample 0, BCE = 0.35239014319917916; \n",
      "[13:42:54] Early stopping at iter 621, best iter 421, best_score 0.3522321712941918\n",
      "[13:42:54] Stdout logging level is INFO.\n",
      "[13:42:54] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:54] Iter 0; Sample 0, BCE = 0.37923241559495874; \n",
      "[13:42:55] Iter 100; Sample 0, BCE = 0.3533381194922389; \n",
      "[13:42:55] Iter 200; Sample 0, BCE = 0.3525419206907166; \n",
      "[13:42:56] Iter 300; Sample 0, BCE = 0.3527243313005273; \n",
      "[13:42:56] Early stopping at iter 383, best iter 183, best_score 0.3525342734098836\n",
      "[13:42:57] Stdout logging level is INFO.\n",
      "[13:42:57] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:57] Iter 0; Sample 0, BCE = 0.3793888215602603; \n",
      "[13:42:57] Iter 100; Sample 0, BCE = 0.3547935181426644; \n",
      "[13:42:57] Iter 200; Sample 0, BCE = 0.3527998096628924; \n",
      "[13:42:58] Iter 300; Sample 0, BCE = 0.3524368296297307; \n",
      "[13:42:58] Iter 400; Sample 0, BCE = 0.35230290937462827; \n",
      "[13:42:58] Iter 500; Sample 0, BCE = 0.35233741995013873; \n",
      "[13:42:59] Iter 600; Sample 0, BCE = 0.35243465991481476; \n",
      "[13:42:59] Early stopping at iter 637, best iter 437, best_score 0.3522946131899899\n",
      "[13:42:59] Stdout logging level is INFO.\n",
      "[13:42:59] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:42:59] Iter 0; Sample 0, BCE = 0.3794646815906156; \n",
      "[13:42:59] Iter 100; Sample 0, BCE = 0.3556333432125904; \n",
      "[13:43:00] Iter 200; Sample 0, BCE = 0.3531069966305807; \n",
      "[13:43:00] Iter 300; Sample 0, BCE = 0.35249794332840617; \n",
      "[13:43:00] Iter 400; Sample 0, BCE = 0.35227707867875496; \n",
      "[13:43:01] Iter 500; Sample 0, BCE = 0.35218920877496923; \n",
      "[13:43:01] Iter 600; Sample 0, BCE = 0.35214766655447605; \n",
      "[13:43:01] Iter 700; Sample 0, BCE = 0.35216968669152426; \n",
      "[13:43:02] Iter 800; Sample 0, BCE = 0.3522312328753219; \n",
      "[13:43:02] Early stopping at iter 841, best iter 641, best_score 0.35213211796936894\n",
      "[13:43:02] Stdout logging level is INFO.\n",
      "[13:43:02] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:02] Iter 0; Sample 0, BCE = 0.3792958543882451; \n",
      "[13:43:03] Iter 100; Sample 0, BCE = 0.3537544528750769; \n",
      "[13:43:03] Iter 200; Sample 0, BCE = 0.35243822256379853; \n",
      "[13:43:03] Iter 300; Sample 0, BCE = 0.3523656795044917; \n",
      "[13:43:04] Iter 400; Sample 0, BCE = 0.35247776640388107; \n",
      "[13:43:04] Early stopping at iter 488, best iter 288, best_score 0.35234487949353316\n",
      "[13:43:04] Stdout logging level is INFO.\n",
      "[13:43:04] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:04] Iter 0; Sample 0, BCE = 0.37938908694995815; \n",
      "[13:43:05] Iter 100; Sample 0, BCE = 0.35479888027267664; \n",
      "[13:43:05] Iter 200; Sample 0, BCE = 0.3527998188243343; \n",
      "[13:43:05] Iter 300; Sample 0, BCE = 0.3524033878743548; \n",
      "[13:43:06] Iter 400; Sample 0, BCE = 0.35227472477309774; \n",
      "[13:43:06] Iter 500; Sample 0, BCE = 0.35230166917441; \n",
      "[13:43:06] Early stopping at iter 569, best iter 369, best_score 0.3522649207762321\n",
      "[13:43:06] Stdout logging level is INFO.\n",
      "[13:43:06] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:06] Iter 0; Sample 0, BCE = 0.3794341490426365; \n",
      "[13:43:07] Iter 100; Sample 0, BCE = 0.35524462665356693; \n",
      "[13:43:07] Iter 200; Sample 0, BCE = 0.3528858208252053; \n",
      "[13:43:07] Iter 300; Sample 0, BCE = 0.35236081541095593; \n",
      "[13:43:08] Iter 400; Sample 0, BCE = 0.3521893376255616; \n",
      "[13:43:08] Iter 500; Sample 0, BCE = 0.3521683575188751; \n",
      "[13:43:08] Iter 600; Sample 0, BCE = 0.3521768387581041; \n",
      "[13:43:09] Iter 700; Sample 0, BCE = 0.35223302600826417; \n",
      "[13:43:09] Early stopping at iter 730, best iter 530, best_score 0.3521482624449624\n",
      "[13:43:09] Stdout logging level is INFO.\n",
      "[13:43:09] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:09] Iter 0; Sample 0, BCE = 0.3794109515675187; \n",
      "[13:43:09] Iter 100; Sample 0, BCE = 0.35489905064881777; \n",
      "[13:43:10] Iter 200; Sample 0, BCE = 0.352734014120093; \n",
      "[13:43:10] Iter 300; Sample 0, BCE = 0.35227034373457883; \n",
      "[13:43:10] Iter 400; Sample 0, BCE = 0.3521771307131491; \n",
      "[13:43:11] Iter 500; Sample 0, BCE = 0.3521622093964267; \n",
      "[13:43:11] Iter 600; Sample 0, BCE = 0.35221534357810874; \n",
      "[13:43:11] Early stopping at iter 670, best iter 470, best_score 0.35213756821256303\n",
      "[13:43:12] Stdout logging level is INFO.\n",
      "[13:43:12] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:12] Iter 0; Sample 0, BCE = 0.379393223848189; \n",
      "[13:43:12] Iter 100; Sample 0, BCE = 0.3548596311400543; \n",
      "[13:43:12] Iter 200; Sample 0, BCE = 0.35271896455031226; \n",
      "[13:43:13] Iter 300; Sample 0, BCE = 0.35231740565442793; \n",
      "[13:43:13] Iter 400; Sample 0, BCE = 0.352199576477274; \n",
      "[13:43:13] Iter 500; Sample 0, BCE = 0.3522300016741366; \n",
      "[13:43:14] Iter 600; Sample 0, BCE = 0.35227175572932257; \n",
      "[13:43:14] Early stopping at iter 622, best iter 422, best_score 0.35219147940237905\n",
      "[13:43:14] Stdout logging level is INFO.\n",
      "[13:43:14] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:14] Iter 0; Sample 0, BCE = 0.3794131885248989; \n",
      "[13:43:14] Iter 100; Sample 0, BCE = 0.3549343940031325; \n",
      "[13:43:15] Iter 200; Sample 0, BCE = 0.35276400590731394; \n",
      "[13:43:15] Iter 300; Sample 0, BCE = 0.3523048632633503; \n",
      "[13:43:15] Iter 400; Sample 0, BCE = 0.3521721363739597; \n",
      "[13:43:16] Iter 500; Sample 0, BCE = 0.3521568973444546; \n",
      "[13:43:16] Iter 600; Sample 0, BCE = 0.3522137048223127; \n",
      "[13:43:16] Early stopping at iter 678, best iter 478, best_score 0.35213342191730485\n",
      "[13:43:16] Stdout logging level is INFO.\n",
      "[13:43:16] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:16] Iter 0; Sample 0, BCE = 0.3794566334338199; \n",
      "[13:43:17] Iter 100; Sample 0, BCE = 0.3556836402251023; \n",
      "[13:43:17] Iter 200; Sample 0, BCE = 0.35310837505341436; \n",
      "[13:43:17] Iter 300; Sample 0, BCE = 0.3524827415690477; \n",
      "[13:43:18] Iter 400; Sample 0, BCE = 0.3522658270139069; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:18] Iter 500; Sample 0, BCE = 0.3521802067582093; \n",
      "[13:43:19] Iter 600; Sample 0, BCE = 0.3521466588779485; \n",
      "[13:43:19] Iter 700; Sample 0, BCE = 0.35216636467354573; \n",
      "[13:43:19] Iter 800; Sample 0, BCE = 0.35223121551637676; \n",
      "[13:43:19] Early stopping at iter 836, best iter 636, best_score 0.3521335402000663\n",
      "[13:43:20] Stdout logging level is INFO.\n",
      "[13:43:20] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:20] Iter 0; Sample 0, BCE = 0.3792923634282585; \n",
      "[13:43:20] Iter 100; Sample 0, BCE = 0.3537795205045072; \n",
      "[13:43:21] Iter 200; Sample 0, BCE = 0.35243684415836535; \n",
      "[13:43:21] Iter 300; Sample 0, BCE = 0.35243983682645375; \n",
      "[13:43:22] Iter 400; Sample 0, BCE = 0.3525660507905294; \n",
      "[13:43:22] Early stopping at iter 477, best iter 277, best_score 0.3523858249066567\n",
      "[13:43:22] Stdout logging level is INFO.\n",
      "[13:43:22] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:22] Iter 0; Sample 0, BCE = 0.3792093747447789; \n",
      "[13:43:23] Iter 100; Sample 0, BCE = 0.35328715588474957; \n",
      "[13:43:24] Iter 200; Sample 0, BCE = 0.3525734387405598; \n",
      "[13:43:24] Iter 300; Sample 0, BCE = 0.3528450261262245; \n",
      "[13:43:25] Iter 400; Sample 0, BCE = 0.35323778744503354; \n",
      "[13:43:25] Early stopping at iter 402, best iter 202, best_score 0.3525656942068801\n",
      "[13:43:25] Stdout logging level is INFO.\n",
      "[13:43:25] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:25] Iter 0; Sample 0, BCE = 0.3793887340917194; \n",
      "[13:43:25] Iter 100; Sample 0, BCE = 0.3547871447684277; \n",
      "[13:43:26] Iter 200; Sample 0, BCE = 0.35279351835970635; \n",
      "[13:43:26] Iter 300; Sample 0, BCE = 0.3524253475398833; \n",
      "[13:43:26] Iter 400; Sample 0, BCE = 0.35230098834783957; \n",
      "[13:43:27] Iter 500; Sample 0, BCE = 0.35234549923087394; \n",
      "[13:43:27] Iter 600; Sample 0, BCE = 0.3524387643929086; \n",
      "[13:43:27] Early stopping at iter 627, best iter 427, best_score 0.3522832205983662\n",
      "[13:43:28] Stdout logging level is INFO.\n",
      "[13:43:28] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:28] Iter 0; Sample 0, BCE = 0.37940972499916; \n",
      "[13:43:28] Iter 100; Sample 0, BCE = 0.3548405045892348; \n",
      "[13:43:28] Iter 200; Sample 0, BCE = 0.3527207566984711; \n",
      "[13:43:29] Iter 300; Sample 0, BCE = 0.35227868897653014; \n",
      "[13:43:29] Iter 400; Sample 0, BCE = 0.3521697765372759; \n",
      "[13:43:29] Iter 500; Sample 0, BCE = 0.3521716212771165; \n",
      "[13:43:30] Iter 600; Sample 0, BCE = 0.3522083176836349; \n",
      "[13:43:30] Early stopping at iter 680, best iter 480, best_score 0.3521391772349133\n",
      "[13:43:30] Stdout logging level is INFO.\n",
      "[13:43:30] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:30] Iter 0; Sample 0, BCE = 0.3793068494635678; \n",
      "[13:43:31] Iter 100; Sample 0, BCE = 0.3537871326498685; \n",
      "[13:43:31] Iter 200; Sample 0, BCE = 0.35242387418537774; \n",
      "[13:43:31] Iter 300; Sample 0, BCE = 0.3523391445195582; \n",
      "[13:43:32] Iter 400; Sample 0, BCE = 0.35245750581370217; \n",
      "[13:43:32] Early stopping at iter 455, best iter 255, best_score 0.3523054719776129\n",
      "[13:43:32] Stdout logging level is INFO.\n",
      "[13:43:32] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:32] Iter 0; Sample 0, BCE = 0.3792704399583489; \n",
      "[13:43:33] Iter 100; Sample 0, BCE = 0.3541415632366772; \n",
      "[13:43:34] Iter 200; Sample 0, BCE = 0.3532334814269994; \n",
      "[13:43:34] Iter 300; Sample 0, BCE = 0.35349354364625185; \n",
      "[13:43:35] Early stopping at iter 400, best iter 200, best_score 0.35322782353266363\n",
      "[13:43:35] Stdout logging level is INFO.\n",
      "[13:43:35] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:35] Iter 0; Sample 0, BCE = 0.37941497905131855; \n",
      "[13:43:35] Iter 100; Sample 0, BCE = 0.35498103756332483; \n",
      "[13:43:36] Iter 200; Sample 0, BCE = 0.35277256985108124; \n",
      "[13:43:36] Iter 300; Sample 0, BCE = 0.3523276966879363; \n",
      "[13:43:36] Iter 400; Sample 0, BCE = 0.3521924083440946; \n",
      "[13:43:37] Iter 500; Sample 0, BCE = 0.35216341561303593; \n",
      "[13:43:37] Iter 600; Sample 0, BCE = 0.3521904942537309; \n",
      "[13:43:37] Early stopping at iter 677, best iter 477, best_score 0.35213885929334937\n",
      "[13:43:38] Stdout logging level is INFO.\n",
      "[13:43:38] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:38] Iter 0; Sample 0, BCE = 0.3794102254621785; \n",
      "[13:43:38] Iter 100; Sample 0, BCE = 0.3548731109904479; \n",
      "[13:43:38] Iter 200; Sample 0, BCE = 0.3527306627610919; \n",
      "[13:43:39] Iter 300; Sample 0, BCE = 0.3522793699134274; \n",
      "[13:43:39] Iter 400; Sample 0, BCE = 0.35217847478068504; \n",
      "[13:43:39] Iter 500; Sample 0, BCE = 0.35217413574386836; \n",
      "[13:43:40] Iter 600; Sample 0, BCE = 0.3522232929431394; \n",
      "[13:43:40] Early stopping at iter 680, best iter 480, best_score 0.35214936293332244\n",
      "[13:43:40] Stdout logging level is INFO.\n",
      "[13:43:40] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:40] Iter 0; Sample 0, BCE = 0.37939071243252065; \n",
      "[13:43:41] Iter 100; Sample 0, BCE = 0.35483955693148844; \n",
      "[13:43:41] Iter 200; Sample 0, BCE = 0.3527563349651141; \n",
      "[13:43:41] Iter 300; Sample 0, BCE = 0.3523566063090128; \n",
      "[13:43:42] Iter 400; Sample 0, BCE = 0.3522342744101222; \n",
      "[13:43:42] Iter 500; Sample 0, BCE = 0.3522771258454865; \n",
      "[13:43:42] Iter 600; Sample 0, BCE = 0.3523363156956384; \n",
      "[13:43:42] Early stopping at iter 626, best iter 426, best_score 0.35222569521767555\n",
      "[13:43:43] Stdout logging level is INFO.\n",
      "[13:43:43] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:43] Iter 0; Sample 0, BCE = 0.3794199795805764; \n",
      "[13:43:43] Iter 100; Sample 0, BCE = 0.3550343729501246; \n",
      "[13:43:44] Iter 200; Sample 0, BCE = 0.35280341278930977; \n",
      "[13:43:44] Iter 300; Sample 0, BCE = 0.3523070296121311; \n",
      "[13:43:44] Iter 400; Sample 0, BCE = 0.35214630028408067; \n",
      "[13:43:45] Iter 500; Sample 0, BCE = 0.3521043751290922; \n",
      "[13:43:45] Iter 600; Sample 0, BCE = 0.3521268934075201; \n",
      "[13:43:45] Early stopping at iter 658, best iter 458, best_score 0.3520870861122541\n",
      "[13:43:46] Stdout logging level is INFO.\n",
      "[13:43:46] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:46] Iter 0; Sample 0, BCE = 0.3794074545777166; \n",
      "[13:43:46] Iter 100; Sample 0, BCE = 0.3548853573907635; \n",
      "[13:43:46] Iter 200; Sample 0, BCE = 0.3527497622811943; \n",
      "[13:43:47] Iter 300; Sample 0, BCE = 0.35231823407880886; \n",
      "[13:43:47] Iter 400; Sample 0, BCE = 0.35221321368035413; \n",
      "[13:43:47] Iter 500; Sample 0, BCE = 0.3522346742691697; \n",
      "[13:43:48] Iter 600; Sample 0, BCE = 0.3522632505654232; \n",
      "[13:43:48] Early stopping at iter 624, best iter 424, best_score 0.3521988737975592\n",
      "[13:43:48] Stdout logging level is INFO.\n",
      "[13:43:48] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:48] Iter 0; Sample 0, BCE = 0.3793914517772952; \n",
      "[13:43:48] Iter 100; Sample 0, BCE = 0.3548345065433443; \n",
      "[13:43:49] Iter 200; Sample 0, BCE = 0.3527365264943571; \n",
      "[13:43:49] Iter 300; Sample 0, BCE = 0.352333627043274; \n",
      "[13:43:50] Iter 400; Sample 0, BCE = 0.3522255405170437; \n",
      "[13:43:50] Iter 500; Sample 0, BCE = 0.35227271363345775; \n",
      "[13:43:50] Early stopping at iter 569, best iter 369, best_score 0.35220444817456115\n",
      "[13:43:50] Stdout logging level is INFO.\n",
      "[13:43:50] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:50] Iter 0; Sample 0, BCE = 0.3794373629311115; \n",
      "[13:43:51] Iter 100; Sample 0, BCE = 0.35524111781567813; \n",
      "[13:43:51] Iter 200; Sample 0, BCE = 0.35289231050583564; \n",
      "[13:43:51] Iter 300; Sample 0, BCE = 0.35238872007646915; \n",
      "[13:43:52] Iter 400; Sample 0, BCE = 0.352196939852157; \n",
      "[13:43:52] Iter 500; Sample 0, BCE = 0.3521583359941808; \n",
      "[13:43:52] Iter 600; Sample 0, BCE = 0.35217452505602603; \n",
      "[13:43:53] Iter 700; Sample 0, BCE = 0.3522121527122722; \n",
      "[13:43:53] Early stopping at iter 730, best iter 530, best_score 0.3521424181592876\n",
      "[13:43:53] Stdout logging level is INFO.\n",
      "[13:43:53] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:53] Iter 0; Sample 0, BCE = 0.3792943526220983; \n",
      "[13:43:53] Iter 100; Sample 0, BCE = 0.35369451660917456; \n",
      "[13:43:54] Iter 200; Sample 0, BCE = 0.35240393669956643; \n",
      "[13:43:54] Iter 300; Sample 0, BCE = 0.35238148437696076; \n",
      "[13:43:55] Iter 400; Sample 0, BCE = 0.35253470706633466; \n",
      "[13:43:55] Early stopping at iter 455, best iter 255, best_score 0.3523030823901836\n",
      "[13:43:55] Stdout logging level is INFO.\n",
      "[13:43:55] GDBT train starts. Max iter 3000, early stopping rounds 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:55] Iter 0; Sample 0, BCE = 0.3794151938785409; \n",
      "[13:43:55] Iter 100; Sample 0, BCE = 0.35497275069697376; \n",
      "[13:43:56] Iter 200; Sample 0, BCE = 0.35277768998699377; \n",
      "[13:43:56] Iter 300; Sample 0, BCE = 0.3523201744059999; \n",
      "[13:43:56] Iter 400; Sample 0, BCE = 0.3521741530390748; \n",
      "[13:43:57] Iter 500; Sample 0, BCE = 0.3521575966407192; \n",
      "[13:43:57] Iter 600; Sample 0, BCE = 0.3522006682688433; \n",
      "[13:43:57] Early stopping at iter 675, best iter 475, best_score 0.35212803453728697\n",
      "[13:43:58] Stdout logging level is INFO.\n",
      "[13:43:58] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:43:58] Iter 0; Sample 0, BCE = 0.3794078709504119; \n",
      "[13:43:58] Iter 100; Sample 0, BCE = 0.3548908296497685; \n",
      "[13:43:58] Iter 200; Sample 0, BCE = 0.3527822072659085; \n",
      "[13:43:59] Iter 300; Sample 0, BCE = 0.3523227610222962; \n",
      "[13:43:59] Iter 400; Sample 0, BCE = 0.3522248593968491; \n",
      "[13:43:59] Iter 500; Sample 0, BCE = 0.35223345666448314; \n",
      "[13:44:00] Iter 600; Sample 0, BCE = 0.3522636375778713; \n",
      "[13:44:00] Early stopping at iter 672, best iter 472, best_score 0.352201867487641\n",
      "[13:44:00] Stdout logging level is INFO.\n",
      "[13:44:00] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:00] Iter 0; Sample 0, BCE = 0.3794179578538592; \n",
      "[13:44:00] Iter 100; Sample 0, BCE = 0.35500754279494506; \n",
      "[13:44:01] Iter 200; Sample 0, BCE = 0.3527711646199623; \n",
      "[13:44:01] Iter 300; Sample 0, BCE = 0.35228563327187695; \n",
      "[13:44:01] Iter 400; Sample 0, BCE = 0.352142585119765; \n",
      "[13:44:02] Iter 500; Sample 0, BCE = 0.3521176800941618; \n",
      "[13:44:02] Iter 600; Sample 0, BCE = 0.3521363749851312; \n",
      "[13:44:02] Iter 700; Sample 0, BCE = 0.3522062848051817; \n",
      "[13:44:03] Early stopping at iter 764, best iter 564, best_score 0.35209304653232004\n",
      "[13:44:03] Stdout logging level is INFO.\n",
      "[13:44:03] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:03] Iter 0; Sample 0, BCE = 0.3794187129829966; \n",
      "[13:44:03] Iter 100; Sample 0, BCE = 0.355022769247797; \n",
      "[13:44:04] Iter 200; Sample 0, BCE = 0.35280079320186547; \n",
      "[13:44:04] Iter 300; Sample 0, BCE = 0.35229527553838547; \n",
      "[13:44:04] Iter 400; Sample 0, BCE = 0.35214501469357873; \n",
      "[13:44:05] Iter 500; Sample 0, BCE = 0.35210073428339056; \n",
      "[13:44:05] Iter 600; Sample 0, BCE = 0.3521194138911395; \n",
      "[13:44:05] Early stopping at iter 675, best iter 475, best_score 0.35208150853651754\n",
      "[13:44:05] Stdout logging level is INFO.\n",
      "[13:44:05] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:05] Iter 0; Sample 0, BCE = 0.3794234039784954; \n",
      "[13:44:06] Iter 100; Sample 0, BCE = 0.3550781007334286; \n",
      "[13:44:06] Iter 200; Sample 0, BCE = 0.3528063571755263; \n",
      "[13:44:06] Iter 300; Sample 0, BCE = 0.3523123917916243; \n",
      "[13:44:07] Iter 400; Sample 0, BCE = 0.3521694934312166; \n",
      "[13:44:07] Iter 500; Sample 0, BCE = 0.3521445815135216; \n",
      "[13:44:07] Iter 600; Sample 0, BCE = 0.3521618189323101; \n",
      "[13:44:08] Early stopping at iter 658, best iter 458, best_score 0.352121843912551\n",
      "[13:44:08] Stdout logging level is INFO.\n",
      "[13:44:08] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:08] Iter 0; Sample 0, BCE = 0.3794421907897088; \n",
      "[13:44:08] Iter 100; Sample 0, BCE = 0.35530236482673105; \n",
      "[13:44:08] Iter 200; Sample 0, BCE = 0.3529360346503256; \n",
      "[13:44:09] Iter 300; Sample 0, BCE = 0.3523916151827718; \n",
      "[13:44:09] Iter 400; Sample 0, BCE = 0.3522146481610434; \n",
      "[13:44:09] Iter 500; Sample 0, BCE = 0.35216778809139654; \n",
      "[13:44:10] Iter 600; Sample 0, BCE = 0.35216847473756824; \n",
      "[13:44:10] Iter 700; Sample 0, BCE = 0.35221340631047626; \n",
      "[13:44:10] Early stopping at iter 730, best iter 530, best_score 0.3521492478653506\n",
      "[13:44:11] Stdout logging level is INFO.\n",
      "[13:44:11] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:11] Iter 0; Sample 0, BCE = 0.37942113922705645; \n",
      "[13:44:11] Iter 100; Sample 0, BCE = 0.35506902849869704; \n",
      "[13:44:11] Iter 200; Sample 0, BCE = 0.35279243877521893; \n",
      "[13:44:12] Iter 300; Sample 0, BCE = 0.35229964228482774; \n",
      "[13:44:12] Iter 400; Sample 0, BCE = 0.3521625698080408; \n",
      "[13:44:12] Iter 500; Sample 0, BCE = 0.3521380366268916; \n",
      "[13:44:13] Iter 600; Sample 0, BCE = 0.3521545706533924; \n",
      "[13:44:13] Early stopping at iter 658, best iter 458, best_score 0.3521203547096246\n",
      "[13:44:13] Stdout logging level is INFO.\n",
      "[13:44:13] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:13] Iter 0; Sample 0, BCE = 0.37939137620660474; \n",
      "[13:44:13] Iter 100; Sample 0, BCE = 0.35483863278533345; \n",
      "[13:44:14] Iter 200; Sample 0, BCE = 0.352723617029639; \n",
      "[13:44:14] Iter 300; Sample 0, BCE = 0.352310424098699; \n",
      "[13:44:14] Iter 400; Sample 0, BCE = 0.3522099998335103; \n",
      "[13:44:15] Iter 500; Sample 0, BCE = 0.3522529062686228; \n",
      "[13:44:15] Early stopping at iter 569, best iter 369, best_score 0.35219818567245686\n",
      "[13:44:15] Stdout logging level is INFO.\n",
      "[13:44:15] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:15] Iter 0; Sample 0, BCE = 0.3793286570868212; \n",
      "[13:44:16] Iter 100; Sample 0, BCE = 0.3544574460061988; \n",
      "[13:44:16] Iter 200; Sample 0, BCE = 0.3530060123991719; \n",
      "[13:44:17] Iter 300; Sample 0, BCE = 0.35288890729945144; \n",
      "[13:44:18] Iter 400; Sample 0, BCE = 0.35307477219687433; \n",
      "[13:44:18] Early stopping at iter 459, best iter 259, best_score 0.35287231243248385\n",
      "[13:44:18] Stdout logging level is INFO.\n",
      "[13:44:18] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:18] Iter 0; Sample 0, BCE = 0.37929237439272506; \n",
      "[13:44:18] Iter 100; Sample 0, BCE = 0.35377096963922505; \n",
      "[13:44:19] Iter 200; Sample 0, BCE = 0.3524328869401263; \n",
      "[13:44:19] Iter 300; Sample 0, BCE = 0.3524174388105579; \n",
      "[13:44:20] Iter 400; Sample 0, BCE = 0.35255581057238516; \n",
      "[13:44:20] Early stopping at iter 459, best iter 259, best_score 0.35236773483895556\n",
      "[13:44:20] Stdout logging level is INFO.\n",
      "[13:44:20] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:20] Iter 0; Sample 0, BCE = 0.37938887482290584; \n",
      "[13:44:20] Iter 100; Sample 0, BCE = 0.3547951225875666; \n",
      "[13:44:21] Iter 200; Sample 0, BCE = 0.352767818470949; \n",
      "[13:44:21] Iter 300; Sample 0, BCE = 0.35238798861886567; \n",
      "[13:44:21] Iter 400; Sample 0, BCE = 0.352285986878794; \n",
      "[13:44:22] Iter 500; Sample 0, BCE = 0.35235128705468954; \n",
      "[13:44:22] Early stopping at iter 570, best iter 370, best_score 0.3522761460711878\n",
      "[13:44:22] Stdout logging level is INFO.\n",
      "[13:44:22] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:22] Iter 0; Sample 0, BCE = 0.37939280362056316; \n",
      "[13:44:23] Iter 100; Sample 0, BCE = 0.3548341476400226; \n",
      "[13:44:23] Iter 200; Sample 0, BCE = 0.35270105479038233; \n",
      "[13:44:23] Iter 300; Sample 0, BCE = 0.3522909525790569; \n",
      "[13:44:24] Iter 400; Sample 0, BCE = 0.3521737967392259; \n",
      "[13:44:24] Iter 500; Sample 0, BCE = 0.3522262410493858; \n",
      "[13:44:24] Iter 600; Sample 0, BCE = 0.3522801250274265; \n",
      "[13:44:24] Early stopping at iter 622, best iter 422, best_score 0.35216756169069446\n",
      "[13:44:25] Stdout logging level is INFO.\n",
      "[13:44:25] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:25] Iter 0; Sample 0, BCE = 0.3794099435392279; \n",
      "[13:44:25] Iter 100; Sample 0, BCE = 0.3548613747329183; \n",
      "[13:44:25] Iter 200; Sample 0, BCE = 0.3527300755369075; \n",
      "[13:44:26] Iter 300; Sample 0, BCE = 0.35229223798819453; \n",
      "[13:44:26] Iter 400; Sample 0, BCE = 0.35218023763669265; \n",
      "[13:44:26] Iter 500; Sample 0, BCE = 0.3521704338021775; \n",
      "[13:44:27] Iter 600; Sample 0, BCE = 0.35221979220329813; \n",
      "[13:44:27] Early stopping at iter 675, best iter 475, best_score 0.3521445876305007\n",
      "[13:44:27] Stdout logging level is INFO.\n",
      "[13:44:27] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:27] Iter 0; Sample 0, BCE = 0.37941174962561236; \n",
      "[13:44:27] Iter 100; Sample 0, BCE = 0.3549035272496153; \n",
      "[13:44:28] Iter 200; Sample 0, BCE = 0.35275407505963446; \n",
      "[13:44:28] Iter 300; Sample 0, BCE = 0.3522900576301432; \n",
      "[13:44:28] Iter 400; Sample 0, BCE = 0.35215792369408355; \n",
      "[13:44:29] Iter 500; Sample 0, BCE = 0.3521410657787602; \n",
      "[13:44:29] Iter 600; Sample 0, BCE = 0.3521995356473941; \n",
      "[13:44:29] Early stopping at iter 670, best iter 470, best_score 0.3521201470898511\n",
      "[13:44:29] Stdout logging level is INFO.\n",
      "[13:44:29] GDBT train starts. Max iter 3000, early stopping rounds 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:30] Iter 0; Sample 0, BCE = 0.3794238176556505; \n",
      "[13:44:30] Iter 100; Sample 0, BCE = 0.3550975330516116; \n",
      "[13:44:30] Iter 200; Sample 0, BCE = 0.3528039307834386; \n",
      "[13:44:30] Iter 300; Sample 0, BCE = 0.35230134154291065; \n",
      "[13:44:31] Iter 400; Sample 0, BCE = 0.35216306705533745; \n",
      "[13:44:31] Iter 500; Sample 0, BCE = 0.35215303947576815; \n",
      "[13:44:31] Iter 600; Sample 0, BCE = 0.3521586973684932; \n",
      "[13:44:32] Iter 700; Sample 0, BCE = 0.3522116982135713; \n",
      "[13:44:32] Early stopping at iter 737, best iter 537, best_score 0.3521303048187547\n",
      "[13:44:32] Stdout logging level is INFO.\n",
      "[13:44:32] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:32] Iter 0; Sample 0, BCE = 0.37941491379394154; \n",
      "[13:44:33] Iter 100; Sample 0, BCE = 0.3549531110061637; \n",
      "[13:44:33] Iter 200; Sample 0, BCE = 0.35275457900511287; \n",
      "[13:44:33] Iter 300; Sample 0, BCE = 0.3523125425546641; \n",
      "[13:44:34] Iter 400; Sample 0, BCE = 0.3521672000912071; \n",
      "[13:44:34] Iter 500; Sample 0, BCE = 0.35214057512043984; \n",
      "[13:44:34] Iter 600; Sample 0, BCE = 0.35217589178451275; \n",
      "[13:44:35] Iter 700; Sample 0, BCE = 0.35223390323515674; \n",
      "[13:44:35] Early stopping at iter 735, best iter 535, best_score 0.3521230184587678\n",
      "[13:44:35] Stdout logging level is INFO.\n",
      "[13:44:35] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:35] Iter 0; Sample 0, BCE = 0.37944114025409853; \n",
      "[13:44:35] Iter 100; Sample 0, BCE = 0.3552869303934557; \n",
      "[13:44:36] Iter 200; Sample 0, BCE = 0.352910283167391; \n",
      "[13:44:36] Iter 300; Sample 0, BCE = 0.3523944364424517; \n",
      "[13:44:36] Iter 400; Sample 0, BCE = 0.3522150061808699; \n",
      "[13:44:37] Iter 500; Sample 0, BCE = 0.3521744191599086; \n",
      "[13:44:37] Iter 600; Sample 0, BCE = 0.35218389835578495; \n",
      "[13:44:37] Iter 700; Sample 0, BCE = 0.35222430615341915; \n",
      "[13:44:37] Early stopping at iter 730, best iter 530, best_score 0.3521467554845033\n",
      "[13:44:38] Stdout logging level is INFO.\n",
      "[13:44:38] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:38] Iter 0; Sample 0, BCE = 0.3794190315209118; \n",
      "[13:44:38] Iter 100; Sample 0, BCE = 0.3550255279533274; \n",
      "[13:44:38] Iter 200; Sample 0, BCE = 0.35279147672093814; \n",
      "[13:44:39] Iter 300; Sample 0, BCE = 0.3523038224871088; \n",
      "[13:44:39] Iter 400; Sample 0, BCE = 0.3521441374443784; \n",
      "[13:44:39] Iter 500; Sample 0, BCE = 0.3521130266472485; \n",
      "[13:44:40] Iter 600; Sample 0, BCE = 0.35213090967084926; \n",
      "[13:44:40] Iter 700; Sample 0, BCE = 0.3521897042890713; \n",
      "[13:44:40] Early stopping at iter 759, best iter 559, best_score 0.3520831262735573\n",
      "[13:44:41] Stdout logging level is INFO.\n",
      "[13:44:41] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:41] Iter 0; Sample 0, BCE = 0.3794163998894186; \n",
      "[13:44:41] Iter 100; Sample 0, BCE = 0.3549735404128736; \n",
      "[13:44:41] Iter 200; Sample 0, BCE = 0.35276219868771214; \n",
      "[13:44:42] Iter 300; Sample 0, BCE = 0.3523085742989648; \n",
      "[13:44:42] Iter 400; Sample 0, BCE = 0.3521555462435515; \n",
      "[13:44:42] Iter 500; Sample 0, BCE = 0.35213093673744256; \n",
      "[13:44:43] Iter 600; Sample 0, BCE = 0.35215778624421495; \n",
      "[13:44:43] Early stopping at iter 675, best iter 475, best_score 0.3521016922024016\n",
      "[13:44:43] Stdout logging level is INFO.\n",
      "[13:44:43] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:43] Iter 0; Sample 0, BCE = 0.3793907270786234; \n",
      "[13:44:43] Iter 100; Sample 0, BCE = 0.35483964951865543; \n",
      "[13:44:44] Iter 200; Sample 0, BCE = 0.35275634814570694; \n",
      "[13:44:44] Iter 300; Sample 0, BCE = 0.35235669792477725; \n",
      "[13:44:44] Iter 400; Sample 0, BCE = 0.35223284916546754; \n",
      "[13:44:45] Iter 500; Sample 0, BCE = 0.352268995827541; \n",
      "[13:44:45] Iter 600; Sample 0, BCE = 0.3523411176072362; \n",
      "[13:44:45] Early stopping at iter 626, best iter 426, best_score 0.35222419393082693\n",
      "[13:44:45] Stdout logging level is INFO.\n",
      "[13:44:45] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:45] Iter 0; Sample 0, BCE = 0.37939285268751516; \n",
      "[13:44:46] Iter 100; Sample 0, BCE = 0.35451838446788464; \n",
      "[13:44:46] Iter 200; Sample 0, BCE = 0.35268732512286827; \n",
      "[13:44:47] Iter 300; Sample 0, BCE = 0.3523609324000918; \n",
      "[13:44:47] Iter 400; Sample 0, BCE = 0.3523120510714767; \n",
      "[13:44:47] Iter 500; Sample 0, BCE = 0.35237531784800663; \n",
      "[13:44:48] Early stopping at iter 572, best iter 372, best_score 0.35227775764167324\n",
      "[13:44:48] Stdout logging level is INFO.\n",
      "[13:44:48] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:48] Iter 0; Sample 0, BCE = 0.3794301493345754; \n",
      "[13:44:48] Iter 100; Sample 0, BCE = 0.3552039826186256; \n",
      "[13:44:49] Iter 200; Sample 0, BCE = 0.3528819802478411; \n",
      "[13:44:49] Iter 300; Sample 0, BCE = 0.3523728467004969; \n",
      "[13:44:49] Iter 400; Sample 0, BCE = 0.3522136538355393; \n",
      "[13:44:50] Iter 500; Sample 0, BCE = 0.35216587547774614; \n",
      "[13:44:50] Iter 600; Sample 0, BCE = 0.35216619487787254; \n",
      "[13:44:51] Iter 700; Sample 0, BCE = 0.3522133247160147; \n",
      "[13:44:51] Early stopping at iter 732, best iter 532, best_score 0.3521354795936969\n",
      "[13:44:51] Stdout logging level is INFO.\n",
      "[13:44:51] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:51] Iter 0; Sample 0, BCE = 0.3794169337290515; \n",
      "[13:44:51] Iter 100; Sample 0, BCE = 0.35501378202236256; \n",
      "[13:44:52] Iter 200; Sample 0, BCE = 0.3527989160014052; \n",
      "[13:44:52] Iter 300; Sample 0, BCE = 0.35230472660693546; \n",
      "[13:44:52] Iter 400; Sample 0, BCE = 0.3521507859230091; \n",
      "[13:44:53] Iter 500; Sample 0, BCE = 0.3521313986654363; \n",
      "[13:44:53] Iter 600; Sample 0, BCE = 0.3521627643854165; \n",
      "[13:44:53] Early stopping at iter 658, best iter 458, best_score 0.3521008513717547\n",
      "[13:44:53] Stdout logging level is INFO.\n",
      "[13:44:53] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:53] Iter 0; Sample 0, BCE = 0.3794073382295528; \n",
      "[13:44:54] Iter 100; Sample 0, BCE = 0.3548866760253177; \n",
      "[13:44:54] Iter 200; Sample 0, BCE = 0.35274186312054073; \n",
      "[13:44:55] Iter 300; Sample 0, BCE = 0.35230797386261725; \n",
      "[13:44:55] Iter 400; Sample 0, BCE = 0.35219694061613516; \n",
      "[13:44:55] Iter 500; Sample 0, BCE = 0.3522169505004793; \n",
      "[13:44:56] Iter 600; Sample 0, BCE = 0.35224894904377974; \n",
      "[13:44:56] Early stopping at iter 671, best iter 471, best_score 0.352184879739371\n",
      "[13:44:56] Stdout logging level is INFO.\n",
      "[13:44:56] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:56] Iter 0; Sample 0, BCE = 0.3794146691950471; \n",
      "[13:44:57] Iter 100; Sample 0, BCE = 0.35496454752772283; \n",
      "[13:44:57] Iter 200; Sample 0, BCE = 0.3527747672340576; \n",
      "[13:44:57] Iter 300; Sample 0, BCE = 0.3523137007341887; \n",
      "[13:44:58] Iter 400; Sample 0, BCE = 0.35216550332693336; \n",
      "[13:44:58] Iter 500; Sample 0, BCE = 0.3521382311748905; \n",
      "[13:44:58] Iter 600; Sample 0, BCE = 0.3521772539528432; \n",
      "[13:44:59] Early stopping at iter 675, best iter 475, best_score 0.35211942790815337\n",
      "[13:44:59] Stdout logging level is INFO.\n",
      "[13:44:59] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:44:59] Iter 0; Sample 0, BCE = 0.3793887340724392; \n",
      "[13:44:59] Iter 100; Sample 0, BCE = 0.35478754915577576; \n",
      "[13:45:00] Iter 200; Sample 0, BCE = 0.35279432342345746; \n",
      "[13:45:00] Iter 300; Sample 0, BCE = 0.3524264483334094; \n",
      "[13:45:00] Iter 400; Sample 0, BCE = 0.3523021593646909; \n",
      "[13:45:01] Iter 500; Sample 0, BCE = 0.35234644058563497; \n",
      "[13:45:01] Iter 600; Sample 0, BCE = 0.35243974235046266; \n",
      "[13:45:01] Early stopping at iter 627, best iter 427, best_score 0.3522843967269665\n",
      "[13:45:01] Stdout logging level is INFO.\n",
      "[13:45:01] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:01] Iter 0; Sample 0, BCE = 0.3794282130638433; \n",
      "[13:45:02] Iter 100; Sample 0, BCE = 0.35517885686485084; \n",
      "[13:45:02] Iter 200; Sample 0, BCE = 0.35287111182018793; \n",
      "[13:45:02] Iter 300; Sample 0, BCE = 0.3523536688917088; \n",
      "[13:45:03] Iter 400; Sample 0, BCE = 0.3521865548495683; \n",
      "[13:45:03] Iter 500; Sample 0, BCE = 0.35215637664949423; \n",
      "[13:45:03] Iter 600; Sample 0, BCE = 0.3521534719555838; \n",
      "[13:45:04] Iter 700; Sample 0, BCE = 0.352217019920843; \n",
      "[13:45:04] Early stopping at iter 732, best iter 532, best_score 0.35213429199871865\n",
      "[13:45:04] Stdout logging level is INFO.\n",
      "[13:45:04] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:04] Iter 0; Sample 0, BCE = 0.37939219935327717; \n",
      "[13:45:04] Iter 100; Sample 0, BCE = 0.35482702708145697; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:05] Iter 200; Sample 0, BCE = 0.3527147865356635; \n",
      "[13:45:05] Iter 300; Sample 0, BCE = 0.3523112715593415; \n",
      "[13:45:05] Iter 400; Sample 0, BCE = 0.35218546423344427; \n",
      "[13:45:06] Iter 500; Sample 0, BCE = 0.35223649141389324; \n",
      "[13:45:06] Iter 600; Sample 0, BCE = 0.3522890981652396; \n",
      "[13:45:06] Early stopping at iter 622, best iter 422, best_score 0.35217644301577905\n",
      "[13:45:06] Stdout logging level is INFO.\n",
      "[13:45:06] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:06] Iter 0; Sample 0, BCE = 0.3794185703964684; \n",
      "[13:45:07] Iter 100; Sample 0, BCE = 0.3550140332560637; \n",
      "[13:45:07] Iter 200; Sample 0, BCE = 0.35277195705400044; \n",
      "[13:45:08] Iter 300; Sample 0, BCE = 0.35229863211829954; \n",
      "[13:45:08] Iter 400; Sample 0, BCE = 0.35213845971884994; \n",
      "[13:45:08] Iter 500; Sample 0, BCE = 0.35210977373578245; \n",
      "[13:45:09] Iter 600; Sample 0, BCE = 0.3521246705515924; \n",
      "[13:45:09] Iter 700; Sample 0, BCE = 0.3521950840180166; \n",
      "[13:45:09] Early stopping at iter 765, best iter 565, best_score 0.3520833568363129\n",
      "[13:45:09] Stdout logging level is INFO.\n",
      "[13:45:09] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:10] Iter 0; Sample 0, BCE = 0.37939026479213184; \n",
      "[13:45:10] Iter 100; Sample 0, BCE = 0.3547558554643488; \n",
      "[13:45:10] Iter 200; Sample 0, BCE = 0.35273796204974794; \n",
      "[13:45:11] Iter 300; Sample 0, BCE = 0.35230351908716223; \n",
      "[13:45:11] Iter 400; Sample 0, BCE = 0.35219909287757856; \n",
      "[13:45:11] Iter 500; Sample 0, BCE = 0.35225929441075293; \n",
      "[13:45:12] Early stopping at iter 569, best iter 369, best_score 0.35218689465479164\n",
      "[13:45:12] Stdout logging level is INFO.\n",
      "[13:45:12] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:12] Iter 0; Sample 0, BCE = 0.3792923629334728; \n",
      "[13:45:12] Iter 100; Sample 0, BCE = 0.35377876290389954; \n",
      "[13:45:13] Iter 200; Sample 0, BCE = 0.35243677407959423; \n",
      "[13:45:13] Iter 300; Sample 0, BCE = 0.3524407319981314; \n",
      "[13:45:14] Iter 400; Sample 0, BCE = 0.35256626397905044; \n",
      "[13:45:14] Early stopping at iter 477, best iter 277, best_score 0.352387894831453\n",
      "[13:45:14] Stdout logging level is INFO.\n",
      "[13:45:14] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:45:14] Iter 0; Sample 0, BCE = 0.37946045253748767; \n",
      "[13:45:15] Iter 100; Sample 0, BCE = 0.3557150434147419; \n",
      "[13:45:15] Iter 200; Sample 0, BCE = 0.35315166445952473; \n",
      "[13:45:16] Iter 300; Sample 0, BCE = 0.35251932909216194; \n",
      "[13:45:16] Iter 400; Sample 0, BCE = 0.3523025294355953; \n",
      "[13:45:16] Iter 500; Sample 0, BCE = 0.35221857517595473; \n",
      "[13:45:17] Iter 600; Sample 0, BCE = 0.35218972822131905; \n",
      "[13:45:17] Iter 700; Sample 0, BCE = 0.35219642560826575; \n",
      "[13:45:18] Iter 800; Sample 0, BCE = 0.35224975643524264; \n",
      "[13:45:18] Early stopping at iter 842, best iter 642, best_score 0.352168056044907\n",
      "[13:45:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m completed\n",
      "[13:45:18] The set of hyperparameters \u001b[1m{'max_depth': 3, 'lambda_l2': 2.0363365546397634, 'sketch_arg': 6}\u001b[0m\n",
      " achieve -7.3709 logloss\n",
      "[13:45:18] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m ...\n",
      "[13:45:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m (orig) =====\n",
      "[13:45:18] Stdout logging level is INFO.\n",
      "[13:45:18] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[13:45:18] Iter 0; Sample 0, BCE = 0.3787854076971528; \n",
      "[13:45:19] Iter 99; Sample 0, BCE = 0.35328565531486084; \n",
      "[13:45:19] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m (orig) =====\n",
      "[13:45:19] Stdout logging level is INFO.\n",
      "[13:45:19] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[13:45:19] Iter 0; Sample 0, BCE = 0.3717788747449127; \n",
      "[13:45:19] Iter 99; Sample 0, BCE = 0.34539059325877125; \n",
      "[13:45:20] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m (orig) =====\n",
      "[13:45:20] Stdout logging level is INFO.\n",
      "[13:45:20] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[13:45:20] Iter 0; Sample 0, BCE = 0.37544699759582967; \n",
      "[13:45:20] Iter 99; Sample 0, BCE = 0.34905379369288103; \n",
      "[13:45:20] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m finished. score = \u001b[1m-7.318311929629495\u001b[0m\n",
      "[13:45:20] \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_PB\u001b[0m fitting and predicting completed\n",
      "[13:45:20] Time left 3311.89 secs\n",
      "\n",
      "[13:45:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:45:20] Blending: Optimization starts with equal weights and score -7.315013298597436\n",
      "[13:45:20] Blending, iter 0: score = -7.314832725312598, weights = [0.6462316 0.3537684]\n",
      "[13:45:20] Blending, iter 1: score = -7.314832725312598, weights = [0.6462316 0.3537684]\n",
      "[13:45:20] No score update. Terminated\n",
      "[13:45:20] \u001b[1mAutoml preset training completed in 288.35 seconds\u001b[0m\n",
      "\n",
      "[13:45:20] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.64623 * (3 averaged models Lvl_0_Pipe_0_Mod_0_PB) +\n",
      "\t 0.35377 * (3 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_PB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad158c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7748506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularAutoMLGPU\n",
      "{'_binary': False, 'data_size': 15, 'categorical_idx': {'int': [12, 13, 14], 'str': ['le__n_0000', 'le__n_0003', 'inter__(n_0000__n_0003)']}, 'embed_sizes': array([ 2, 12, 12], dtype=int32), 'output_size': 14, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'max_iter': 100, 'tol': 1e-06, 'early_stopping': 2, 'loss': TorchLossWrapper(\n",
      "  (base_loss): BCELoss()\n",
      "), 'metric': <lightautoml.tasks.losses.base.MetricFunc object at 0x7f62a113f670>, 'model': CatMulticlass(\n",
      "  (linear): Linear(in_features=12, out_features=14, bias=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")}\n",
      "TorchBasedLogisticRegression\n",
      "{'_name': 'multilabel', 'device': 'gpu', 'losses': {'lgb': <lightautoml.tasks.losses.lgb.LGBLoss object at 0x7f62a0e673a0>, 'sklearn': <lightautoml.tasks.losses.sklearn.SKLoss object at 0x7f62a0e67190>, 'torch': <lightautoml.tasks.losses.torch.TORCHLoss object at 0x7f62a113f040>, 'cb': <lightautoml.tasks.losses.cb.CBLoss object at 0x7f62a113fe80>, 'torch_gpu': <lightautoml.tasks.losses.gpu.torch_gpu.TORCHLossGPU object at 0x7f62a113ffa0>, 'cuml': <lightautoml.tasks.losses.gpu.cuml.CUMLLoss object at 0x7f62a113f850>, 'xgb': <lightautoml.tasks.losses.gpu.xgb_gpu.XGBLoss object at 0x7f62a113fbe0>, 'pb': <lightautoml.tasks.losses.gpu.pb_gpu.PBLoss object at 0x7f62a113f160>}, 'metric_params': {}, 'metric_func': functools.partial(<function log_loss_gpu at 0x7f6322deadc0>, eps=1e-07), 'metric_name': 'logloss', 'greater_is_better': False}\n",
      "multilabel isn`t supported in lgb\n",
      "[15:35:22] CatBoost uses as obj. MultiCrossEntropy.\n",
      "cpu\n",
      "PB: {'task': <lightautoml.tasks.base.Task object at 0x7f62a0e675b0>, 'optimization_search_space': {}, 'freeze_defaults': False, 'default_params': {'ntrees': 100, 'lr': 0.05, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 100, 'seed': 42, 'verbose': 10}, 'models': [<py_boost.gpu.boosting.GradientBoosting object at 0x7f62a05b0910>, <py_boost.gpu.boosting.GradientBoosting object at 0x7f62a0285760>, <py_boost.gpu.boosting.GradientBoosting object at 0x7f647d021220>], '_features': ['inter__(n_0000__n_0003)', 'n_0001', 'n_0002', 'n_0004', 'n_0005', 'n_0006', 'n_0007', 'ord__n_0000', 'ord__n_0003'], 'timer': <lightautoml.utils.timer.TaskTimer object at 0x7f62a1112190>, '_nan_rate': None, 'gpu_ids': None, 'parallel_folds': False, '_name': 'Lvl_0_Pipe_1_Mod_0_PB', '_params': {'ntrees': 3000, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 200, 'seed': 42, 'verbose': 10}, 'n_classes': 14}\n",
      "PB model type: GradientBoosting\n",
      "PB model: {'models': [<py_boost.gpu.tree.Tree object at 0x7f62a65300d0>, <py_boost.gpu.tree.Tree object at 0x7f62a01d4040>, <py_boost.gpu.tree.Tree object at 0x7f647d18ecd0>, <py_boost.gpu.tree.Tree object at 0x7f647d18e550>, <py_boost.gpu.tree.Tree object at 0x7f647d18ed90>, <py_boost.gpu.tree.Tree object at 0x7f647d18ee80>, <py_boost.gpu.tree.Tree object at 0x7f647d18efd0>, <py_boost.gpu.tree.Tree object at 0x7f647d18ef70>, <py_boost.gpu.tree.Tree object at 0x7f647d18ec40>, <py_boost.gpu.tree.Tree object at 0x7f647d18e490>, <py_boost.gpu.tree.Tree object at 0x7f647d18e5e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0670>, <py_boost.gpu.tree.Tree object at 0x7f647d33f3a0>, <py_boost.gpu.tree.Tree object at 0x7f647d266df0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0310>, <py_boost.gpu.tree.Tree object at 0x7f647d1a06d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0820>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0640>, <py_boost.gpu.tree.Tree object at 0x7f647d1a0370>, <py_boost.gpu.tree.Tree object at 0x7f62a0285370>, <py_boost.gpu.tree.Tree object at 0x7f62a02853d0>, <py_boost.gpu.tree.Tree object at 0x7f62a0285d00>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1a00>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1f40>, <py_boost.gpu.tree.Tree object at 0x7f62a01f17f0>, <py_boost.gpu.tree.Tree object at 0x7f62a01f17c0>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1e20>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1f70>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1700>, <py_boost.gpu.tree.Tree object at 0x7f62a01f1b80>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcbb0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcac0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc8e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcb80>, <py_boost.gpu.tree.Tree object at 0x7f647d1bca90>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc850>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcc10>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcf40>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcf10>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcca0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcee0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc910>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc790>, <py_boost.gpu.tree.Tree object at 0x7f647d1bceb0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc2e0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc9d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcfd0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc0d0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc4f0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc580>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc1c0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc340>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcd30>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc280>, <py_boost.gpu.tree.Tree object at 0x7f647d17a0a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc9a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc2b0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc6a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1bcd60>, <py_boost.gpu.tree.Tree object at 0x7f647d1bc940>, <py_boost.gpu.tree.Tree object at 0x7f647d17cb80>, <py_boost.gpu.tree.Tree object at 0x7f647d17cee0>, <py_boost.gpu.tree.Tree object at 0x7f647d17cf10>, <py_boost.gpu.tree.Tree object at 0x7f647d17cf70>, <py_boost.gpu.tree.Tree object at 0x7f647d17c850>, <py_boost.gpu.tree.Tree object at 0x7f647d17c8e0>, <py_boost.gpu.tree.Tree object at 0x7f647d17cbe0>, <py_boost.gpu.tree.Tree object at 0x7f647d175790>, <py_boost.gpu.tree.Tree object at 0x7f647d175700>, <py_boost.gpu.tree.Tree object at 0x7f647d173e50>, <py_boost.gpu.tree.Tree object at 0x7f647d173340>, <py_boost.gpu.tree.Tree object at 0x7f647d173ee0>, <py_boost.gpu.tree.Tree object at 0x7f62a05aff10>, <py_boost.gpu.tree.Tree object at 0x7f62a05aff40>, <py_boost.gpu.tree.Tree object at 0x7f62a05b2970>, <py_boost.gpu.tree.Tree object at 0x7f62a05b26d0>, <py_boost.gpu.tree.Tree object at 0x7f647d173df0>, <py_boost.gpu.tree.Tree object at 0x7f647d173670>, <py_boost.gpu.tree.Tree object at 0x7f647d173370>, <py_boost.gpu.tree.Tree object at 0x7f647d170a30>, <py_boost.gpu.tree.Tree object at 0x7f647d170ac0>, <py_boost.gpu.tree.Tree object at 0x7f647d170370>, <py_boost.gpu.tree.Tree object at 0x7f647d1709a0>, <py_boost.gpu.tree.Tree object at 0x7f647d1701c0>, <py_boost.gpu.tree.Tree object at 0x7f647d1709d0>, <py_boost.gpu.tree.Tree object at 0x7f647d170250>, <py_boost.gpu.tree.Tree object at 0x7f647d170580>, <py_boost.gpu.tree.Tree object at 0x7f647d17e1c0>, <py_boost.gpu.tree.Tree object at 0x7f647d17ebe0>, <py_boost.gpu.tree.Tree object at 0x7f647d17eac0>, <py_boost.gpu.tree.Tree object at 0x7f647d17eb20>, <py_boost.gpu.tree.Tree object at 0x7f647d17e190>, <py_boost.gpu.tree.Tree object at 0x7f647d17e700>, <py_boost.gpu.tree.Tree object at 0x7f647d17e520>, <py_boost.gpu.tree.Tree object at 0x7f647d17e670>, <py_boost.gpu.tree.Tree object at 0x7f647d17e790>, <py_boost.gpu.tree.Tree object at 0x7f647d17e6a0>, <py_boost.gpu.tree.Tree object at 0x7f647d17e070>, <py_boost.gpu.tree.Tree object at 0x7f647d17e0d0>, <py_boost.gpu.tree.Tree object at 0x7f647d17e640>], 'nfeats': 9, 'postprocess_fn': <bound method BCELoss.postprocess_output of <py_boost.gpu.losses.losses.BCELoss object at 0x7f62a0a8cbe0>>, 'base_score': array([ 1.2744273 , -0.88346356, -4.1533837 , -2.9211771 , -0.7037684 ,\n",
      "       -2.1483364 , -2.8961174 , -3.5005257 , -4.194554  , -1.5248097 ,\n",
      "        1.7412851 , -1.0348811 , -0.10745831, -2.3499177 ], dtype=float32), '_on_device': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'params': {'loss': 'logloss', 'metric': None, 'ntrees': 100, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'colsample': 1.0, 'subsample': 1.0, 'target_splitter': 'Single', 'multioutput_sketch': <py_boost.multioutput.sketching.RandomProjectionSketch object at 0x7f62a05b0640>, 'use_hess': True, 'quantization': 'Quantile', 'quant_sample': 2000000, 'max_bin': 256, 'min_data_in_bin': 3, 'es': 100, 'seed': 42, 'verbose': 100, 'callbacks': None}, 'ntrees': 100, 'lr': 0.035, 'min_gain_to_split': 0, 'lambda_l2': 1, 'gd_steps': 1, 'max_depth': 6, 'min_data_in_leaf': 10, 'use_hess': True, 'colsample': <py_boost.sampling.bagging.BaseSampler object at 0x7f62a05b00d0>, 'subsample': <py_boost.sampling.bagging.BaseSampler object at 0x7f62a057a100>, 'target_splitter': <py_boost.multioutput.target_splitter.SingleSplitter object at 0x7f62a057a040>, 'multioutput_sketch': <py_boost.multioutput.sketching.RandomProjectionSketch object at 0x7f62a05b0640>, 'es': 100, 'verbose': 100, 'loss': <py_boost.gpu.losses.losses.BCELoss object at 0x7f62a0a8cbe0>, 'metric': <py_boost.gpu.losses.metrics.BCEMetric object at 0x7f62a0576df0>, 'seed': 42, 'history': [[0.3791767522991384], [0.3778416120752246], [0.3762674118738236], [0.37514040717926267], [0.37416972910751045], [0.37321100253399625], [0.37204776209683177], [0.37124094911654487], [0.37041730463987543], [0.36978657801783166], [0.36892871863965426], [0.3680218382829175], [0.36722533037437743], [0.36653690507570086], [0.3659066383129189], [0.3651784657803058], [0.3645622214007063], [0.36408055783859966], [0.36351199715648574], [0.36301823044411013], [0.36246650380450207], [0.36208665737738055], [0.36170642099751377], [0.36124463456873107], [0.36088624389267765], [0.3605031153441547], [0.36017062322123616], [0.3598390672032548], [0.35949904860956117], [0.35924612959789476], [0.3589941399965245], [0.3587827823000444], [0.35852464714127996], [0.35830522637873685], [0.358087019871591], [0.3578593743364027], [0.35762406422313664], [0.35745768869813327], [0.3573011911694761], [0.3570795397969606], [0.35695875008929473], [0.35678372184820356], [0.35656185976580806], [0.3563773658716894], [0.3562291636750396], [0.3560540624957311], [0.3559737730648791], [0.35580729604079725], [0.3556632508605666], [0.35558251276525693], [0.3554693948953833], [0.3553672590520818], [0.35527167498912726], [0.3551784769430135], [0.3550456225527433], [0.35496720828514433], [0.3548836755350177], [0.3547905032234891], [0.3547267937118343], [0.3546829252843606], [0.3546157485234878], [0.3545751889228638], [0.35445996529998314], [0.3543893989541639], [0.35434003067485736], [0.3542782006045622], [0.3542461649025937], [0.35420695658697765], [0.3541381623806585], [0.35408436256315684], [0.3540361107599926], [0.3539656358261486], [0.3539428939023407], [0.35389726906457364], [0.35388151780846705], [0.3538530697691564], [0.35383322607822826], [0.35380162338178434], [0.35377454748022386], [0.3537380815753694], [0.3536971916197887], [0.35364178332508683], [0.3536282761422021], [0.35359999721650864], [0.3535571494795898], [0.35352073745278095], [0.3534704647587743], [0.3534277953264103], [0.3534133832027478], [0.353377778464938], [0.35334014404965125], [0.35333011331372666], [0.35330182346342004], [0.3532637754343206], [0.35326911671001004], [0.35326739974841986], [0.3532416904374764], [0.3532250495275617], [0.3532018709334216], [0.35317920625777316]], 'callbacks': <py_boost.callbacks.callback.CallbackPipeline object at 0x7f62a05762b0>, 'best_round': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109bf25283a404fa5f861be42cf1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d05adae4414910a81142d53d7fd3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3243fcbb9c24b3ca0a0aa72c284479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[15:35:24] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "cpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70394263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 21513. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-11-30 15:35:26,754 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-wf7z6oqf', purging\n",
      "2022-11-30 15:35:26,754 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-11-30 15:35:26,754 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:60617': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[15:35:27] CatBoost uses as obj. MultiCrossEntropy.\n",
      "[15:35:27] Stdout logging level is INFO2.\n",
      "[15:35:27] Task: multilabel\n",
      "\n",
      "[15:35:27] Start automl preset with listed constraints:\n",
      "[15:35:27] - time: 3600.00 seconds\n",
      "[15:35:27] - CPU: 1 cores\n",
      "[15:35:27] - memory: 16 GB\n",
      "\n",
      "[15:35:27] Train data shape: (14644, 22)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[15:35:29] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.23 secs\n",
      "[15:35:29] Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "[15:35:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.597461223602295\n",
      "Score: -7.577960014343262\n",
      "Score: -7.561263084411621\n",
      "Score: -7.507802963256836\n",
      "Score: -7.484713554382324\n",
      "Score: -7.434474468231201\n",
      "Score: -7.434474468231201\n",
      "Score: -7.409946441650391\n",
      "Score: -7.409946441650391\n",
      "Score: -7.409946441650391\n",
      "[15:35:33] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.4780988693237305\n",
      "Score: -7.458440780639648\n",
      "Score: -7.44199275970459\n",
      "Score: -7.3888373374938965\n",
      "Score: -7.365793228149414\n",
      "Score: -7.317152976989746\n",
      "Score: -7.317152976989746\n",
      "Score: -7.292194843292236\n",
      "Score: -7.292194843292236\n",
      "Score: -7.292194843292236\n",
      "[15:35:39] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "Score: -7.512928009033203\n",
      "Score: -7.495559215545654\n",
      "Score: -7.4844279289245605\n",
      "Score: -7.463672161102295\n",
      "Score: -7.457089900970459\n",
      "Score: -7.435981750488281\n",
      "Score: -7.431396007537842\n",
      "Score: -7.425570964813232\n",
      "Score: -7.425786972045898\n",
      "Score: -7.425788402557373\n",
      "[15:35:46] Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "[15:35:46] Time left 3581.28 secs\n",
      "\n",
      "[15:35:46] Start fitting Selector_XGB ...\n",
      "[15:35:46] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mSelector_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:35:50] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:15] Selector_XGB fitting and predicting completed\n",
      "[15:36:15] Start fitting Lvl_0_Pipe_1_Mod_0_XGB ...\n",
      "[15:36:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:36:16] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:36:43] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[15:37:11] task [xgboost.dask-0]:ucx://127.0.0.1:60617 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:39] Lvl_0_Pipe_1_Mod_0_XGB fitting and predicting completed\n",
      "[15:37:39] Time left 3467.91 secs\n",
      "\n",
      "[15:37:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:37:39] Blending: Optimization starts with equal weights and score -7.369040055931575\n",
      "[15:37:39] Blending, iter 0: score = -7.332288272275898, weights = [0.90295106 0.09704894]\n",
      "[15:37:39] Blending, iter 1: score = -7.332288272275898, weights = [0.90295106 0.09704894]\n",
      "[15:37:39] No score update. Terminated\n",
      "[15:37:39] \u001b[1mAutoml preset training completed in 132.30 seconds\u001b[0m\n",
      "\n",
      "[15:37:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.90295 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09705 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5572413  0.5140602  0.554345   ... 0.32615978 0.55932724 0.5283271 ]\n",
      " [0.10613684 0.15360174 0.10628839 ... 0.24034458 0.10660344 0.13533857]\n",
      " [0.01066768 0.01306654 0.01075604 ... 0.00172346 0.01067023 0.00936168]\n",
      " ...\n",
      " [0.0912509  0.11758646 0.09017038 ... 0.2209489  0.08924023 0.12009337]\n",
      " [0.18382518 0.22122423 0.17709294 ... 0.3786014  0.16766214 0.22966513]\n",
      " [0.02809653 0.04665985 0.02616439 ... 0.04066981 0.02415165 0.05030812]]\n",
      "\n",
      "[[0.56842893 0.5196632  0.5663695  ... 0.32545125 0.5775144  0.5322845 ]\n",
      " [0.10147692 0.16129875 0.10777053 ... 0.24136236 0.10288282 0.12789753]\n",
      " [0.01173552 0.01505887 0.01187614 ... 0.00313549 0.00997119 0.00903109]\n",
      " ...\n",
      " [0.09023867 0.1269161  0.08745717 ... 0.24356261 0.07901268 0.11170406]\n",
      " [0.18878452 0.23331442 0.17551136 ... 0.39841276 0.15086576 0.21826142]\n",
      " [0.0252515  0.05333086 0.02523747 ... 0.04038102 0.01980539 0.04349071]]\n",
      "\n",
      "[[0.5664643  0.5166605  0.5704907  ... 0.33915734 0.57409036 0.5306796 ]\n",
      " [0.09986173 0.16810127 0.10628133 ... 0.20926563 0.10062604 0.12780127]\n",
      " [0.01196821 0.01398394 0.01322161 ... 0.00280323 0.01032557 0.01050191]\n",
      " ...\n",
      " [0.09180846 0.13396505 0.09454171 ... 0.2606958  0.07511169 0.12074684]\n",
      " [0.18628407 0.22799858 0.17925116 ... 0.41266233 0.1433349  0.23176786]\n",
      " [0.02698906 0.04811605 0.02420964 ... 0.03835659 0.0200704  0.04737411]]\n",
      "\n",
      "[[0.5566101  0.5167476  0.5587     ... 0.3180616  0.55953795 0.52395034]\n",
      " [0.10735844 0.14981753 0.10365902 ... 0.24246103 0.10839043 0.13269033]\n",
      " [0.01044928 0.01220986 0.0094422  ... 0.00169395 0.01090351 0.01022525]\n",
      " ...\n",
      " [0.09026912 0.11811364 0.08929776 ... 0.20285338 0.087581   0.12475552]\n",
      " [0.18097366 0.2176568  0.17152062 ... 0.37750742 0.16242473 0.23077025]\n",
      " [0.02716871 0.0458691  0.02571099 ... 0.03726    0.021709   0.04831092]]\n",
      "\n",
      "[[0.38230485 0.33360735 0.37970474 ... 0.18429603 0.39537454 0.35456634]\n",
      " [0.06503995 0.09911688 0.07147714 ... 0.12759788 0.0726622  0.0630847 ]\n",
      " [0.00721015 0.00751541 0.00580979 ... 0.00213916 0.0090256  0.00684993]\n",
      " ...\n",
      " [0.05489378 0.07309221 0.06428277 ... 0.14156312 0.04322646 0.06683876]\n",
      " [0.1101869  0.13309942 0.10156783 ... 0.23032379 0.09343332 0.1422773 ]\n",
      " [0.01629821 0.0290544  0.0159301  ... 0.01993656 0.01690265 0.03529549]]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(oof_pred_mgpu.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml_gpu.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml_gpu.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml_gpu.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml_gpu.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml_gpu.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml_gpu.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daa935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5476/705777730.py:1: DtypeWarning: Columns (329,331,333,336,338,344,345,346,348,354,355,356,357,358,361,362,364,367,372,377,380,383,385,387,390,392,399,400,406,408,409,413,416,418,419,431,433,437,438,442,448,449,450,453,457,464,473,478,479,481,483,485,486,489,492,495,496,497,498,499,500,503,507,508,510,511,514,515,517,519,520,521,522,523,524,526,527,530,534,537,538,539,541,544,547,548,549,550,551,557,558,560,564,569,572,573,576,577,579,583,596,597,598,600,601,602,604,605,606,608,609,613,619,620,625,627,628,629,631,632,633,636,641,642,643,645,646,647,648,651,655,661,662,665,668,675,676,679,682,685,687,689,690,691,694,698,701,702,703,706,711,712,713,719,720,721,733,735,737,738,742,746,747,748,749,752,754,755,760,764,768,770,781,782,789,797,807,812,814,817,818,822,823,824,825,832,840,843,844,845,850,853,857,858,861,867,868,873,874,876,877,879,880,881,883,886,890,893,897,899,900,901,902,904,905,908,909,910,912,913,914,915,916,922,923,931,933,935,937,939,942,943,946,951,955,960,964,965,968,969,970,973,974,977,980,987,994,995,996,999,1000,1008,1014,1015,1016,1017,1020,1021,1023,1028,1031,1035,1036,1037,1039,1040,1043,1048,1051,1055,1058,1059,1072,1073,1074,1081,1090,1097,1098,1103,1104,1109,1112,1113,1114,1118,1120,1130,1134,1135,1139,1140,1147,1148,1149,1152,1154,1157,1158,1162,1163,1164,1166,1169,1174,1177,1180,1181,1182,1183,1185,1188,1189,1195,1197,1198,1200,1203,1208,1210,1212,1215,1217,1220,1222,1225,1229,1230,1233,1234,1241,1243,1246,1250,1251,1252,1254,1259,1262,1263,1265,1266,1269,1270,1273,1274,1276,1277,1279,1280,1282,1284,1285,1286,1289,1291,1292,1293,1294,1295,1301,1302,1304,1305,1306,1308,1309,1311,1313,1316,1318,1320,1322,1323,1325,1330,1335,1337,1340,1341,1343,1345,1350,1351,1352,1354,1357,1358,1359,1360,1361,1368,1369,1372,1377) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('../../data/small_new/multilabel/train Data.csv')\n",
    "labels = pd.read_csv('../../data/small_new/multilabel/train labels.csv')\n",
    "labels.drop(columns='id', inplace=True)\n",
    "data = pd.concat([features, labels], axis=1)\n",
    "data = data[['n_0000','n_0001','n_0002','n_0003',\n",
    "             'n_0004','n_0005','n_0006','n_0007',\n",
    "             'service_a', 'service_b', 'service_c', \n",
    "             'service_d', 'service_e', 'service_f',\n",
    "             'service_g', 'service_h', 'service_i',\n",
    "             'service_j', 'service_k', 'service_l',\n",
    "             'service_m', 'service_n']]\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'service_a', 'service_b', 'service_c',\n",
    "               'service_d', 'service_e', 'service_f',\n",
    "               'service_g', 'service_h', 'service_i',\n",
    "               'service_j', 'service_k', 'service_l',\n",
    "               'service_m', 'service_n'},\n",
    "    \"drop\" : ['id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml_gpu.automl.base import AutoML\n",
    "\n",
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml_gpu.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml_gpu.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml_gpu.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml_gpu.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.ml.base import MLPipeline\n",
    "from lightautoml_gpu.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:24] Stdout logging level is INFO2.\n",
      "[22:14:24] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[22:14:24] Task: multilabel\n",
      "\n",
      "[22:14:24] Start automl preset with listed constraints:\n",
      "[22:14:24] - time: 3600.00 seconds\n",
      "[22:14:24] - CPU: 4 cores\n",
      "[22:14:24] - memory: 16 GB\n",
      "\n",
      "[22:14:24] \u001b[1mTrain data shape: (14644, 22)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:28] Feats was rejected during automatic roles guess: []\n",
      "[22:14:28] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.57 secs\n",
      "[22:14:28] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[22:14:28] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/reader/guess_roles.py:56: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  gini_sum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:31] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[22:14:34] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[22:14:36] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-7.35028162615705\u001b[0m\n",
      "[22:14:36] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[22:14:36] Time left 3588.06 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:45] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[22:14:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[22:14:45] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:14:52] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:00] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-7.319639591038699\u001b[0m\n",
      "[22:15:08] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[22:15:08] Time left 3556.05 secs\n",
      "\n",
      "[22:15:08] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[22:15:08] Blending: optimization starts with equal weights and score \u001b[1m-7.314009267074656\u001b[0m\n",
      "[22:15:08] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-7.313950612738106\u001b[0m, weights = \u001b[1m[0.5435342 0.4564658]\u001b[0m\n",
      "[22:15:09] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-7.313950612738106\u001b[0m, weights = \u001b[1m[0.5435342 0.4564658]\u001b[0m\n",
      "[22:15:09] Blending: no score update. Terminated\n",
      "\n",
      "[22:15:09] \u001b[1mAutoml preset training completed in 44.32 seconds\u001b[0m\n",
      "\n",
      "[22:15:09] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.54353 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.45647 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[22:15:10] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multilabel', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'pb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:11] Stdout logging level is INFO2.\n",
      "[22:15:11] Task: multilabel\n",
      "\n",
      "[22:15:11] Start automl preset with listed constraints:\n",
      "[22:15:11] - time: 3600.00 seconds\n",
      "[22:15:11] - CPU: 1 cores\n",
      "[22:15:11] - memory: 16 GB\n",
      "\n",
      "[22:15:11] Train data shape: (14644, 22)\n",
      "[22:15:11] Feats was rejected during automatic roles guess: []\n",
      "[22:15:11] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.36 secs\n",
      "[22:15:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[22:15:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[22:15:17] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[22:15:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[22:15:29] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-7.377731107533531\u001b[0m\n",
      "[22:15:29] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[22:15:29] Time left 3581.13 secs\n",
      "\n",
      "[22:15:52] \u001b[1mSelector_XGB\u001b[0m fitting and predicting completed\n",
      "[22:15:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m ...\n",
      "[22:15:52] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[22:15:54] Stdout logging level is INFO.\n",
      "[22:15:54] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[22:15:54] Iter 0; Sample 0, BCE = 0.3790205528572303; \n",
      "[22:15:55] Iter 100; Sample 0, BCE = 0.35330232178832366; \n",
      "[22:15:55] Iter 200; Sample 0, BCE = 0.3531220856769635; \n",
      "[22:15:56] Iter 300; Sample 0, BCE = 0.3537443123858311; \n",
      "[22:15:56] Early stopping at iter 345, best iter 145, best_score 0.35300010943360355\n",
      "[22:15:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[22:15:56] Stdout logging level is INFO.\n",
      "[22:15:56] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[22:15:56] Iter 0; Sample 0, BCE = 0.37160564452989925; \n",
      "[22:15:57] Iter 100; Sample 0, BCE = 0.3456048339915689; \n",
      "[22:15:57] Iter 200; Sample 0, BCE = 0.3456026448130401; \n",
      "[22:15:58] Iter 300; Sample 0, BCE = 0.34641568359194913; \n",
      "[22:15:58] Early stopping at iter 342, best iter 142, best_score 0.34528128733591146\n",
      "[22:15:58] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m (orig) =====\n",
      "[22:15:58] Stdout logging level is INFO.\n",
      "[22:15:58] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[22:15:58] Iter 0; Sample 0, BCE = 0.3754746645949033; \n",
      "[22:15:59] Iter 100; Sample 0, BCE = 0.3492358005915022; \n",
      "[22:16:00] Iter 200; Sample 0, BCE = 0.34916125028310696; \n",
      "[22:16:00] Iter 300; Sample 0, BCE = 0.3498954724971279; \n",
      "[22:16:00] Early stopping at iter 344, best iter 144, best_score 0.3489873688597108\n",
      "[22:16:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m finished. score = \u001b[1m-7.316222988954335\u001b[0m\n",
      "[22:16:00] \u001b[1mLvl_0_Pipe_1_Mod_0_PB\u001b[0m fitting and predicting completed\n",
      "[22:16:00] Time left 3550.05 secs\n",
      "\n",
      "[22:16:00] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[22:16:00] Blending: Optimization starts with equal weights and score -7.313582049586577\n",
      "[22:16:01] Blending, iter 0: score = -7.31357829540162, weights = [0.5196658  0.48033422]\n",
      "[22:16:01] Blending, iter 1: score = -7.31357829540162, weights = [0.5196658  0.48033422]\n",
      "[22:16:01] No score update. Terminated\n",
      "[22:16:01] \u001b[1mAutoml preset training completed in 50.21 seconds\u001b[0m\n",
      "\n",
      "[22:16:01] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.51967 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.48033 * (3 averaged models Lvl_0_Pipe_1_Mod_0_PB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad158c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2d56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu.levels[0][1].ml_algos[0].models[0].to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7748506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[22:16:01] CatBoost uses as obj. MultiCrossEntropy.\n",
      "multilabel isn`t supported in lgb\n",
      "[22:16:01] CatBoost uses as obj. MultiCrossEntropy.\n",
      "multilabel isn`t supported in lgb\n",
      "[22:16:01] CatBoost uses as obj. MultiCrossEntropy.\n",
      "multilabel isn`t supported in lgb\n",
      "[22:16:02] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455ff47793bb4e24a4649a3f5d0c17ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012e1aa140e1412d930bac2282e10809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b8ab385a024f1a9d0bbc92e2cdd8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilabel isn`t supported in lgb\n",
      "[22:16:03] CatBoost uses as obj. MultiCrossEntropy.\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b14160e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': <lightautoml_gpu.tasks.base.Task at 0x7fe83e58a6a0>,\n",
       " 'optimization_search_space': {},\n",
       " 'freeze_defaults': True,\n",
       " 'default_params': {},\n",
       " 'models': [<py_boost.utils.tl_wrapper.TLPredictor at 0x7fe8465dcf40>,\n",
       "  <py_boost.utils.tl_wrapper.TLPredictor at 0x7fe83e931f40>,\n",
       "  <py_boost.utils.tl_wrapper.TLPredictor at 0x7fea0886cdc0>],\n",
       " '_features': ['freq__n_0006',\n",
       "  'inter__(n_0000__n_0003)',\n",
       "  'inter__(n_0000__n_0004)',\n",
       "  'inter__(n_0000__n_0006)',\n",
       "  'inter__(n_0003__n_0004)',\n",
       "  'inter__(n_0003__n_0006)',\n",
       "  'inter__(n_0004__n_0006)',\n",
       "  'inter__(n_0000__n_0003__n_0004)',\n",
       "  'inter__(n_0000__n_0003__n_0006)',\n",
       "  'inter__(n_0000__n_0004__n_0006)',\n",
       "  'inter__(n_0003__n_0004__n_0006)',\n",
       "  'n_0001',\n",
       "  'n_0002',\n",
       "  'n_0005',\n",
       "  'n_0007',\n",
       "  'ord__n_0000',\n",
       "  'ord__n_0003',\n",
       "  'ord__n_0004'],\n",
       " 'timer': <lightautoml_gpu.utils.timer.TaskTimer at 0x7fe83eafac10>,\n",
       " '_nan_rate': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_gpu.levels[0][1].ml_algos[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027652e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import time\n",
    "pickle_file = './gpu.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc3395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am being pickled\n",
      "Raw dump duration: 0.138s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    dump(automl_gpu, f)\n",
    "raw_dump_duration = time.time() - start\n",
    "print(\"Raw dump duration: %0.3fs\" % raw_dump_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56a1a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am being unpickled\n",
      "dict: {'task': <lightautoml_gpu.tasks.base.Task object at 0x7fe837b650a0>, 'optimization_search_space': {}, 'freeze_defaults': True, 'default_params': {}, '_features': ['freq__n_0006', 'inter__(n_0000__n_0003)', 'inter__(n_0000__n_0004)', 'inter__(n_0000__n_0006)', 'inter__(n_0003__n_0004)', 'inter__(n_0003__n_0006)', 'inter__(n_0004__n_0006)', 'inter__(n_0000__n_0003__n_0004)', 'inter__(n_0000__n_0003__n_0006)', 'inter__(n_0000__n_0004__n_0006)', 'inter__(n_0003__n_0004__n_0006)', 'n_0001', 'n_0002', 'n_0005', 'n_0007', 'ord__n_0000', 'ord__n_0003', 'ord__n_0004'], 'timer': <lightautoml_gpu.utils.timer.TaskTimer object at 0x7fe837b65310>, '_nan_rate': None}\n",
      "['0', '1', '2']\n",
      "[<py_boost.utils.tl_wrapper.TLPredictor object at 0x7fe837b65520>, <py_boost.utils.tl_wrapper.TLPredictor object at 0x7fe837b65670>, <py_boost.utils.tl_wrapper.TLPredictor object at 0x7fe837b65790>]\n",
      "Raw load duration: 0.102s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    model_inf = load(f)\n",
    "raw_load_duration = time.time() - start\n",
    "print(\"Raw load duration: %0.3fs\" % raw_load_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inf.levels[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad59ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inf.levels[0][1].pre_selection.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae4bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_pred = model_inf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdecea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0040593 , 0.01104795, 0.00455618, ..., 0.00880432, 0.00519127,\n",
       "        0.00402712],\n",
       "       [0.01266458, 0.01693736, 0.01217235, ..., 0.00294561, 0.01033957,\n",
       "        0.00951653],\n",
       "       [0.02570421, 0.06104734, 0.02489345, ..., 0.03574519, 0.01928957,\n",
       "        0.04422379],\n",
       "       ...,\n",
       "       [0.59768033, 0.54322815, 0.59243715, ..., 0.3416608 , 0.60686815,\n",
       "        0.56063   ],\n",
       "       [0.04642241, 0.05089628, 0.04339997, ..., 0.00870741, 0.04638685,\n",
       "        0.03446699],\n",
       "       [0.63145196, 0.58646077, 0.6288966 , ..., 0.36634105, 0.6377027 ,\n",
       "        0.6012654 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_pred.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23815756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0040593 , 0.01104795, 0.00455618, ..., 0.00880432, 0.00519127,\n",
       "        0.00402712],\n",
       "       [0.01266458, 0.01693736, 0.01217235, ..., 0.00294561, 0.01033957,\n",
       "        0.00951653],\n",
       "       [0.02570421, 0.06104734, 0.02489345, ..., 0.03574519, 0.01928957,\n",
       "        0.04422379],\n",
       "       ...,\n",
       "       [0.59768033, 0.54322815, 0.59243715, ..., 0.3416608 , 0.60686815,\n",
       "        0.56063   ],\n",
       "       [0.04642241, 0.05089628, 0.04339997, ..., 0.00870741, 0.04638685,\n",
       "        0.03446699],\n",
       "       [0.63145196, 0.58646077, 0.6288966 , ..., 0.36634105, 0.6377027 ,\n",
       "        0.6012654 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_pred.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9565ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00453568 0.011844   0.00497166 ... 0.00806187 0.00571794 0.00406567]\n",
      " [0.01194317 0.01575575 0.01144553 ... 0.00323016 0.0098604  0.00904782]\n",
      " [0.02324387 0.05228925 0.02249713 ... 0.0329233  0.01756081 0.03982078]\n",
      " ...\n",
      " [0.5948076  0.5388622  0.5879661  ... 0.35846284 0.60326093 0.5586468 ]\n",
      " [0.04839214 0.05508531 0.04603454 ... 0.00940074 0.04818819 0.03438577]\n",
      " [0.63275814 0.58800876 0.6297505  ... 0.3941361  0.6384841  0.60115516]]\n",
      "\n",
      "[[0.0040593  0.01104795 0.00455619 ... 0.00880433 0.00519127 0.00402713]\n",
      " [0.0126646  0.01693738 0.01217235 ... 0.00294561 0.01033958 0.00951654]\n",
      " [0.02570421 0.06104737 0.02489345 ... 0.03574518 0.01928957 0.0442238 ]\n",
      " ...\n",
      " [0.59768033 0.54322815 0.59243715 ... 0.3416608  0.60686815 0.5606301 ]\n",
      " [0.04642243 0.05089632 0.0434     ... 0.00870741 0.04638685 0.03446698]\n",
      " [0.63145196 0.58646077 0.6288966  ... 0.36634102 0.6377027  0.60126543]]\n",
      "\n",
      "[[0.00400276 0.01218286 0.00493251 ... 0.00710507 0.00418582 0.00424656]\n",
      " [0.01266814 0.0159497  0.01368894 ... 0.00267034 0.01136277 0.01127742]\n",
      " [0.02685698 0.05573656 0.02391902 ... 0.03415908 0.02009368 0.04901036]\n",
      " ...\n",
      " [0.59574586 0.5447111  0.5984924  ... 0.37220007 0.6038853  0.5608696 ]\n",
      " [0.04184718 0.05110879 0.04810259 ... 0.00796808 0.04243356 0.03726724]\n",
      " [0.6340059  0.5831628  0.62465674 ... 0.39012098 0.63517326 0.59659994]]\n",
      "\n",
      "[[0.00585273 0.01071973 0.00473556 ... 0.01222234 0.00802297 0.00382404]\n",
      " [0.01081822 0.01360643 0.00954316 ... 0.00155242 0.01100199 0.01117327]\n",
      " [0.02918123 0.05287381 0.0255281  ... 0.03504727 0.02228512 0.05015943]\n",
      " ...\n",
      " [0.5721381  0.5322967  0.57742125 ... 0.3287828  0.5790439  0.5433578 ]\n",
      " [0.04576294 0.0452823  0.04267206 ... 0.00694387 0.04720241 0.03663189]\n",
      " [0.6077737  0.57370365 0.6100969  ... 0.36274362 0.61323345 0.5923728 ]]\n",
      "\n",
      "[[0.0040593  0.01104795 0.00455618 ... 0.00880432 0.00519127 0.00402712]\n",
      " [0.01266458 0.01693736 0.01217235 ... 0.00294561 0.01033957 0.00951653]\n",
      " [0.02570421 0.06104734 0.02489345 ... 0.03574519 0.01928957 0.04422379]\n",
      " ...\n",
      " [0.59768033 0.54322815 0.59243715 ... 0.3416608  0.60686815 0.56063   ]\n",
      " [0.04642241 0.05089628 0.04339997 ... 0.00870741 0.04638685 0.03446699]\n",
      " [0.63145196 0.58646077 0.6288966  ... 0.36634105 0.6377027  0.6012654 ]]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(disk_pred.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70394263",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('multilabel', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_mgpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcpu_inf = automl_mgpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(oof_pred_mgpu.data.T)\n",
    "print()\n",
    "print(mcpu_inf.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import time\n",
    "\n",
    "pickle_file = './mgpu.joblib'\n",
    "\n",
    "start = time.time()\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    dump(automl_mgpu, f)\n",
    "raw_dump_duration = time.time() - start\n",
    "print(\"Raw dump duration: %0.3fs\" % raw_dump_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "a = os.environ['OMP_NUM_THREADS'] = \"8\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml_gpu.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml_gpu.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml_gpu.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml_gpu.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml_gpu.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml_gpu.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/small_new/multioutput/ENB2012_data.csv')\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'Y1', 'Y2'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml_gpu.automl.base import AutoML\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml_gpu.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml_gpu.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml_gpu.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml_gpu.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearLBFGS\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearL1CD\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.ml.base import MLPipeline\n",
    "from lightautoml_gpu.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b768794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:33] Stdout logging level is INFO2.\n",
      "[13:47:33] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:47:33] Task: multi:reg\n",
      "\n",
      "[13:47:33] Start automl preset with listed constraints:\n",
      "[13:47:33] - time: 3600.00 seconds\n",
      "[13:47:33] - CPU: 4 cores\n",
      "[13:47:33] - memory: 16 GB\n",
      "\n",
      "[13:47:33] \u001b[1mTrain data shape: (768, 10)\u001b[0m\n",
      "\n",
      "[13:47:36] Feats was rejected during automatic roles guess: []\n",
      "[13:47:36] Layer \u001b[1m1\u001b[0m train process start. Time left 3596.73 secs\n",
      "[13:47:36] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:47:36] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[13:47:36] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[13:47:37] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[13:47:37] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-2.1695059866706523\u001b[0m\n",
      "[13:47:37] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:47:37] Time left 3595.84 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:37] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:47:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[13:47:37] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:38] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:38] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-0.3494882974897825\u001b[0m\n",
      "[13:47:38] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:47:38] Time left 3594.39 secs\n",
      "\n",
      "[13:47:38] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:47:38] Blending: optimization starts with equal weights and score \u001b[1m-1.1413262737418224\u001b[0m\n",
      "[13:47:38] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.3494882974897825\u001b[0m, weights = \u001b[1m[0. 1.]\u001b[0m\n",
      "[13:47:39] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.3494882974897825\u001b[0m, weights = \u001b[1m[0. 1.]\u001b[0m\n",
      "[13:47:39] Blending: no score update. Terminated\n",
      "\n",
      "[13:47:39] \u001b[1mAutoml preset training completed in 5.63 seconds\u001b[0m\n",
      "\n",
      "[13:47:39] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535dcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[13:47:46] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2', 'pb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:46] Stdout logging level is INFO2.\n",
      "[13:47:46] Task: multi:reg\n",
      "\n",
      "[13:47:46] Start automl preset with listed constraints:\n",
      "[13:47:46] - time: 3600.00 seconds\n",
      "[13:47:46] - CPU: 1 cores\n",
      "[13:47:46] - memory: 16 GB\n",
      "\n",
      "[13:47:46] Train data shape: (768, 10)\n",
      "[13:47:46] Feats was rejected during automatic roles guess: []\n",
      "[13:47:46] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.56 secs\n",
      "[13:47:47] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:47:47] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:47:49] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:47:51] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:47:52] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-1.9745038881401222\u001b[0m\n",
      "[13:47:52] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:47:52] Time left 3593.69 secs\n",
      "\n",
      "[13:47:54] Stdout logging level is INFO.\n",
      "[13:47:54] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:47:54] Iter 0; Sample 0, rmse = 9.207141299398062; \n",
      "[13:47:55] Iter 100; Sample 0, rmse = 2.0756559367240768; \n",
      "[13:47:55] Iter 200; Sample 0, rmse = 1.172410234929655; \n",
      "[13:47:56] Iter 300; Sample 0, rmse = 1.008134218865326; \n",
      "[13:47:56] Iter 400; Sample 0, rmse = 0.9737353694640504; \n",
      "[13:47:56] Iter 500; Sample 0, rmse = 0.9584290096964746; \n",
      "[13:47:57] Iter 600; Sample 0, rmse = 0.9400354521845207; \n",
      "[13:47:57] Iter 700; Sample 0, rmse = 0.9087759101171203; \n",
      "[13:47:58] Iter 800; Sample 0, rmse = 0.8909928169090401; \n",
      "[13:47:58] Iter 900; Sample 0, rmse = 0.8840892265990593; \n",
      "[13:47:58] Iter 1000; Sample 0, rmse = 0.8736135928637424; \n",
      "[13:47:59] Iter 1100; Sample 0, rmse = 0.867252195375641; \n",
      "[13:47:59] Iter 1200; Sample 0, rmse = 0.8593788475702507; \n",
      "[13:48:00] Iter 1300; Sample 0, rmse = 0.8518580067194309; \n",
      "[13:48:00] Iter 1400; Sample 0, rmse = 0.8433873033553652; \n",
      "[13:48:00] Iter 1500; Sample 0, rmse = 0.8381785912711455; \n",
      "[13:48:01] Iter 1600; Sample 0, rmse = 0.8311691514726188; \n",
      "[13:48:01] Iter 1700; Sample 0, rmse = 0.8257648265126466; \n",
      "[13:48:02] Iter 1800; Sample 0, rmse = 0.8218851663633375; \n",
      "[13:48:02] Iter 1900; Sample 0, rmse = 0.8161583187562983; \n",
      "[13:48:02] Iter 2000; Sample 0, rmse = 0.8134614329970614; \n",
      "[13:48:03] Iter 2100; Sample 0, rmse = 0.8110621802537437; \n",
      "[13:48:03] Iter 2200; Sample 0, rmse = 0.8068372314020935; \n",
      "[13:48:03] Iter 2300; Sample 0, rmse = 0.8024390946172805; \n",
      "[13:48:04] Iter 2400; Sample 0, rmse = 0.7993091384714043; \n",
      "[13:48:04] Iter 2500; Sample 0, rmse = 0.7972183454020305; \n",
      "[13:48:05] Iter 2600; Sample 0, rmse = 0.7971636907089888; \n",
      "[13:48:05] Early stopping at iter 2660, best iter 2460, best_score 0.7969131930106131\n",
      "[13:48:06] \u001b[1mSelector_PB\u001b[0m fitting and predicting completed\n",
      "[13:48:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m ...\n",
      "[13:48:07] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:48:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:48:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:48:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m finished. score = \u001b[1m-0.997903097619613\u001b[0m\n",
      "[13:48:25] \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[13:48:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m ...\n",
      "[13:48:25] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[13:48:25] Stdout logging level is INFO.\n",
      "[13:48:25] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:48:25] Iter 0; Sample 0, rmse = 9.212943912166697; \n",
      "[13:48:25] Iter 100; Sample 0, rmse = 2.576848197075309; \n",
      "[13:48:26] Iter 200; Sample 0, rmse = 1.4908217821649898; \n",
      "[13:48:27] Iter 300; Sample 0, rmse = 1.3330383728625008; \n",
      "[13:48:27] Iter 400; Sample 0, rmse = 1.2822353330741536; \n",
      "[13:48:28] Iter 500; Sample 0, rmse = 1.2658022559074051; \n",
      "[13:48:28] Iter 600; Sample 0, rmse = 1.2587688097492684; \n",
      "[13:48:29] Iter 700; Sample 0, rmse = 1.2501995736506717; \n",
      "[13:48:30] Iter 800; Sample 0, rmse = 1.2414355649931648; \n",
      "[13:48:30] Iter 900; Sample 0, rmse = 1.2369090560629739; \n",
      "[13:48:31] Iter 1000; Sample 0, rmse = 1.2326626906324738; \n",
      "[13:48:31] Iter 1100; Sample 0, rmse = 1.2276648995133832; \n",
      "[13:48:32] Iter 1200; Sample 0, rmse = 1.225651502207205; \n",
      "[13:48:32] Iter 1300; Sample 0, rmse = 1.222568715266988; \n",
      "[13:48:33] Iter 1400; Sample 0, rmse = 1.220675648086428; \n",
      "[13:48:33] Iter 1500; Sample 0, rmse = 1.2190213114296706; \n",
      "[13:48:34] Iter 1600; Sample 0, rmse = 1.2205968538389134; \n",
      "[13:48:35] Early stopping at iter 1692, best iter 1492, best_score 1.2188726341700264\n",
      "[13:48:35] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[13:48:35] Stdout logging level is INFO.\n",
      "[13:48:35] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:48:35] Iter 0; Sample 0, rmse = 9.955186849206838; \n",
      "[13:48:36] Iter 100; Sample 0, rmse = 2.793154160799369; \n",
      "[13:48:37] Iter 200; Sample 0, rmse = 1.5157831260643213; \n",
      "[13:48:37] Iter 300; Sample 0, rmse = 1.2684126635260695; \n",
      "[13:48:38] Iter 400; Sample 0, rmse = 1.183014439702733; \n",
      "[13:48:38] Iter 500; Sample 0, rmse = 1.1508148786079244; \n",
      "[13:48:39] Iter 600; Sample 0, rmse = 1.1295754304148828; \n",
      "[13:48:39] Iter 700; Sample 0, rmse = 1.1175501400236867; \n",
      "[13:48:40] Iter 800; Sample 0, rmse = 1.1119601892253954; \n",
      "[13:48:40] Iter 900; Sample 0, rmse = 1.10667751310738; \n",
      "[13:48:41] Iter 1000; Sample 0, rmse = 1.1024850759156053; \n",
      "[13:48:41] Iter 1100; Sample 0, rmse = 1.1006952039095634; \n",
      "[13:48:42] Iter 1200; Sample 0, rmse = 1.0997118770194465; \n",
      "[13:48:42] Iter 1300; Sample 0, rmse = 1.099349821858777; \n",
      "[13:48:43] Iter 1400; Sample 0, rmse = 1.0981623929626088; \n",
      "[13:48:43] Iter 1500; Sample 0, rmse = 1.0977196050944802; \n",
      "[13:48:44] Iter 1600; Sample 0, rmse = 1.096888111006195; \n",
      "[13:48:44] Iter 1700; Sample 0, rmse = 1.0951189896870823; \n",
      "[13:48:45] Iter 1800; Sample 0, rmse = 1.0943413929159564; \n",
      "[13:48:45] Iter 1900; Sample 0, rmse = 1.0949454048134923; \n",
      "[13:48:46] Iter 2000; Sample 0, rmse = 1.095492720782482; \n",
      "[13:48:46] Early stopping at iter 2001, best iter 1801, best_score 1.0943413929159564\n",
      "[13:48:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[13:48:47] Stdout logging level is INFO.\n",
      "[13:48:47] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:48:47] Iter 0; Sample 0, rmse = 9.834688022986077; \n",
      "[13:48:47] Iter 100; Sample 0, rmse = 3.309870492846768; \n",
      "[13:48:48] Iter 200; Sample 0, rmse = 2.5212173675781937; \n",
      "[13:48:48] Iter 300; Sample 0, rmse = 2.4051995651420164; \n",
      "[13:48:49] Iter 400; Sample 0, rmse = 2.3578591115646117; \n",
      "[13:48:49] Iter 500; Sample 0, rmse = 2.324530999382296; \n",
      "[13:48:50] Iter 600; Sample 0, rmse = 2.3037318128606246; \n",
      "[13:48:50] Iter 700; Sample 0, rmse = 2.293441265508282; \n",
      "[13:48:51] Iter 800; Sample 0, rmse = 2.289718041702712; \n",
      "[13:48:51] Iter 900; Sample 0, rmse = 2.286045156763456; \n",
      "[13:48:52] Iter 1000; Sample 0, rmse = 2.283432705722531; \n",
      "[13:48:52] Iter 1100; Sample 0, rmse = 2.2813715307860827; \n",
      "[13:48:53] Iter 1200; Sample 0, rmse = 2.279135350814139; \n",
      "[13:48:53] Iter 1300; Sample 0, rmse = 2.279152835837146; \n",
      "[13:48:54] Iter 1400; Sample 0, rmse = 2.2770027178700576; \n",
      "[13:48:54] Iter 1500; Sample 0, rmse = 2.2748125946151143; \n",
      "[13:48:55] Iter 1600; Sample 0, rmse = 2.2736027816773374; \n",
      "[13:48:55] Iter 1700; Sample 0, rmse = 2.2717048975606033; \n",
      "[13:48:56] Iter 1800; Sample 0, rmse = 2.2708950362836755; \n",
      "[13:48:56] Iter 1900; Sample 0, rmse = 2.27078097713066; \n",
      "[13:48:57] Early stopping at iter 1986, best iter 1786, best_score 2.2705039717919275\n",
      "[13:48:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m finished. score = \u001b[1m-1.1244267033909758\u001b[0m\n",
      "[13:48:58] \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m fitting and predicting completed\n",
      "[13:48:58] Time left 3528.48 secs\n",
      "\n",
      "[13:48:58] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:48:58] Blending: Optimization starts with equal weights and score -1.0916163704792659\n",
      "[13:48:58] Blending, iter 0: score = -0.9538817095011474, weights = [0.05849272 0.72949505 0.21201225]\n",
      "[13:48:58] Blending, iter 1: score = -0.953750300159057, weights = [0.0686978  0.72069496 0.21060725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:58] Blending, iter 2: score = -0.9537503526235621, weights = [0.06871326 0.7206321  0.21065466]\n",
      "[13:48:58] Blending, iter 3: score = -0.9537503526235621, weights = [0.06871326 0.7206321  0.21065466]\n",
      "[13:48:58] No score update. Terminated\n",
      "[13:48:58] \u001b[1mAutoml preset training completed in 71.86 seconds\u001b[0m\n",
      "\n",
      "[13:48:58] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.06871 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.72063 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) +\n",
      "\t 0.21065 * (3 averaged models Lvl_0_Pipe_1_Mod_1_PB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f31b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d53856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7558ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[13:40:18] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c35d43a613491ba61a05cf1b3d6700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b844f9d4a2e746ca88688620860a89e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2742 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3748e2985d54b1eb7d52c17a242a66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[13:40:22] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22280bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608ac415",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b98e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 13097. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-12-10 13:40:24,902 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-kgdbqb4r', purging\n",
      "2022-12-10 13:40:24,902 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-12-10 13:40:24,902 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:51957': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf\n",
    "\n",
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[13:40:25] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff1a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:25] Stdout logging level is INFO2.\n",
      "[13:40:25] Task: multi:reg\n",
      "\n",
      "[13:40:25] Start automl preset with listed constraints:\n",
      "[13:40:25] - time: 3600.00 seconds\n",
      "[13:40:25] - CPU: 1 cores\n",
      "[13:40:25] - memory: 16 GB\n",
      "\n",
      "[13:40:25] Train data shape: (768, 10)\n",
      "[13:40:25] Feats was rejected during automatic roles guess: []\n",
      "[13:40:25] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.63 secs\n",
      "[13:40:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[13:40:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:40:27] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:40:29] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[13:40:30] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-1.987997462488711\u001b[0m\n",
      "[13:40:30] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[13:40:30] Time left 3594.93 secs\n",
      "\n",
      "[13:40:30] Stdout logging level is INFO.\n",
      "[13:40:30] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[13:40:30] Iter 0; Sample 0, rmse = 9.208333457707193; \n",
      "[13:40:31] Iter 100; Sample 0, rmse = 2.1064522237860097; \n",
      "[13:40:31] Iter 200; Sample 0, rmse = 1.1980207469862485; \n",
      "[13:40:32] Iter 300; Sample 0, rmse = 1.0163220732142488; \n",
      "[13:40:32] Iter 400; Sample 0, rmse = 0.988062572680007; \n",
      "[13:40:32] Iter 500; Sample 0, rmse = 0.9602676881174969; \n",
      "[13:40:33] Iter 600; Sample 0, rmse = 0.9331955645679085; \n",
      "[13:40:33] Iter 700; Sample 0, rmse = 0.9164846587515136; \n",
      "[13:40:34] Iter 800; Sample 0, rmse = 0.9009796207777556; \n",
      "[13:40:34] Iter 900; Sample 0, rmse = 0.8878733884329372; \n",
      "[13:40:35] Iter 1000; Sample 0, rmse = 0.878690922278661; \n",
      "[13:40:35] Iter 1100; Sample 0, rmse = 0.8680998601976976; \n",
      "[13:40:35] Iter 1200; Sample 0, rmse = 0.8601710160235022; \n",
      "[13:40:36] Iter 1300; Sample 0, rmse = 0.8541951394012666; \n",
      "[13:40:36] Iter 1400; Sample 0, rmse = 0.8392666925918405; \n",
      "[13:40:37] Iter 1500; Sample 0, rmse = 0.8314032017503943; \n",
      "[13:40:37] Iter 1600; Sample 0, rmse = 0.8217053161334698; \n",
      "[13:40:38] Iter 1700; Sample 0, rmse = 0.8184812179496193; \n",
      "[13:40:38] Iter 1800; Sample 0, rmse = 0.8169892275185376; \n",
      "[13:40:38] Iter 1900; Sample 0, rmse = 0.8116111599489466; \n",
      "[13:40:39] Iter 2000; Sample 0, rmse = 0.808586428676979; \n",
      "[13:40:39] Iter 2100; Sample 0, rmse = 0.8058801271615923; \n",
      "[13:40:40] Iter 2200; Sample 0, rmse = 0.8036660457041447; \n",
      "[13:40:40] Iter 2300; Sample 0, rmse = 0.8021516428094156; \n",
      "[13:40:40] Iter 2400; Sample 0, rmse = 0.7991415762092448; \n",
      "[13:40:41] Iter 2500; Sample 0, rmse = 0.7959274557430939; \n",
      "[13:40:41] Iter 2600; Sample 0, rmse = 0.794687266651903; \n",
      "[13:40:42] Iter 2700; Sample 0, rmse = 0.7902793476857103; \n",
      "[13:40:42] Iter 2800; Sample 0, rmse = 0.7886334426437052; \n",
      "[13:40:42] Iter 2900; Sample 0, rmse = 0.7853165166845909; \n",
      "[13:40:43] Iter 2999; Sample 0, rmse = 0.7843056469244047; \n",
      "[13:40:44] \u001b[1mSelector_PB\u001b[0m fitting and predicting completed\n",
      "[13:40:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m ...\n",
      "[13:40:45] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[13:40:48] task [xgboost.dask-0]:ucx://127.0.0.1:51957 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[13:40:56] task [xgboost.dask-0]:ucx://127.0.0.1:51957 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:04] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[13:41:05] task [xgboost.dask-0]:ucx://127.0.0.1:51957 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m finished. score = \u001b[1m-1.4210363074888785\u001b[0m\n",
      "[13:41:07] \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[13:41:07] Time left 3558.30 secs\n",
      "\n",
      "[13:41:07] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:41:07] Blending: Optimization starts with equal weights and score -1.5198859591657916\n",
      "[13:41:07] Blending, iter 0: score = -1.3705565962319572, weights = [0.14589803 0.85410196]\n",
      "[13:41:07] Blending, iter 1: score = -1.3705565962319572, weights = [0.14589803 0.85410196]\n",
      "[13:41:07] No score update. Terminated\n",
      "[13:41:07] \u001b[1mAutoml preset training completed in 41.85 seconds\u001b[0m\n",
      "\n",
      "[13:41:07] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.14590 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.85410 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc74a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.592127 20.911577 21.538649 ... 17.80141  16.999327 16.89115 ]\n",
      " [16.273535 16.558796 15.514778 ... 17.351414 17.059956 16.524736]]\n",
      "\n",
      "[[21.592134 20.911587 21.538649 ... 17.801424 16.999352 16.891197]\n",
      " [16.27357  16.558823 15.514776 ... 17.351433 17.05996  16.52476 ]]\n",
      "\n",
      "[[22.084217 23.090494 20.3359   ... 17.556313 16.952316 16.56749 ]\n",
      " [17.585676 16.95052  15.522291 ... 17.295746 16.689827 16.334679]]\n",
      "\n",
      "[[22.325417 21.209105 21.430384 ... 16.482996 15.88877  16.432215]\n",
      " [15.770237 15.915673 15.78574  ... 16.53469  16.339546 16.176693]]\n",
      "\n",
      "[[23.569838 23.603844 21.206917 ... 17.79602  17.50906  17.473864]\n",
      " [16.294819 16.225418 15.455781 ... 17.205748 16.966179 17.177782]]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(oof_pred_mgpu.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f0ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d946297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74a36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

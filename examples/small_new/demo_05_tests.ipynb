{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf\n",
    "\n",
    "from lightautoml.dataset.roles import TargetRole\n",
    "\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d7afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Airline  Flight AirportFrom AirportTo  DayOfWeek  Time  Length  Delay\n",
      "0      CO     269         SFO       IAH          3    15     205      1\n",
      "1      US    1558         PHX       CLT          3    15     222      1\n",
      "2      AA    2400         LAX       DFW          3    20     165      1\n",
      "3      AA    2466         SFO       DFW          3    20     195      1\n",
      "4      AS     108         ANC       SEA          3    30     202      0\n",
      "task type: binary\n"
     ]
    }
   ],
   "source": [
    "key = 'airlines'\n",
    "adv_roles = True\n",
    "args_fold = 2\n",
    "\n",
    "data_info = joblib.load(os.path.join(\"../../data/old_presets\", 'data_info.pkl'))[key]\n",
    "folds = joblib.load(os.path.join(\"../../data/old_presets\", 'folds', '{0}.pkl'.format(key)))\n",
    "\n",
    "read_csv_params = {}\n",
    "if 'read_csv_params' in data_info:\n",
    "    read_csv_params = {**read_csv_params, **data_info['read_csv_params']}\n",
    "\n",
    "data = pd.read_csv(os.path.join(\"../../data/old_presets/data\", data_info['path']), **read_csv_params)\n",
    "\n",
    "if 'drop' in data_info:\n",
    "    data.drop(data_info['drop'], axis=1, inplace=True)\n",
    "\n",
    "if 'class_map' in data_info:\n",
    "    data[data_info['target']] = data[data_info['target']].map(data_info['class_map']).values\n",
    "    assert data[data_info['target']].notnull().all(), 'Class mapping is set unproperly'\n",
    "\n",
    "print(data.head())\n",
    "print(\"task type:\", data_info['task_type'])\n",
    "\n",
    "roles = {TargetRole(): data_info['target']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "\n",
    "from lightautoml.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "from lightautoml.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(data_info['task_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': ['linear_l2', 'cb', 'lgbm']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:56] Stdout logging level is INFO2.\n",
      "[14:20:56] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[14:20:56] Task: binary\n",
      "\n",
      "[14:20:56] Start automl preset with listed constraints:\n",
      "[14:20:56] - time: 3600.00 seconds\n",
      "[14:20:56] - CPU: 4 cores\n",
      "[14:20:56] - memory: 16 GB\n",
      "\n",
      "[14:20:56] \u001b[1mTrain data shape: (431506, 8)\u001b[0m\n",
      "\n",
      "[14:21:00] Feats was rejected during automatic roles guess: []\n",
      "[14:21:00] Layer \u001b[1m1\u001b[0m train process start. Time left 3595.81 secs\n",
      "[14:21:11] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[14:21:11] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[14:21:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[14:21:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[14:21:19] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7079384207630041\u001b[0m\n",
      "[14:21:19] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[14:21:19] Time left 3576.78 secs\n",
      "\n",
      "[14:21:19] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:21:19] Layer \u001b[1m2\u001b[0m train process start. Time left 3576.76 secs\n",
      "[14:21:29] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[14:21:40] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m ...\n",
      "[14:21:40] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:46] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:01] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m0.7167728338119556\u001b[0m\n",
      "[14:22:01] \u001b[1mLvl_1_Pipe_0_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[14:22:01] Time left 3535.22 secs\n",
      "\n",
      "[14:22:01] \u001b[1mLayer 2 training completed.\u001b[0m\n",
      "\n",
      "[14:22:01] Layer \u001b[1m3\u001b[0m train process start. Time left 3535.20 secs\n",
      "[14:22:13] Start fitting \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[14:22:13] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:22:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:22:24] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
      "[14:22:32] Fitting \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7176078633171086\u001b[0m\n",
      "[14:22:32] \u001b[1mLvl_2_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[14:22:32] Time left 3504.09 secs\n",
      "\n",
      "[14:22:32] \u001b[1mLayer 3 training completed.\u001b[0m\n",
      "\n",
      "[14:22:32] \u001b[1mAutoml preset training completed in 95.92 seconds\u001b[0m\n",
      "\n",
      "[14:22:32] Model description:\n",
      "Models on level 0:\n",
      "\t 3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
      "\n",
      "Models on level 1:\n",
      "\t 3 averaged models Lvl_1_Pipe_0_Mod_0_CatBoost\n",
      "\n",
      "Final prediction for new objects (level 2) = \n",
      "\t 1.00000 * (3 averaged models Lvl_2_Pipe_0_Mod_0_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_fit_pred = automl.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9e7f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "cpu_pred = automl.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f432e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(data_info['task_type'], device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': ['linear_l2', 'xgb', 'cb']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:39] Stdout logging level is INFO2.\n",
      "[14:22:39] Task: binary\n",
      "\n",
      "[14:22:39] Start automl preset with listed constraints:\n",
      "[14:22:39] - time: 3600.00 seconds\n",
      "[14:22:39] - CPU: 1 cores\n",
      "[14:22:39] - memory: 16 GB\n",
      "\n",
      "[14:22:39] Train data shape: (431506, 8)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[14:22:40] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.34 secs\n",
      "[14:22:41] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[14:22:41] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:22:47] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:22:50] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:22:54] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7083783149719238\u001b[0m\n",
      "[14:22:54] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[14:22:54] Time left 3584.54 secs\n",
      "\n",
      "[14:22:54] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:22:54] Layer \u001b[1m2\u001b[0m train process start. Time left 3584.54 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1501.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:06] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[14:23:07] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m ...\n",
      "[14:23:07] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[14:23:14] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[14:23:22] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[14:23:33] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m finished. score = \u001b[1m0.7159843444824219\u001b[0m\n",
      "[14:23:33] \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[14:23:33] Time left 3546.40 secs\n",
      "\n",
      "[14:23:33] \u001b[1mLayer 2 training completed.\u001b[0m\n",
      "\n",
      "[14:23:33] Layer \u001b[1m3\u001b[0m train process start. Time left 3546.40 secs\n",
      "[14:23:34] Start fitting \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m ...\n",
      "[14:23:34] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1393.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:39] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1393.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:48] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1393.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:56] Fitting \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.7170827984809875\u001b[0m\n",
      "[14:23:56] \u001b[1mLvl_2_Pipe_0_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[14:23:56] Time left 3523.13 secs\n",
      "\n",
      "[14:23:56] \u001b[1mLayer 3 training completed.\u001b[0m\n",
      "\n",
      "[14:23:56] \u001b[1mAutoml preset training completed in 76.87 seconds\u001b[0m\n",
      "\n",
      "[14:23:56] Model description:\n",
      "Models on level 0:\n",
      "\t 3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2\n",
      "\n",
      "Models on level 1:\n",
      "\t 3 averaged models Lvl_1_Pipe_0_Mod_0_XGB\n",
      "\n",
      "Final prediction for new objects (level 2) = \n",
      "\t 1.00000 * (3 averaged models Lvl_2_Pipe_0_Mod_0_CatBoostGPU) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_fit_pred = automl_gpu.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad158c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "gpu_inf = automl_gpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7748506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models parameters: {'_init_params': {'task_type': 'GPU', 'devices': '0', 'thread_count': 1, 'random_seed': 42, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'max_ctr_complexity': 1, 'num_trees': 3000, 'objective': 'Logloss', 'eval_metric': 'AUC', 'od_wait': 100}, '_object': <_catboost._CatBoost object at 0x7fcd68f53400>, '_is_fitted_': True, '_random_seed': 42, '_learning_rate': 0.05000000074505806, '_tree_count': 774, '_n_features_in': 20, '_prediction_values_change': [2.1750902691001297, 5.076168164338567, 3.220156124006821, 2.9674498896177623, 2.5282828208675676, 3.2260336098832862, 5.2225764808514645, 1.1118635684449916, 1.7029795599176003, 2.911652531558489, 3.6668095603794573, 5.877746382719845, 4.39706975729181, 0.6480764029832288, 0.9253961857935022, 0.8525167171072641, 1.1987492816099405, 40.79393958667321, 3.8759328733148193, 7.621510233540249]}\n",
      "Models type: <class 'catboost.core.CatBoost'>\n",
      "CB feats: {'task': <lightautoml.tasks.base.Task object at 0x7fcd6a2b89d0>, 'optimization_search_space': {}, 'freeze_defaults': False, 'default_params': {'task_type': 'GPU', 'devices': '0', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'max_ctr_complexity': 1}, 'models': [<catboost.core.CatBoost object at 0x7fcd68c84f40>, <catboost.core.CatBoost object at 0x7fcd68c78910>, <catboost.core.CatBoost object at 0x7fcd68c84190>], '_features': ['le__DayOfWeek', 'oof__le__Airline', 'oof__le__AirportFrom', 'oof__le__AirportTo', 'oof__le__Flight', 'oof__le__Length', 'oof__le__Time', 'oof__inter__(Flight__Time)', 'oof__inter__(Flight__Length)', 'oof__inter__(Flight__AirportFrom)', 'oof__inter__(Time__Length)', 'oof__inter__(Time__AirportFrom)', 'oof__inter__(Length__AirportFrom)', 'oof__inter__(Flight__Time__Length)', 'oof__inter__(Flight__Time__AirportFrom)', 'oof__inter__(Flight__Length__AirportFrom)', 'oof__inter__(Time__Length__AirportFrom)', 'Lvl_0_Pipe_0_Mod_0_LinearL2_prediction_0', 'ord__Flight', 'ord__Time'], 'timer': <lightautoml.utils.timer.TaskTimer object at 0x7fcd06f952b0>, '_nan_rate': 0, 'gpu_ids': ['0'], 'parallel_folds': False, '_name': 'Lvl_2_Pipe_0_Mod_0_CatBoostGPU', '_le_cat_features': None, '_text_features': None, '_params': {'task_type': 'GPU', 'devices': '0', 'thread_count': 1, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.05, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'max_ctr_complexity': 1}, 'n_classes': 1}\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "cpu_inf = automl_gpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70394263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 21226. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-12-07 14:24:01,301 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tzrfwv9q', purging\n",
      "2022-12-07 14:24:01,306 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-12-07 14:24:01,306 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:41589': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:01] Stdout logging level is INFO2.\n",
      "[14:24:01] Task: binary\n",
      "\n",
      "[14:24:01] Start automl preset with listed constraints:\n",
      "[14:24:01] - time: 3600.00 seconds\n",
      "[14:24:01] - CPU: 1 cores\n",
      "[14:24:01] - memory: 16 GB\n",
      "\n",
      "[14:24:01] Train data shape: (431506, 8)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "[14:24:02] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.41 secs\n",
      "[14:24:03] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[14:24:03] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:24:07] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:24:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[14:24:14] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7083818316459656\u001b[0m\n",
      "[14:24:14] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[14:24:14] Time left 3587.18 secs\n",
      "\n",
      "[14:24:14] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[14:24:14] Layer \u001b[1m2\u001b[0m train process start. Time left 3587.18 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1314.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:26] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[14:24:27] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m ...\n",
      "[14:24:27] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "THIS IS MGPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[14:24:31] task [xgboost.dask-0]:ucx://127.0.0.1:41589 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:32] Model Lvl_1_Pipe_0_Mod_0_XGB failed during ml_algo.fit_predict call.\n",
      "\n",
      "uninitialized_fill_n: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 14:24:32,045 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       dispatched_train-2b58ca9a-4715-4aca-a900-fe05436406e5\n",
      "Function:  dispatched_train\n",
      "args:      ({'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'task': 'train', 'learning_rate': 0.05, 'max_leaves': 244, 'max_depth': 0, 'verbosity': 0, 'reg_alpha': 1, 'reg_lambda': 0.0, 'gamma': 0.0, 'max_bin': 255, 'random_state': 42, 'nthread': 1, 'objective': 'binary:logistic', 'metric': 'auc', 'num_class': 1}, [b'DMLC_NUM_WORKER=1', b'DMLC_TRACKER_URI=192.168.18.5', b'DMLC_TRACKER_PORT=60433', b'DMLC_TASK_ID=[xgboost.dask-0]:ucx://127.0.0.1:41589'], 140519969677216, ['train', 'valid'], [140519969677216, 140518548399920], < could not convert arg to str >, < could not convert arg to str >, < could not convert arg to str >)\n",
      "kwargs:    {}\n",
      "Exception: \"XGBoostError('uninitialized_fill_n: failed to synchronize: cudaErrorIllegalAddress: an illegal memory access was encountered')\"\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Pipeline finished with 0 models for some reason.\nProbably one or more models failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m task \u001b[38;5;241m=\u001b[39m Task(data_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_type\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m automl_mgpu \u001b[38;5;241m=\u001b[39m TabularAutoMLGPU(\n\u001b[1;32m      4\u001b[0m     task \u001b[38;5;241m=\u001b[39m task, \n\u001b[1;32m      5\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3600\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     client \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m mgpu_fit_pred \u001b[38;5;241m=\u001b[39m \u001b[43mautoml_mgpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43margs_fold\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/automl/presets/gpu/tabular_gpu_presets.py:596\u001b[0m, in \u001b[0;36mTabularAutoMLGPU.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, log_file, verbose, return_numpy)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m read_data(\n\u001b[1;32m    593\u001b[0m         valid_data, valid_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_limit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_csv_params\n\u001b[1;32m    594\u001b[0m     )\n\u001b[0;32m--> 596\u001b[0m oof_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTabularAutoMLGPU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__bases__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_numpy:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m oof_pred\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/automl/presets/base.py:205\u001b[0m, in \u001b[0;36mAutoMLPreset.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, verbose)\u001b[0m\n\u001b[1;32m    202\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 205\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1mAutoml preset training completed in \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mtime_spent))\n\u001b[1;32m    216\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel description:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_model_str_desc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/automl/base.py:223\u001b[0m, in \u001b[0;36mAutoML.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleven_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m train process start. Time left \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mtime_left\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, ml_pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(level):\n\u001b[0;32m--> 223\u001b[0m     pipe_pred \u001b[38;5;241m=\u001b[39m \u001b[43mml_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     level_predictions\u001b[38;5;241m.\u001b[39mappend(pipe_pred)\n\u001b[1;32m    225\u001b[0m     pipes\u001b[38;5;241m.\u001b[39mappend(ml_pipe)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml/pipelines/ml/base.py:162\u001b[0m, in \u001b[0;36mMLPipeline.fit_predict\u001b[0;34m(self, train_valid)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mml_algos\u001b[38;5;241m.\u001b[39mappend(ml_algo)\n\u001b[1;32m    160\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(preds)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mlen\u001b[39m(predictions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    164\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline finished with 0 models for some reason.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProbably one or more models failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m predictions \u001b[38;5;241m=\u001b[39m concatenate(predictions)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ml_algos\n",
      "\u001b[0;31mAssertionError\u001b[0m: Pipeline finished with 0 models for some reason.\nProbably one or more models failed"
     ]
    }
   ],
   "source": [
    "task = Task(data_info['task_type'], device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': ['linear_l2', 'xgb', 'cb']},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "mgpu_fit_pred = automl_mgpu.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2962d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgpu_pred = automl_mgpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(cpu_pred.data.T)\n",
    "print()\n",
    "print(mgpu_pred.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_fit_pred.data.T)\n",
    "print()\n",
    "print(gpu_fit_pred.data.T)\n",
    "print()\n",
    "print(mgpu_fit_pred.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_mgpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgpu_inf = automl_mgpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b02a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "terminate called after throwing an instance of 'thrust::system::system_error'\n",
      "  what():  parallel_for failed: cudaErrorIllegalAddress: an illegal memory access was encountered\n",
      "2022-12-07 14:24:56,856 - distributed.nanny - WARNING - Restarting worker\n",
      "2022-12-07 14:24:57,983 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-12-07 14:24:57,983 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "print(mgpu_inf.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb57a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1dd94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23960d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad26c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0e779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d7bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4509b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af90c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a079f613",
   "metadata": {},
   "source": [
    "# Tutorial 9: Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0676f4e",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial you will learn how to:\n",
    "* train neural networks (nn) with LightAutoML on tabualr data\n",
    "* customize model architecture and pipelines\n",
    "\n",
    "Official LightAutoML github repository is [here](https://github.com/AILab-MLTools/LightAutoML)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bb2c0aa",
   "metadata": {
    "papermill": {
     "duration": 0.032379,
     "end_time": "2021-06-22T20:10:29.835505",
     "exception": false,
     "start_time": "2021-06-22T20:10:29.803126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"../../imgs/LightAutoML_logo_big.png\" alt=\"LightAutoML logo\" style=\"width:100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb2f44",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8496d8",
   "metadata": {},
   "source": [
    "### 0.0. install LightAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58201c72",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-22T20:10:29.980264Z",
     "iopub.status.busy": "2021-06-22T20:10:29.979511Z",
     "iopub.status.idle": "2021-06-22T20:10:52.955439Z",
     "shell.execute_reply": "2021-06-22T20:10:52.953955Z",
     "shell.execute_reply.started": "2021-06-22T19:06:24.534180Z"
    },
    "papermill": {
     "duration": 23.023261,
     "end_time": "2021-06-22T20:10:52.955691",
     "exception": false,
     "start_time": "2021-06-22T20:10:29.932430",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U lightautoml[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1606cb",
   "metadata": {
    "papermill": {
     "duration": 0.066681,
     "end_time": "2021-06-22T20:10:53.090975",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.024294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.1. Import libraries\n",
    "\n",
    "Here we will import the libraries we use in this kernel:\n",
    "- Standard python libraries for timing, working with OS etc.\n",
    "- Essential python DS libraries like numpy, pandas, scikit-learn and torch (the last we will use in the next cell)\n",
    "- LightAutoML modules: presets for AutoML, task and report generation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea2ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:10:53.233356Z",
     "iopub.status.busy": "2021-06-22T20:10:53.232675Z",
     "iopub.status.idle": "2021-06-22T20:11:01.486841Z",
     "shell.execute_reply": "2021-06-22T20:11:01.487566Z",
     "shell.execute_reply.started": "2021-06-22T19:06:43.597648Z"
    },
    "papermill": {
     "duration": 8.32949,
     "end_time": "2021-06-22T20:11:01.487788",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.158298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import optuna\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from copy import deepcopy as copy\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486dff3d",
   "metadata": {
    "papermill": {
     "duration": 0.064234,
     "end_time": "2021-06-22T20:11:01.619010",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.554776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.2. Constants\n",
    "\n",
    "Here we setup the constants to use in the kernel:\n",
    "- `N_THREADS` - number of vCPUs for LightAutoML model creation\n",
    "- `N_FOLDS` - number of folds in LightAutoML inner CV\n",
    "- `RANDOM_STATE` - random seed for better reproducibility\n",
    "- `TEST_SIZE` - houldout data part size \n",
    "- `TIMEOUT` - limit in seconds for model to train\n",
    "- `TARGET_NAME` - target column name in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfd5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:01.758476Z",
     "iopub.status.busy": "2021-06-22T20:11:01.757403Z",
     "iopub.status.idle": "2021-06-22T20:11:01.760870Z",
     "shell.execute_reply": "2021-06-22T20:11:01.760168Z",
     "shell.execute_reply.started": "2021-06-22T19:06:51.523697Z"
    },
    "papermill": {
     "duration": 0.077787,
     "end_time": "2021-06-22T20:11:01.761030",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.683243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 300\n",
    "TARGET_NAME = 'TARGET'\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62e42740",
   "metadata": {},
   "source": [
    "### 0.3. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c3218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '../data/'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/AILab-MLTools/LightAutoML/master/examples/data/sampled_app_train.csv'\n",
    "\n",
    "if not os.path.exists(DATASET_FULLNAME):\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = requests.get(DATASET_URL).text\n",
    "    with open(DATASET_FULLNAME, 'w') as output:\n",
    "        output.write(dataset)\n",
    "\n",
    "data = pd.read_csv(DATASET_FULLNAME)\n",
    "data.head()\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=data[TARGET_NAME], \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7266e9d9",
   "metadata": {},
   "source": [
    "## 1. Task definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc3bd7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.005952Z",
     "iopub.status.busy": "2021-06-22T20:11:23.002234Z",
     "iopub.status.idle": "2021-06-22T20:11:23.009732Z",
     "shell.execute_reply": "2021-06-22T20:11:23.010398Z",
     "shell.execute_reply.started": "2021-06-22T19:07:08.656347Z"
    },
    "papermill": {
     "duration": 0.086442,
     "end_time": "2021-06-22T20:11:23.010643",
     "exception": false,
     "start_time": "2021-06-22T20:11:22.924201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = Task('binary')\n",
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'drop': ['SK_ID_CURR']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f8b1439",
   "metadata": {
    "papermill": {
     "duration": 0.074284,
     "end_time": "2021-06-22T20:11:23.582462",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.508178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3. LightAutoML model creation - TabularAutoML preset with neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56030975",
   "metadata": {
    "papermill": {
     "duration": 0.072649,
     "end_time": "2021-06-22T20:11:23.726154",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.653505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In next the cell we are going to create LightAutoML model with `TabularAutoML` class.\n",
    "\n",
    "in just several lines. Let's discuss the params we can setup:\n",
    "- `task` - the type of the ML task (the only **must have** parameter)\n",
    "- `timeout` - time limit in seconds for model to train\n",
    "- `cpu_limit` - vCPU count for model to use\n",
    "- `nn_params` - network and training params, for example, `\"hidden_size\"`, `\"batch_size\"`, `\"lr\"`, etc.\n",
    "- `nn_pipeline_params` - data preprocessing params, which affect how data is fed to the model: use embeddings or target encoding for categorical columns, standard scalar or quantile transformer for numerical columns\n",
    "- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5d0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = TIMEOUT,\n",
    "    cpu_limit = N_THREADS,\n",
    "    general_params = {\"use_algos\": [[\"mlp\"]]}, # ['nn', 'mlp', 'dense', 'denselight', 'resnet', 'snn'] or custom torch model\n",
    "    nn_params = {\"n_epochs\": 10, \"bs\": 512, \"num_workers\": 0, \"path_to_save\": None},\n",
    "    nn_pipeline_params = {\"use_qnt\": True, \"use_te\": False},\n",
    "    reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ee822",
   "metadata": {},
   "source": [
    "## 2. AutoML training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da4245",
   "metadata": {},
   "source": [
    "To run autoML training use fit_predict method:\n",
    "\n",
    "- `train_data` - Dataset to train.\n",
    "- `roles` - Roles dict.\n",
    "- `verbose` - Controls the verbosity: the higher, the more messages.\n",
    "        <1  : messages are not displayed;\n",
    "        >=1 : the computation process for layers is displayed;\n",
    "        >=2 : the information about folds processing is also displayed;\n",
    "        >=3 : the hyperparameters optimization process is also displayed;\n",
    "        >=4 : the training process for every algorithm is displayed;\n",
    "\n",
    "Note: out-of-fold prediction is calculated during training and returned from the fit_predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc26e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0a58a",
   "metadata": {
    "papermill": {
     "duration": 0.145098,
     "end_time": "2021-06-22T20:34:32.530768",
     "exception": false,
     "start_time": "2021-06-22T20:34:32.385670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Prediction on holdout and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "te_pred = automl.predict(te_data)\n",
    "print(f'Prediction for te_data:\\n{te_pred}\\nShape = {te_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'OOF score: {roc_auc_score(tr_data[TARGET_NAME].values, oof_pred.data[:, 0])}')\n",
    "print(f'HOLDOUT score: {roc_auc_score(te_data[TARGET_NAME].values, te_pred.data[:, 0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9846b4",
   "metadata": {},
   "source": [
    "You can obtain the description of the resulting pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(automl.create_model_str_desc())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a26dc61",
   "metadata": {},
   "source": [
    "## 4. Available built-in models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f43fa090",
   "metadata": {},
   "source": [
    "To use different model pass it to the list in `\"use_algo\"`. We support custom models inherited from `torch.nn.Module` class. For every model their parameters is listed below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ecdf10d",
   "metadata": {},
   "source": [
    "### 4.1. MLP (`\"mlp\"`)\n",
    "- `hidden_size` - define hidden layer dimensions\n",
    "\n",
    "### 4.2. Dense Light (`\"denselight\"`)\n",
    "<img src=\"../../imgs/denselight.png\" style=\"width:25%;\"/>\n",
    "\n",
    "- `hidden_size` - define hidden layer dimensions\n",
    "\n",
    "### 4.3. Dense (`\"dense\"`)\n",
    "<img src=\"../../imgs/densenet.png\" style=\"width:60%;\"/>\n",
    "\n",
    "- `block_config` - set number of blocks and layers within each block\n",
    "- `compression` - portion of neuron to drop after `DenseBlock`\n",
    "- `growth_size` - output dim of every `DenseLayer`\n",
    "- `bn_factor` - size of intermediate fc is increased times this factor in layer\n",
    "\n",
    "### 4.4. Resnet (`\"resnet\"`)\n",
    "<img src=\"../../imgs/resnet.png\" style=\"width:50%;\"/>\n",
    "\n",
    "- `hid_factor` - size of intermediate fc is increased times this factor in layer\n",
    "\n",
    "### 4.5. SNN (`\"snn\"`)\n",
    "- `hidden_size` - define hidden layer dimensions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41d07887",
   "metadata": {},
   "source": [
    "## 5. Main training loop and pipeline params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc28b650",
   "metadata": {},
   "source": [
    "### 5.1 Training loop params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b0633e5",
   "metadata": {},
   "source": [
    "<img src=\"../../imgs/swa.png\" style=\"width:70%;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c7cd871",
   "metadata": {},
   "source": [
    "- `bs` - batch_size\n",
    "- `snap_params` - early stopping and checkpoint averaging params, swa\n",
    "- `opt` - lr optimizer\n",
    "- `opt_params` - optimizer params\n",
    "- `clip_grad` - use grad clipping for regularization\n",
    "- `clip_grad_params`\n",
    "- `emb_dropout` - embedding dropout for categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "401c164c",
   "metadata": {},
   "source": [
    "This set of params should be passed in `nn_params` as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc28b650",
   "metadata": {},
   "source": [
    "### 5.2 Pipeline params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "449bd024",
   "metadata": {},
   "source": [
    "Transformation for numerical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b79443",
   "metadata": {},
   "source": [
    "- `use_qnt` - uses quantile transformation for numerical columns\n",
    "- `output_distribution` - type of distribuiton of feature after qnt transformer\n",
    "- `n_quantiles` - number of quantiles used to build feature distribution\n",
    "- `qnt_factor` - decreses `n_quantiles` depending on train data shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "449bd024",
   "metadata": {},
   "source": [
    "Transformation for categorical columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a910e28",
   "metadata": {},
   "source": [
    "- `use_te` - uses target encoding\n",
    "- `top_intersections` - number of intersections of cat columns to use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79551da5",
   "metadata": {},
   "source": [
    "Full list of default parametres you can find here:\n",
    "- [nn_params](https://github.com/sb-ai-lab/LightAutoML/blob/feature/torch/lightautoml/automl/presets/tabular_config.yml#L126)\n",
    "- [nn_pipeline_params](https://github.com/sb-ai-lab/LightAutoML/blob/feature/torch/lightautoml/automl/presets/tabular_config.yml#L229)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c176647",
   "metadata": {},
   "source": [
    "## 6. More use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c6863d3",
   "metadata": {},
   "source": [
    "Let's remember default Lama params to be more compact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_lama_params = {\n",
    "    \"task\": task, \n",
    "    \"timeout\": TIMEOUT,\n",
    "    \"cpu_limit\": N_THREADS,\n",
    "    \"reader_params\": {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    "}\n",
    "\n",
    "default_nn_params = {\n",
    "    \"bs\": 512, \"num_workers\": 0, \"path_to_save\": None, \"n_epochs\": 10,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f82ac87",
   "metadata": {},
   "source": [
    "### 6.1 Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41519f",
   "metadata": {},
   "source": [
    "Consider simple neural network that we want to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32247a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_in,\n",
    "        n_out,\n",
    "        hidden_size,\n",
    "        drop_rate,\n",
    "        **kwargs, # kwargs is must-have to hold unnecessary parameters\n",
    "    ):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.features = nn.Sequential(OrderedDict([]))\n",
    "\n",
    "        self.features.add_module(\"norm\", nn.BatchNorm1d(n_in))\n",
    "        self.features.add_module(\"dense1\", nn.Linear(n_in, hidden_size))\n",
    "        self.features.add_module(\"act\", nn.SiLU())\n",
    "        self.features.add_module(\"dropout\", nn.Dropout(p=drop_rate))\n",
    "        self.features.add_module(\"dense2\", nn.Linear(hidden_size, n_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: data after feature pipeline transformation\n",
    "            (by default concatenation of columns)\n",
    "        \"\"\"\n",
    "        for layer in self.features:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e359df",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params={\"use_algos\": [[SimpleNet]]},\n",
    "    nn_params={\n",
    "        **default_nn_params,\n",
    "        \"hidden_size\": 256,\n",
    "        \"drop_rate\": 0.1\n",
    "    },\n",
    ")\n",
    "automl.fit_predict(tr_data, roles=roles, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8a589",
   "metadata": {},
   "source": [
    "#### 6.1.2 Define by yourself whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7015726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from typing import Dict\n",
    "from typing import Optional\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class CatEmbedder(nn.Module):\n",
    "    \"\"\"Category data model.\n",
    "\n",
    "    Args:\n",
    "        cat_dims: Sequence with number of unique categories\n",
    "            for category features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cat_dims: Sequence[int],\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(CatEmbedder, self).__init__()\n",
    "        emb_dims = [\n",
    "            (int(x), 5)\n",
    "            for x in cat_dims\n",
    "        ]\n",
    "        self.no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "    \n",
    "    def get_out_shape(self) -> int:\n",
    "        \"\"\"Output shape.\n",
    "\n",
    "        Returns:\n",
    "            Int with module output shape.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.no_of_embs\n",
    "\n",
    "    def forward(self, inp: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Concat all categorical embeddings\n",
    "        \"\"\"\n",
    "        output = torch.cat(\n",
    "            [\n",
    "                emb_layer(inp[\"cat\"][:, i])\n",
    "                for i, emb_layer in enumerate(self.emb_layers)\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "class ContEmbedder(nn.Module):\n",
    "    \"\"\"Numeric data model.\n",
    "\n",
    "    Class for working with numeric data.\n",
    "\n",
    "    Args:\n",
    "        num_dims: Sequence with number of numeric features.\n",
    "        input_bn: Use 1d batch norm for input data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_dims: int,  **kwargs):\n",
    "        super(ContEmbedder, self).__init__()\n",
    "        self.n_out = num_dims\n",
    "    \n",
    "    def get_out_shape(self) -> int:\n",
    "        \"\"\"Output shape.\n",
    "\n",
    "        Returns:\n",
    "            int with module output shape.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.n_out\n",
    "        \n",
    "    def forward(self, inp: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Forward-pass.\"\"\"\n",
    "        return (inp[\"cont\"] - inp[\"cont\"].mean(axis=0)) / inp[\"cont\"].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ea71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.text.nn_model import TorchUniversalModel\n",
    "\n",
    "class SimpleNet_plus(TorchUniversalModel):\n",
    "    \"\"\"Mixed data model.\n",
    "\n",
    "    Class for preparing input for DL model with mixed data.\n",
    "\n",
    "    Args:\n",
    "            n_out: Number of output dimensions.\n",
    "            cont_params: Dict with numeric model params.\n",
    "            cat_params: Dict with category model para\n",
    "            **kwargs: Loss, task and other parameters.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_out: int = 1,\n",
    "            cont_params: Optional[Dict] = None,\n",
    "            cat_params: Optional[Dict] = None,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        # init parent class (need some helper functions to be used)\n",
    "        super(SimpleNet_plus, self).__init__(**{\n",
    "                **kwargs,\n",
    "                \"cont_params\": cont_params,\n",
    "                \"cat_params\": cat_params,\n",
    "                \"torch_model\": None, # dont need any model inside parent class\n",
    "        })\n",
    "        \n",
    "        n_in = 0\n",
    "        \n",
    "        # add cont columns processing\n",
    "        self.cont_embedder = ContEmbedder(**cont_params)\n",
    "        n_in += self.cont_embedder.get_out_shape()\n",
    "        \n",
    "        # add cat columns processing\n",
    "        self.cat_embedder = CatEmbedder(**cat_params)\n",
    "        n_in += self.cat_embedder.get_out_shape()\n",
    "        \n",
    "        self.torch_model = SimpleNet(\n",
    "                **{\n",
    "                    **kwargs,\n",
    "                    **{\"n_in\": n_in, \"n_out\": n_out},\n",
    "                }\n",
    "        )\n",
    "    \n",
    "    def get_logits(self, inp: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        outputs = []\n",
    "        outputs.append(self.cont_embedder(inp))\n",
    "        outputs.append(self.cat_embedder(inp))\n",
    "        \n",
    "        if len(outputs) > 1:\n",
    "            output = torch.cat(outputs, dim=1)\n",
    "        else:\n",
    "            output = outputs[0]\n",
    "        \n",
    "        logits = self.torch_model(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params={\"use_algos\": [[SimpleNet_plus]]},\n",
    "    nn_params={\n",
    "        **default_nn_params,\n",
    "        \"hidden_size\": 256,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"model_with_emb\": True,\n",
    "    },\n",
    "    debug=True\n",
    ")\n",
    "automl.fit_predict(tr_data, roles = roles, verbose = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f82ac87",
   "metadata": {},
   "source": [
    "### 6.2 Tuning network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42c7ac0",
   "metadata": {},
   "source": [
    "One can try optimize metric with the help of Optuna. Among validation stratagies there are:\n",
    "- `fit_on_holdout = True` - holdout\n",
    "- `fit_on_holdout = False` - cross-validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f82ac87",
   "metadata": {},
   "source": [
    "#### 6.2.1 Built-in models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78dfb657",
   "metadata": {},
   "source": [
    "Use `\"_tuned\"` in model name to tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params={\"use_algos\": [[\"denselight_tuned\"]]},\n",
    "    nn_params={\n",
    "        **default_nn_params,\n",
    "        \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 100,\n",
    "            \"fit_on_holdout\": True\n",
    "        }\n",
    "    },\n",
    ")\n",
    "automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f82ac87",
   "metadata": {},
   "source": [
    "#### 6.2.2 Custom model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78dfb657",
   "metadata": {},
   "source": [
    "There is a spesial flag `tuned` to mark that you need optimize parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params={\"use_algos\": [[SimpleNet]]},\n",
    "    nn_params={\n",
    "        **default_nn_params,\n",
    "        \"hidden_size\": 256,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \n",
    "        \"tuned\": True,\n",
    "        \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 100,\n",
    "            \"fit_on_holdout\": True\n",
    "        }\n",
    "    },\n",
    ")\n",
    "automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52aa5e2",
   "metadata": {},
   "source": [
    "Sometimes we need to tune parameters that we define by ourself. To this purpose we have `optimization_search_space` which describes neccesary parameter grid. See example below.  \n",
    "Here is the grid:  \n",
    "- `bs` in `[64, 128, 256, 512, 1024]`\n",
    "- `hidden_size` in `[64, 128, 256, 512, 1024]`\n",
    "- `drop_rate` in `[0.0, 0.3]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e905c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_opt_space(trial: optuna.trial.Trial, estimated_n_trials, suggested_params):\n",
    "    ''' \n",
    "        This fucntion needs for paramer tuning\n",
    "    '''\n",
    "    # optionally\n",
    "    trial_values = copy(suggested_params)\n",
    "\n",
    "    trial_values[\"bs\"] = trial.suggest_categorical(\n",
    "        \"bs\", [2 ** i for i in range(6, 11)]\n",
    "    )\n",
    "    trial_values[\"hidden_size\"] = trial.suggest_categorical(\n",
    "        \"hidden_size\", [2 ** i for i in range(6, 11)]\n",
    "    )\n",
    "    trial_values[\"drop_rate\"] = trial.suggest_float(\n",
    "        \"drop_rate\", 0.0, 0.3\n",
    "    )\n",
    "    return trial_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params={\"use_algos\": [[SimpleNet]]},\n",
    "    nn_params={\n",
    "        **default_nn_params,\n",
    "        \"tuned\": True,\n",
    "        \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 3600,\n",
    "            \"fit_on_holdout\": True\n",
    "        },\n",
    "        \"optimization_search_space\": my_opt_space,\n",
    "    },\n",
    ")\n",
    "automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f82ac87",
   "metadata": {},
   "source": [
    "### 6.3 Several models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f70cafd6",
   "metadata": {},
   "source": [
    "If you have several neural networks you can either define one set parameters for all or use unique for each one of them as below.  \n",
    "**Note:** numeration starts with 0. Each id (string of number) corresponds to the serial number in *the list of used neural networks*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d282b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    **default_lama_params,\n",
    "    general_params = {\"use_algos\": [[\"lgb\", \"mlp\", \"dense\"]]},\n",
    "    nn_params = {\"0\": {**default_nn_params, \"n_epochs\": 2},\n",
    "                 \"1\": {**default_nn_params, \"n_epochs\": 5}},\n",
    ")\n",
    "automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misha-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1531.539656,
   "end_time": "2021-06-22T20:35:52.076563",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T20:10:20.536907",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "627859947abf2d56f3b996a2b10f55a84515683130af72b4b7e3159c07acb31d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

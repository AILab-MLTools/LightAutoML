{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:22:15,386] (INFO): Stdout logging level is INFO.\n"
     ]
    }
   ],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Installed libraries\n",
    "from copy import deepcopy as copy\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import optuna\n",
    "import yaml\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightautoml.pipelines.features.torch_pipeline import TorchSimpleFeatures\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.validation.np_iterators import FoldsIterator\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "from lightautoml.ml_algo.dl_model import TorchModel\n",
    "from lightautoml.ml_algo.torch_based.nn_models import DenseLightModel, DenseModel, ResNetModel, MLP, LinearLayer, SNN\n",
    "from lightautoml.ml_algo.tuning.optuna import DLOptunaTuner\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import logging\n",
    "from lightautoml.utils.logging import set_stdout_level\n",
    "from lightautoml.utils.logging import verbosity_to_loglevel\n",
    "\n",
    "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
    "from lightautoml.addons.interpretation import LimeTextExplainer, L2XTextExplainer\n",
    "from lightautoml.report import ReportDecoNLP\n",
    "\n",
    "# Выключим предупреждения от HuggingFace\n",
    "import transformers\n",
    "transformers.logging.set_verbosity(50)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "logger = logging.getLogger()\n",
    "level = verbosity_to_loglevel(1)\n",
    "set_stdout_level(level)\n",
    "logger.info(f\"Stdout logging level is {logging._levelToName[level]}.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Таски Tabular Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:24:46,891] (INFO2): CatBoost uses as obj. MultiCrossEntropy.\n",
      "[2022-11-12 15:24:46,913] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:24:46,915] (INFO): Task: multilabel\n",
      "\n",
      "[2022-11-12 15:24:46,915] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:24:46,915] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:24:46,916] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:24:46,916] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:24:46,917] (INFO): \u001b[1mTrain data shape: (64, 110)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## multilabel ############\n",
      "multilabel isn`t supported in lgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:24:47,238] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:24:47,252] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.66 secs\n",
      "[2022-11-12 15:24:47,348] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m ...\n",
      "[2022-11-12 15:24:47,349] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:47,350] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:47,372] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:47,372] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:47,373] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.791): 100%|██████████| 2/2 [00:00<00:00, 334.78it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 798.61it/s]\n",
      "[2022-11-12 15:24:47,393] (INFO3): Epoch: 0, train loss: 6.79100227355957, val loss: 7.199702262878418, val metric: -12.42670476436615\n",
      "train (loss=6.74644): 100%|██████████| 2/2 [00:00<00:00, 429.22it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 795.28it/s]\n",
      "[2022-11-12 15:24:47,406] (INFO3): Epoch: 1, train loss: 6.7464399337768555, val loss: 7.198494911193848, val metric: -12.425714008510113\n",
      "[2022-11-12 15:24:47,569] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:47,591] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:47,591] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:47,592] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.81812): 100%|██████████| 2/2 [00:00<00:00, 362.00it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 943.07it/s]\n",
      "[2022-11-12 15:24:47,611] (INFO3): Epoch: 0, train loss: 6.818116188049316, val loss: 7.173430919647217, val metric: -11.088796183466911\n",
      "train (loss=6.76858): 100%|██████████| 2/2 [00:00<00:00, 429.17it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 846.31it/s]\n",
      "[2022-11-12 15:24:47,624] (INFO3): Epoch: 1, train loss: 6.768582820892334, val loss: 7.172205924987793, val metric: -11.08799758553505\n",
      "[2022-11-12 15:24:47,783] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m finished. score = \u001b[1m-11.756855797022581\u001b[0m\n",
      "[2022-11-12 15:24:47,784] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:47,789] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m ...\n",
      "[2022-11-12 15:24:47,790] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:47,791] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:47,812] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:47,813] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:47,814] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.79537): 100%|██████████| 2/2 [00:00<00:00, 150.54it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 391.63it/s]\n",
      "[2022-11-12 15:24:47,853] (INFO3): Epoch: 0, train loss: 6.795368194580078, val loss: 7.200003623962402, val metric: -12.4273137524724\n",
      "train (loss=6.75943): 100%|██████████| 2/2 [00:00<00:00, 178.61it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 399.95it/s]\n",
      "[2022-11-12 15:24:47,879] (INFO3): Epoch: 1, train loss: 6.759426116943359, val loss: 7.200927734375, val metric: -12.427839614450932\n",
      "[2022-11-12 15:24:48,050] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:48,072] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:48,073] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:48,074] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.82612): 100%|██████████| 2/2 [00:00<00:00, 153.62it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 401.71it/s]\n",
      "[2022-11-12 15:24:48,113] (INFO3): Epoch: 0, train loss: 6.826115131378174, val loss: 7.1741180419921875, val metric: -11.089343890547752\n",
      "train (loss=6.78902): 100%|██████████| 2/2 [00:00<00:00, 176.35it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 404.64it/s]\n",
      "[2022-11-12 15:24:48,138] (INFO3): Epoch: 1, train loss: 6.789018154144287, val loss: 7.173944473266602, val metric: -11.089130863547325\n",
      "[2022-11-12 15:24:48,308] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m finished. score = \u001b[1m-11.758485238999128\u001b[0m\n",
      "[2022-11-12 15:24:48,309] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:48,314] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m ...\n",
      "[2022-11-12 15:24:48,315] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:48,316] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:48,338] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:48,339] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:48,339] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.79127): 100%|██████████| 2/2 [00:00<00:00, 71.00it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 202.55it/s]\n",
      "[2022-11-12 15:24:48,419] (INFO3): Epoch: 0, train loss: 6.791266441345215, val loss: 7.2005791664123535, val metric: -12.427657425403595\n",
      "train (loss=6.6532): 100%|██████████| 2/2 [00:00<00:00, 80.24it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 200.75it/s]\n",
      "[2022-11-12 15:24:48,472] (INFO3): Epoch: 1, train loss: 6.653198719024658, val loss: 7.201131820678711, val metric: -12.427717857062817\n",
      "[2022-11-12 15:24:48,666] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:48,688] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:48,689] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:48,690] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.82033): 100%|██████████| 2/2 [00:00<00:00, 71.40it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 197.84it/s]\n",
      "[2022-11-12 15:24:48,769] (INFO3): Epoch: 0, train loss: 6.820330619812012, val loss: 7.174282073974609, val metric: -11.089345015585423\n",
      "train (loss=6.68839): 100%|██████████| 2/2 [00:00<00:00, 78.40it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 196.23it/s]\n",
      "[2022-11-12 15:24:48,822] (INFO3): Epoch: 1, train loss: 6.688388347625732, val loss: 7.175162315368652, val metric: -11.089806020259857\n",
      "[2022-11-12 15:24:49,025] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m finished. score = \u001b[1m-11.758761938661337\u001b[0m\n",
      "[2022-11-12 15:24:49,026] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:49,031] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m ...\n",
      "[2022-11-12 15:24:49,032] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:49,033] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:49,055] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:49,055] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:49,056] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.79451): 100%|██████████| 2/2 [00:00<00:00, 160.36it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 379.40it/s]\n",
      "[2022-11-12 15:24:49,095] (INFO3): Epoch: 0, train loss: 6.794510841369629, val loss: 7.199422359466553, val metric: -12.426857836544514\n",
      "train (loss=6.75871): 100%|██████████| 2/2 [00:00<00:00, 171.95it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 388.72it/s]\n",
      "[2022-11-12 15:24:49,122] (INFO3): Epoch: 1, train loss: 6.758706092834473, val loss: 7.200828552246094, val metric: -12.42749309539795\n",
      "[2022-11-12 15:24:49,302] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:49,325] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:49,326] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:49,326] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.829): 100%|██████████| 2/2 [00:00<00:00, 160.42it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 381.86it/s]\n",
      "[2022-11-12 15:24:49,366] (INFO3): Epoch: 0, train loss: 6.8289995193481445, val loss: 7.174513816833496, val metric: -11.090121410787106\n",
      "train (loss=6.78904): 100%|██████████| 2/2 [00:00<00:00, 174.37it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 380.40it/s]\n",
      "[2022-11-12 15:24:49,392] (INFO3): Epoch: 1, train loss: 6.789044380187988, val loss: 7.172197341918945, val metric: -11.088627442717552\n",
      "[2022-11-12 15:24:49,569] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m finished. score = \u001b[1m-11.75806026905775\u001b[0m\n",
      "[2022-11-12 15:24:49,570] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:49,575] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m ...\n",
      "[2022-11-12 15:24:49,576] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'resnet', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:49,577] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:49,599] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:49,599] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:49,600] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.7934): 100%|██████████| 2/2 [00:00<00:00, 161.59it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 447.23it/s]\n",
      "[2022-11-12 15:24:49,639] (INFO3): Epoch: 0, train loss: 6.793403625488281, val loss: 7.201253890991211, val metric: -12.42797066271305\n",
      "train (loss=6.78015): 100%|██████████| 2/2 [00:00<00:00, 176.28it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 462.97it/s]\n",
      "[2022-11-12 15:24:49,664] (INFO3): Epoch: 1, train loss: 6.780152320861816, val loss: 7.201895713806152, val metric: -12.428280614316463\n",
      "[2022-11-12 15:24:49,822] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:49,845] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:49,845] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:49,846] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.82267): 100%|██████████| 2/2 [00:00<00:00, 160.47it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 447.30it/s]\n",
      "[2022-11-12 15:24:49,880] (INFO3): Epoch: 0, train loss: 6.82267427444458, val loss: 7.172789573669434, val metric: -11.088679999113083\n",
      "train (loss=6.80952): 100%|██████████| 2/2 [00:00<00:00, 167.94it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 437.93it/s]\n",
      "[2022-11-12 15:24:49,905] (INFO3): Epoch: 1, train loss: 6.809518337249756, val loss: 7.172467231750488, val metric: -11.088580794632435\n",
      "[2022-11-12 15:24:50,072] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m finished. score = \u001b[1m-11.75843070447445\u001b[0m\n",
      "[2022-11-12 15:24:50,073] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:50,078] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m ...\n",
      "[2022-11-12 15:24:50,079] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'snn', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([ 0.06252036, -0.25131443, -0.06252036, -0.12516314,  0.18805223,\n",
      "        0.18805223,  0.25131443, -0.12516314,  0.        ,  0.12516314])}\n",
      "[2022-11-12 15:24:50,080] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:50,103] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:50,104] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:50,104] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.79144): 100%|██████████| 2/2 [00:00<00:00, 231.68it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 576.18it/s]\n",
      "[2022-11-12 15:24:50,137] (INFO3): Epoch: 0, train loss: 6.791437149047852, val loss: 7.199483871459961, val metric: -12.426582649350166\n",
      "train (loss=6.74849): 100%|██████████| 2/2 [00:00<00:00, 278.22it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 586.37it/s]\n",
      "[2022-11-12 15:24:50,155] (INFO3): Epoch: 1, train loss: 6.748492240905762, val loss: 7.200366020202637, val metric: -12.426267549395561\n",
      "[2022-11-12 15:24:50,360] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:50,382] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:50,383] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:50,383] (DEBUG): number of continuous features: 100 \n",
      "train (loss=6.81943): 100%|██████████| 2/2 [00:00<00:00, 232.40it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 622.39it/s]\n",
      "[2022-11-12 15:24:50,413] (INFO3): Epoch: 0, train loss: 6.819430351257324, val loss: 7.171879291534424, val metric: -11.088598936796188\n",
      "train (loss=6.76391): 100%|██████████| 2/2 [00:00<00:00, 303.77it/s]\n",
      "val: 100%|██████████| 2/2 [00:00<00:00, 640.21it/s]\n",
      "[2022-11-12 15:24:50,429] (INFO3): Epoch: 1, train loss: 6.763911247253418, val loss: 7.169920921325684, val metric: -11.087665192782879\n",
      "[2022-11-12 15:24:50,628] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m finished. score = \u001b[1m-11.75696637108922\u001b[0m\n",
      "[2022-11-12 15:24:50,630] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:50,631] (INFO): Time left 596.29 secs\n",
      "\n",
      "[2022-11-12 15:24:50,631] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:24:50,634] (INFO): Blending: optimization starts with equal weights and score \u001b[1m-11.757886558771133\u001b[0m\n",
      "[2022-11-12 15:24:50,695] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-11.756853330880404\u001b[0m, weights = \u001b[1m[0.8699692  0.         0.         0.         0.         0.13003083]\u001b[0m\n",
      "[2022-11-12 15:24:50,753] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-11.756853330880404\u001b[0m, weights = \u001b[1m[0.8699692  0.         0.         0.         0.         0.13003083]\u001b[0m\n",
      "[2022-11-12 15:24:50,754] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:24:50,756] (INFO): \u001b[1mAutoml preset training completed in 3.84 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:24:50,757] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.86997 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0) +\n",
      "\t 0.13003 * (2 averaged models Lvl_0_Pipe_0_Mod_5_TorchNN_snn_5) \n",
      "\n",
      "[2022-11-12 15:24:50,857] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:50,858] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:50,858] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 726.16it/s]\n",
      "[2022-11-12 15:24:51,054] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:51,055] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:51,055] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 908.45it/s]\n",
      "[2022-11-12 15:24:51,237] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:51,238] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:51,238] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 722.16it/s]\n",
      "[2022-11-12 15:24:51,430] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:51,430] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:51,431] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 679.46it/s]\n",
      "[2022-11-12 15:24:51,635] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:24:51,637] (INFO): Task: multiclass\n",
      "\n",
      "[2022-11-12 15:24:51,637] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:24:51,638] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:24:51,638] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:24:51,639] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:24:51,639] (INFO): \u001b[1mTrain data shape: (80, 101)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## multiclass ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:24:51,955] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:24:51,969] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.67 secs\n",
      "[2022-11-12 15:24:52,065] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m ...\n",
      "[2022-11-12 15:24:52,066] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:52,067] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:52,090] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:52,090] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:52,091] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.29737): 100%|██████████| 3/3 [00:00<00:00, 290.65it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1029.53it/s]\n",
      "[2022-11-12 15:24:52,115] (INFO3): Epoch: 0, train loss: 2.297368288040161, val loss: 2.3075990676879883, val metric: -2.2946715652942657\n",
      "train (loss=2.26625): 100%|██████████| 3/3 [00:00<00:00, 471.36it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1040.43it/s]\n",
      "[2022-11-12 15:24:52,130] (INFO3): Epoch: 1, train loss: 2.2662534713745117, val loss: 2.306039571762085, val metric: -2.2932505309581757\n",
      "[2022-11-12 15:24:52,291] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:52,313] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:52,314] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:52,314] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.28398): 100%|██████████| 3/3 [00:00<00:00, 394.72it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 958.77it/s]\n",
      "[2022-11-12 15:24:52,338] (INFO3): Epoch: 0, train loss: 2.2839760780334473, val loss: 2.3152191638946533, val metric: -2.3095475852489473\n",
      "train (loss=2.24493): 100%|██████████| 3/3 [00:00<00:00, 476.52it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1072.89it/s]\n",
      "[2022-11-12 15:24:52,353] (INFO3): Epoch: 1, train loss: 2.24493408203125, val loss: 2.3134310245513916, val metric: -2.3085515677928923\n",
      "[2022-11-12 15:24:52,513] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m finished. score = \u001b[1m-2.300901049375534\u001b[0m\n",
      "[2022-11-12 15:24:52,514] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:52,519] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m ...\n",
      "[2022-11-12 15:24:52,520] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:52,521] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:52,543] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:52,544] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:52,544] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.30069): 100%|██████████| 3/3 [00:00<00:00, 163.29it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 458.96it/s]\n",
      "[2022-11-12 15:24:52,590] (INFO3): Epoch: 0, train loss: 2.3006935119628906, val loss: 2.308797597885132, val metric: -2.2958193123340607\n",
      "train (loss=2.29273): 100%|██████████| 3/3 [00:00<00:00, 187.20it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 443.39it/s]\n",
      "[2022-11-12 15:24:52,625] (INFO3): Epoch: 1, train loss: 2.2927253246307373, val loss: 2.3086273670196533, val metric: -2.2955730140209196\n",
      "[2022-11-12 15:24:52,809] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:52,831] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:52,832] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:52,832] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.28268): 100%|██████████| 3/3 [00:00<00:00, 166.70it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 451.73it/s]\n",
      "[2022-11-12 15:24:52,878] (INFO3): Epoch: 0, train loss: 2.2826755046844482, val loss: 2.3151772022247314, val metric: -2.309234493970871\n",
      "train (loss=2.26642): 100%|██████████| 3/3 [00:00<00:00, 183.39it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 452.25it/s]\n",
      "[2022-11-12 15:24:52,910] (INFO3): Epoch: 1, train loss: 2.2664222717285156, val loss: 2.3149030208587646, val metric: -2.3092562198638915\n",
      "[2022-11-12 15:24:53,092] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m finished. score = \u001b[1m-2.302414616942406\u001b[0m\n",
      "[2022-11-12 15:24:53,093] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:53,098] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m ...\n",
      "[2022-11-12 15:24:53,099] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:53,100] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:53,121] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:53,122] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:53,122] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.2997): 100%|██████████| 3/3 [00:00<00:00, 76.46it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 217.89it/s]\n",
      "[2022-11-12 15:24:53,219] (INFO3): Epoch: 0, train loss: 2.299701452255249, val loss: 2.30889630317688, val metric: -2.295899587869644\n",
      "train (loss=2.21144): 100%|██████████| 3/3 [00:00<00:00, 83.04it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 217.23it/s]\n",
      "[2022-11-12 15:24:53,287] (INFO3): Epoch: 1, train loss: 2.2114365100860596, val loss: 2.3074586391448975, val metric: -2.2948158502578737\n",
      "[2022-11-12 15:24:53,509] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:53,531] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:53,532] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:53,532] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.27703): 100%|██████████| 3/3 [00:00<00:00, 75.99it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 217.23it/s]\n",
      "[2022-11-12 15:24:53,628] (INFO3): Epoch: 0, train loss: 2.2770252227783203, val loss: 2.3149712085723877, val metric: -2.309041917324066\n",
      "train (loss=2.19639): 100%|██████████| 3/3 [00:00<00:00, 84.01it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 217.78it/s]\n",
      "[2022-11-12 15:24:53,695] (INFO3): Epoch: 1, train loss: 2.1963918209075928, val loss: 2.314345598220825, val metric: -2.3089878141880034\n",
      "[2022-11-12 15:24:53,918] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m finished. score = \u001b[1m-2.3019018322229385\u001b[0m\n",
      "[2022-11-12 15:24:53,919] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:53,924] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m ...\n",
      "[2022-11-12 15:24:53,925] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:53,926] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:53,948] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:53,949] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:53,949] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.30681): 100%|██████████| 3/3 [00:00<00:00, 172.69it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 414.02it/s]\n",
      "[2022-11-12 15:24:53,996] (INFO3): Epoch: 0, train loss: 2.3068106174468994, val loss: 2.3079984188079834, val metric: -2.2957103967666628\n",
      "train (loss=2.27522): 100%|██████████| 3/3 [00:00<00:00, 180.88it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 414.92it/s]\n",
      "[2022-11-12 15:24:54,030] (INFO3): Epoch: 1, train loss: 2.275219678878784, val loss: 2.308088541030884, val metric: -2.2955059587955473\n",
      "[2022-11-12 15:24:54,205] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:54,227] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:54,228] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:54,228] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.28769): 100%|██████████| 3/3 [00:00<00:00, 144.63it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 411.53it/s]\n",
      "[2022-11-12 15:24:54,279] (INFO3): Epoch: 0, train loss: 2.287688970565796, val loss: 2.315610885620117, val metric: -2.308912640810013\n",
      "train (loss=2.26845): 100%|██████████| 3/3 [00:00<00:00, 179.59it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 443.76it/s]\n",
      "[2022-11-12 15:24:54,314] (INFO3): Epoch: 1, train loss: 2.268450975418091, val loss: 2.3151028156280518, val metric: -2.3091935217380524\n",
      "[2022-11-12 15:24:54,511] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m finished. score = \u001b[1m-2.3023497402668\u001b[0m\n",
      "[2022-11-12 15:24:54,512] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:54,517] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m ...\n",
      "[2022-11-12 15:24:54,518] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'resnet', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:54,519] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:54,542] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:54,542] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:54,543] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.2958): 100%|██████████| 3/3 [00:00<00:00, 170.54it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 526.31it/s]\n",
      "[2022-11-12 15:24:54,584] (INFO3): Epoch: 0, train loss: 2.2957956790924072, val loss: 2.3089425563812256, val metric: -2.2960129976272583\n",
      "train (loss=2.2909): 100%|██████████| 3/3 [00:00<00:00, 187.73it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 510.69it/s]\n",
      "[2022-11-12 15:24:54,616] (INFO3): Epoch: 1, train loss: 2.2909018993377686, val loss: 2.3087048530578613, val metric: -2.2958188235759733\n",
      "[2022-11-12 15:24:54,817] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:54,839] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:54,840] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:54,841] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.28065): 100%|██████████| 3/3 [00:00<00:00, 172.82it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 518.82it/s]\n",
      "[2022-11-12 15:24:54,881] (INFO3): Epoch: 0, train loss: 2.280651807785034, val loss: 2.315549373626709, val metric: -2.3091574132442476\n",
      "train (loss=2.29219): 100%|██████████| 3/3 [00:00<00:00, 185.18it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 548.16it/s]\n",
      "[2022-11-12 15:24:54,911] (INFO3): Epoch: 1, train loss: 2.2921934127807617, val loss: 2.3156449794769287, val metric: -2.30918430685997\n",
      "[2022-11-12 15:24:55,083] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m finished. score = \u001b[1m-2.302501565217972\u001b[0m\n",
      "[2022-11-12 15:24:55,084] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:55,089] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m ...\n",
      "[2022-11-12 15:24:55,090] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'snn', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-2.07944153, -2.18480205, -2.18480205, -2.30258508, -2.30258508,\n",
      "       -2.30258508, -2.30258508, -2.43611647, -2.43611647, -2.59026715])}\n",
      "[2022-11-12 15:24:55,091] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:55,113] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:55,113] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:55,114] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.30639): 100%|██████████| 3/3 [00:00<00:00, 254.45it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 716.24it/s]\n",
      "[2022-11-12 15:24:55,149] (INFO3): Epoch: 0, train loss: 2.3063900470733643, val loss: 2.306121587753296, val metric: -2.2938471913337706\n",
      "train (loss=2.26292): 100%|██████████| 3/3 [00:00<00:00, 299.56it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 700.92it/s]\n",
      "[2022-11-12 15:24:55,170] (INFO3): Epoch: 1, train loss: 2.262918472290039, val loss: 2.3052284717559814, val metric: -2.2941260278224944\n",
      "[2022-11-12 15:24:55,342] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:55,364] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:55,365] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:55,365] (DEBUG): number of continuous features: 100 \n",
      "train (loss=2.30049): 100%|██████████| 3/3 [00:00<00:00, 263.49it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 701.98it/s]\n",
      "[2022-11-12 15:24:55,399] (INFO3): Epoch: 0, train loss: 2.300485372543335, val loss: 2.3116979598999023, val metric: -2.3063536465167997\n",
      "train (loss=2.25039): 100%|██████████| 3/3 [00:00<00:00, 300.90it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 704.69it/s]\n",
      "[2022-11-12 15:24:55,420] (INFO3): Epoch: 1, train loss: 2.2503905296325684, val loss: 2.307096242904663, val metric: -2.3030641317367553\n",
      "[2022-11-12 15:24:55,586] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m finished. score = \u001b[1m-2.298595079779625\u001b[0m\n",
      "[2022-11-12 15:24:55,587] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:55,588] (INFO): Time left 596.05 secs\n",
      "\n",
      "[2022-11-12 15:24:55,588] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:24:55,591] (INFO): Blending: optimization starts with equal weights and score \u001b[1m-2.3013725876808167\u001b[0m\n",
      "[2022-11-12 15:24:55,637] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-2.298595079779625\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:24:55,675] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-2.298595079779625\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:24:55,676] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:24:55,678] (INFO): \u001b[1mAutoml preset training completed in 4.04 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:24:55,679] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_5_TorchNN_snn_5) \n",
      "\n",
      "[2022-11-12 15:24:55,776] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:55,776] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:55,777] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1011.28it/s]\n",
      "[2022-11-12 15:24:55,959] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:55,960] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:55,960] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1059.84it/s]\n",
      "[2022-11-12 15:24:56,161] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:24:56,163] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:24:56,163] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:24:56,164] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:24:56,164] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:24:56,164] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:24:56,165] (INFO): \u001b[1mTrain data shape: (80, 101)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## binary ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:24:56,432] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:24:56,446] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.72 secs\n",
      "[2022-11-12 15:24:56,542] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m ...\n",
      "[2022-11-12 15:24:56,543] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:56,544] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:56,566] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:56,566] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:56,567] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.685804): 100%|██████████| 3/3 [00:00<00:00, 368.24it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 837.74it/s]\n",
      "[2022-11-12 15:24:56,590] (INFO3): Epoch: 0, train loss: 0.6858036518096924, val loss: 0.6913996338844299, val metric: 0.5934343434343434\n",
      "train (loss=0.67914): 100%|██████████| 3/3 [00:00<00:00, 421.10it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 843.19it/s]\n",
      "[2022-11-12 15:24:56,607] (INFO3): Epoch: 1, train loss: 0.6791397929191589, val loss: 0.6904460787773132, val metric: 0.6085858585858586\n",
      "[2022-11-12 15:24:56,767] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:24:56,789] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:56,790] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:56,790] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.685304): 100%|██████████| 3/3 [00:00<00:00, 386.56it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 892.47it/s]\n",
      "[2022-11-12 15:24:56,813] (INFO3): Epoch: 0, train loss: 0.6853042244911194, val loss: 0.6892287135124207, val metric: 0.5907928388746803\n",
      "train (loss=0.675918): 100%|██████████| 3/3 [00:00<00:00, 419.11it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 875.21it/s]\n",
      "[2022-11-12 15:24:56,830] (INFO3): Epoch: 1, train loss: 0.67591792345047, val loss: 0.6892142295837402, val metric: 0.5754475703324808\n",
      "[2022-11-12 15:24:56,991] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m finished. score = \u001b[1m0.5333333333333333\u001b[0m\n",
      "[2022-11-12 15:24:56,992] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:56,997] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m ...\n",
      "[2022-11-12 15:24:56,998] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:56,999] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:57,021] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:57,021] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:57,022] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.68635): 100%|██████████| 3/3 [00:00<00:00, 160.02it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 428.34it/s]\n",
      "[2022-11-12 15:24:57,069] (INFO3): Epoch: 0, train loss: 0.6863495707511902, val loss: 0.6917582154273987, val metric: 0.606060606060606\n",
      "train (loss=0.678831): 100%|██████████| 3/3 [00:00<00:00, 179.02it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 424.64it/s]\n",
      "[2022-11-12 15:24:57,103] (INFO3): Epoch: 1, train loss: 0.678830623626709, val loss: 0.691510021686554, val metric: 0.5707070707070707\n",
      "[2022-11-12 15:24:57,275] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:24:57,297] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:57,298] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:57,298] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.690098): 100%|██████████| 3/3 [00:00<00:00, 162.15it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 423.28it/s]\n",
      "[2022-11-12 15:24:57,345] (INFO3): Epoch: 0, train loss: 0.690098226070404, val loss: 0.6899738311767578, val metric: 0.4373401534526854\n",
      "train (loss=0.687632): 100%|██████████| 3/3 [00:00<00:00, 182.05it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 426.31it/s]\n",
      "[2022-11-12 15:24:57,378] (INFO3): Epoch: 1, train loss: 0.6876316666603088, val loss: 0.6898297667503357, val metric: 0.5319693094629155\n",
      "[2022-11-12 15:24:57,555] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m finished. score = \u001b[1m0.5130158730158729\u001b[0m\n",
      "[2022-11-12 15:24:57,556] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:57,562] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m ...\n",
      "[2022-11-12 15:24:57,562] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:57,563] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:57,585] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:57,586] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:57,586] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.686567): 100%|██████████| 3/3 [00:00<00:00, 76.05it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 217.97it/s]\n",
      "[2022-11-12 15:24:57,682] (INFO3): Epoch: 0, train loss: 0.6865670084953308, val loss: 0.6918818354606628, val metric: 0.5404040404040404\n",
      "train (loss=0.656209): 100%|██████████| 3/3 [00:00<00:00, 83.83it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 215.38it/s]\n",
      "[2022-11-12 15:24:57,749] (INFO3): Epoch: 1, train loss: 0.6562087535858154, val loss: 0.6917209625244141, val metric: 0.5631313131313131\n",
      "[2022-11-12 15:24:57,943] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:24:57,965] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:57,966] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:57,966] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.680762): 100%|██████████| 3/3 [00:00<00:00, 77.08it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 215.03it/s]\n",
      "[2022-11-12 15:24:58,061] (INFO3): Epoch: 0, train loss: 0.680761992931366, val loss: 0.6896316409111023, val metric: 0.557544757033248\n",
      "train (loss=0.666478): 100%|██████████| 3/3 [00:00<00:00, 82.45it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 215.38it/s]\n",
      "[2022-11-12 15:24:58,128] (INFO3): Epoch: 1, train loss: 0.666478157043457, val loss: 0.6893386244773865, val metric: 0.5703324808184144\n",
      "[2022-11-12 15:24:58,319] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m finished. score = \u001b[1m0.5206349206349206\u001b[0m\n",
      "[2022-11-12 15:24:58,319] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:58,325] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m ...\n",
      "[2022-11-12 15:24:58,325] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:58,326] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:58,348] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:58,348] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:58,349] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.68543): 100%|██████████| 3/3 [00:00<00:00, 172.36it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 405.78it/s]\n",
      "[2022-11-12 15:24:58,395] (INFO3): Epoch: 0, train loss: 0.6854304671287537, val loss: 0.6913010478019714, val metric: 0.5757575757575757\n",
      "train (loss=0.678128): 100%|██████████| 3/3 [00:00<00:00, 176.80it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 405.64it/s]\n",
      "[2022-11-12 15:24:58,429] (INFO3): Epoch: 1, train loss: 0.6781277060508728, val loss: 0.6906313300132751, val metric: 0.5681818181818181\n",
      "[2022-11-12 15:24:58,600] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:24:58,622] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:58,623] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:58,623] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.688963): 100%|██████████| 3/3 [00:00<00:00, 171.32it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 407.98it/s]\n",
      "[2022-11-12 15:24:58,669] (INFO3): Epoch: 0, train loss: 0.6889632344245911, val loss: 0.6891754269599915, val metric: 0.6930946291560103\n",
      "train (loss=0.685531): 100%|██████████| 3/3 [00:00<00:00, 177.27it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 411.49it/s]\n",
      "[2022-11-12 15:24:58,703] (INFO3): Epoch: 1, train loss: 0.685530960559845, val loss: 0.6887500882148743, val metric: 0.6419437340153453\n",
      "[2022-11-12 15:24:58,875] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m finished. score = \u001b[1m0.5396825396825398\u001b[0m\n",
      "[2022-11-12 15:24:58,875] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:58,880] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m ...\n",
      "[2022-11-12 15:24:58,881] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'resnet', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:58,882] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:58,904] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:58,904] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:58,905] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.692107): 100%|██████████| 3/3 [00:00<00:00, 172.03it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 498.85it/s]\n",
      "[2022-11-12 15:24:58,946] (INFO3): Epoch: 0, train loss: 0.6921065449714661, val loss: 0.691903829574585, val metric: 0.4823232323232324\n",
      "train (loss=0.683299): 100%|██████████| 3/3 [00:00<00:00, 179.72it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 498.45it/s]\n",
      "[2022-11-12 15:24:58,977] (INFO3): Epoch: 1, train loss: 0.6832990050315857, val loss: 0.69175785779953, val metric: 0.5\n",
      "[2022-11-12 15:24:59,161] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:24:59,183] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:59,184] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:59,185] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.694365): 100%|██████████| 3/3 [00:00<00:00, 167.97it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 495.57it/s]\n",
      "[2022-11-12 15:24:59,225] (INFO3): Epoch: 0, train loss: 0.6943654417991638, val loss: 0.6897029876708984, val metric: 0.6265984654731458\n",
      "train (loss=0.688452): 100%|██████████| 3/3 [00:00<00:00, 175.56it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 522.65it/s]\n",
      "[2022-11-12 15:24:59,257] (INFO3): Epoch: 1, train loss: 0.6884519457817078, val loss: 0.6896486878395081, val metric: 0.6112531969309463\n",
      "[2022-11-12 15:24:59,424] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m finished. score = \u001b[1m0.514920634920635\u001b[0m\n",
      "[2022-11-12 15:24:59,425] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:59,430] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m ...\n",
      "[2022-11-12 15:24:59,431] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'snn', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([-0.25131443])}\n",
      "[2022-11-12 15:24:59,432] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:59,456] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:59,457] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:59,457] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.673838): 100%|██████████| 3/3 [00:00<00:00, 254.15it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 631.83it/s]\n",
      "[2022-11-12 15:24:59,491] (INFO3): Epoch: 0, train loss: 0.6738377213478088, val loss: 0.6893795132637024, val metric: 0.6161616161616162\n",
      "train (loss=0.659513): 100%|██████████| 3/3 [00:00<00:00, 299.96it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 649.71it/s]\n",
      "[2022-11-12 15:24:59,513] (INFO3): Epoch: 1, train loss: 0.6595125198364258, val loss: 0.686622142791748, val metric: 0.6313131313131313\n",
      "[2022-11-12 15:24:59,680] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:24:59,702] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:24:59,703] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:24:59,703] (DEBUG): number of continuous features: 100 \n",
      "train (loss=0.685907): 100%|██████████| 3/3 [00:00<00:00, 257.05it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 658.62it/s]\n",
      "[2022-11-12 15:24:59,737] (INFO3): Epoch: 0, train loss: 0.6859073638916016, val loss: 0.6893401145935059, val metric: 0.5652173913043479\n",
      "train (loss=0.68939): 100%|██████████| 3/3 [00:00<00:00, 290.57it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 681.89it/s]\n",
      "[2022-11-12 15:24:59,759] (INFO3): Epoch: 1, train loss: 0.6893897652626038, val loss: 0.688286304473877, val metric: 0.6112531969309463\n",
      "[2022-11-12 15:24:59,937] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m finished. score = \u001b[1m0.5536507936507936\u001b[0m\n",
      "[2022-11-12 15:24:59,938] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:24:59,939] (INFO): Time left 596.23 secs\n",
      "\n",
      "[2022-11-12 15:24:59,939] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:24:59,942] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5453968253968253\u001b[0m\n",
      "[2022-11-12 15:24:59,990] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5523809523809524\u001b[0m, weights = \u001b[1m[0.         0.         0.         0.12212352 0.08889876 0.7889777 ]\u001b[0m\n",
      "[2022-11-12 15:25:00,039] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5561904761904762\u001b[0m, weights = \u001b[1m[0.         0.         0.         0.6080981  0.10081306 0.29108882]\u001b[0m\n",
      "[2022-11-12 15:25:00,087] (INFO): Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.5561904761904762\u001b[0m, weights = \u001b[1m[0.         0.         0.         0.6080981  0.10081306 0.29108882]\u001b[0m\n",
      "[2022-11-12 15:25:00,088] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:25:00,089] (INFO): \u001b[1mAutoml preset training completed in 3.92 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:25:00,090] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.60810 * (2 averaged models Lvl_0_Pipe_0_Mod_3_TorchNN_denselight_3) +\n",
      "\t 0.10081 * (2 averaged models Lvl_0_Pipe_0_Mod_4_TorchNN_resnet_4) +\n",
      "\t 0.29109 * (2 averaged models Lvl_0_Pipe_0_Mod_5_TorchNN_snn_5) \n",
      "\n",
      "[2022-11-12 15:25:00,188] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:00,189] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:00,189] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 752.14it/s]\n",
      "[2022-11-12 15:25:00,387] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:00,387] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:00,388] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 708.68it/s]\n",
      "[2022-11-12 15:25:00,580] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:00,581] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:00,581] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 697.66it/s]\n",
      "[2022-11-12 15:25:00,765] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:00,766] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:00,766] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 686.97it/s]\n",
      "[2022-11-12 15:25:00,952] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:00,953] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:00,954] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1040.64it/s]\n",
      "[2022-11-12 15:25:01,141] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:01,142] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:01,142] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1029.28it/s]\n",
      "[2022-11-12 15:25:01,344] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:25:01,346] (INFO): Task: reg\n",
      "\n",
      "[2022-11-12 15:25:01,347] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:25:01,347] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:25:01,348] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:25:01,348] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:25:01,349] (INFO): \u001b[1mTrain data shape: (80, 101)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## reg ############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:25:01,604] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:25:01,618] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.73 secs\n",
      "[2022-11-12 15:25:01,716] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m ...\n",
      "[2022-11-12 15:25:01,717] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:01,718] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:25:01,739] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:01,740] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:01,740] (DEBUG): number of continuous features: 100 \n",
      "train (loss=46683.7): 100%|██████████| 3/3 [00:00<00:00, 378.10it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1056.15it/s]\n",
      "[2022-11-12 15:25:01,762] (INFO3): Epoch: 0, train loss: 46683.73828125, val loss: 32706.150390625, val metric: -32636.23046875\n",
      "train (loss=36882.9): 100%|██████████| 3/3 [00:00<00:00, 445.30it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1076.29it/s]\n",
      "[2022-11-12 15:25:01,777] (INFO3): Epoch: 1, train loss: 36882.9375, val loss: 32705.4375, val metric: -32635.59765625\n",
      "[2022-11-12 15:25:01,936] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:25:01,958] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:01,959] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:01,960] (DEBUG): number of continuous features: 100 \n",
      "train (loss=30636.6): 100%|██████████| 3/3 [00:00<00:00, 402.94it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1067.80it/s]\n",
      "[2022-11-12 15:25:01,981] (INFO3): Epoch: 0, train loss: 30636.556640625, val loss: 41729.875, val metric: -42416.08203125\n",
      "train (loss=33739.5): 100%|██████████| 3/3 [00:00<00:00, 430.80it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1137.08it/s]\n",
      "[2022-11-12 15:25:01,996] (INFO3): Epoch: 1, train loss: 33739.5, val loss: 41729.46484375, val metric: -42415.59375\n",
      "[2022-11-12 15:25:02,161] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m finished. score = \u001b[1m-37525.596030105764\u001b[0m\n",
      "[2022-11-12 15:25:02,162] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:02,167] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m ...\n",
      "[2022-11-12 15:25:02,168] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:02,169] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:25:02,191] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:02,192] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:02,192] (DEBUG): number of continuous features: 100 \n",
      "train (loss=45106.4): 100%|██████████| 3/3 [00:00<00:00, 160.46it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 464.93it/s]\n",
      "[2022-11-12 15:25:02,240] (INFO3): Epoch: 0, train loss: 45106.421875, val loss: 32706.751953125, val metric: -32636.787109375\n",
      "train (loss=43894.7): 100%|██████████| 3/3 [00:00<00:00, 182.97it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 453.65it/s]\n",
      "[2022-11-12 15:25:02,272] (INFO3): Epoch: 1, train loss: 43894.72265625, val loss: 32706.603515625, val metric: -32636.697265625\n",
      "[2022-11-12 15:25:02,448] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:25:02,470] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:02,471] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:02,471] (DEBUG): number of continuous features: 100 \n",
      "train (loss=29784): 100%|██████████| 3/3 [00:00<00:00, 164.76it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 475.17it/s]\n",
      "[2022-11-12 15:25:02,516] (INFO3): Epoch: 0, train loss: 29784.013671875, val loss: 41730.640625, val metric: -42416.78125\n",
      "train (loss=33161): 100%|██████████| 3/3 [00:00<00:00, 147.12it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 464.81it/s]\n",
      "[2022-11-12 15:25:02,553] (INFO3): Epoch: 1, train loss: 33160.95703125, val loss: 41730.75, val metric: -42416.9296875\n",
      "[2022-11-12 15:25:02,755] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m finished. score = \u001b[1m-37526.81263174462\u001b[0m\n",
      "[2022-11-12 15:25:02,756] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:02,761] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m ...\n",
      "[2022-11-12 15:25:02,762] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:02,763] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:25:02,785] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:02,786] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:02,786] (DEBUG): number of continuous features: 100 \n",
      "train (loss=42092.4): 100%|██████████| 3/3 [00:00<00:00, 76.12it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 226.10it/s]\n",
      "[2022-11-12 15:25:02,885] (INFO3): Epoch: 0, train loss: 42092.40234375, val loss: 32706.4921875, val metric: -32636.494140625\n",
      "train (loss=38958): 100%|██████████| 3/3 [00:00<00:00, 82.98it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 224.74it/s]\n",
      "[2022-11-12 15:25:02,954] (INFO3): Epoch: 1, train loss: 38958.01953125, val loss: 32706.380859375, val metric: -32636.29296875\n",
      "[2022-11-12 15:25:03,156] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:25:03,179] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:03,180] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:03,180] (DEBUG): number of continuous features: 100 \n",
      "train (loss=28556.3): 100%|██████████| 3/3 [00:00<00:00, 76.94it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 224.12it/s]\n",
      "[2022-11-12 15:25:03,274] (INFO3): Epoch: 0, train loss: 28556.322265625, val loss: 41729.96484375, val metric: -42416.23046875\n",
      "train (loss=33645.5): 100%|██████████| 3/3 [00:00<00:00, 82.26it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 225.58it/s]\n",
      "[2022-11-12 15:25:03,340] (INFO3): Epoch: 1, train loss: 33645.546875, val loss: 41729.078125, val metric: -42415.35546875\n",
      "[2022-11-12 15:25:03,555] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m finished. score = \u001b[1m-37525.82565343795\u001b[0m\n",
      "[2022-11-12 15:25:03,556] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:03,562] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m ...\n",
      "[2022-11-12 15:25:03,562] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:03,563] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:25:03,585] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:03,586] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:03,587] (DEBUG): number of continuous features: 100 \n",
      "train (loss=51621.9): 100%|██████████| 3/3 [00:00<00:00, 169.69it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 431.35it/s]\n",
      "[2022-11-12 15:25:03,633] (INFO3): Epoch: 0, train loss: 51621.86328125, val loss: 32706.458984375, val metric: -32636.45703125\n",
      "train (loss=42008.3): 100%|██████████| 3/3 [00:00<00:00, 179.48it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 441.65it/s]\n",
      "[2022-11-12 15:25:03,666] (INFO3): Epoch: 1, train loss: 42008.30078125, val loss: 32706.103515625, val metric: -32636.197265625\n",
      "[2022-11-12 15:25:03,836] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:25:03,858] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:03,859] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:03,859] (DEBUG): number of continuous features: 100 \n",
      "train (loss=31816.4): 100%|██████████| 3/3 [00:00<00:00, 175.44it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 437.12it/s]\n",
      "[2022-11-12 15:25:03,904] (INFO3): Epoch: 0, train loss: 31816.357421875, val loss: 41729.87890625, val metric: -42416.1328125\n",
      "train (loss=29076.6): 100%|██████████| 3/3 [00:00<00:00, 178.52it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 445.44it/s]\n",
      "[2022-11-12 15:25:03,937] (INFO3): Epoch: 1, train loss: 29076.587890625, val loss: 41729.33203125, val metric: -42415.5234375\n",
      "[2022-11-12 15:25:04,107] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m finished. score = \u001b[1m-37525.86010213454\u001b[0m\n",
      "[2022-11-12 15:25:04,108] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:04,114] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m ...\n",
      "[2022-11-12 15:25:04,114] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'resnet', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:04,115] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:25:04,137] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:04,138] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:04,138] (DEBUG): number of continuous features: 100 \n",
      "train (loss=42652.6): 100%|██████████| 3/3 [00:00<00:00, 173.73it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 555.32it/s]\n",
      "[2022-11-12 15:25:04,177] (INFO3): Epoch: 0, train loss: 42652.58984375, val loss: 32706.771484375, val metric: -32636.759765625\n",
      "train (loss=44942.6): 100%|██████████| 3/3 [00:00<00:00, 179.53it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 565.35it/s]\n",
      "[2022-11-12 15:25:04,208] (INFO3): Epoch: 1, train loss: 44942.609375, val loss: 32706.748046875, val metric: -32636.712890625\n",
      "[2022-11-12 15:25:04,374] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:25:04,396] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:04,397] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:04,398] (DEBUG): number of continuous features: 100 \n",
      "train (loss=29865.8): 100%|██████████| 3/3 [00:00<00:00, 176.53it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 543.30it/s]\n",
      "[2022-11-12 15:25:04,436] (INFO3): Epoch: 0, train loss: 29865.818359375, val loss: 41730.3203125, val metric: -42416.6015625\n",
      "train (loss=34594.9): 100%|██████████| 3/3 [00:00<00:00, 182.14it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 555.44it/s]\n",
      "[2022-11-12 15:25:04,466] (INFO3): Epoch: 1, train loss: 34594.91015625, val loss: 41730.296875, val metric: -42416.609375\n",
      "[2022-11-12 15:25:04,630] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m finished. score = \u001b[1m-37526.660007621256\u001b[0m\n",
      "[2022-11-12 15:25:04,630] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:04,636] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m ...\n",
      "[2022-11-12 15:25:04,636] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'snn', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([17.98725037])}\n",
      "[2022-11-12 15:25:04,637] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:25:04,659] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:04,660] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:04,661] (DEBUG): number of continuous features: 100 \n",
      "train (loss=38734.3): 100%|██████████| 3/3 [00:00<00:00, 260.96it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 727.38it/s]\n",
      "[2022-11-12 15:25:04,694] (INFO3): Epoch: 0, train loss: 38734.33984375, val loss: 32703.146484375, val metric: -32633.162109375\n",
      "train (loss=39894.3): 100%|██████████| 3/3 [00:00<00:00, 308.75it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 750.32it/s]\n",
      "[2022-11-12 15:25:04,713] (INFO3): Epoch: 1, train loss: 39894.2890625, val loss: 32699.658203125, val metric: -32629.755859375\n",
      "[2022-11-12 15:25:04,874] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:25:04,896] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:04,897] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:04,897] (DEBUG): number of continuous features: 100 \n",
      "train (loss=35886.7): 100%|██████████| 3/3 [00:00<00:00, 266.06it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 709.34it/s]\n",
      "[2022-11-12 15:25:04,930] (INFO3): Epoch: 0, train loss: 35886.66015625, val loss: 41726.83984375, val metric: -42412.69140625\n",
      "train (loss=30640.2): 100%|██████████| 3/3 [00:00<00:00, 312.50it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 710.58it/s]\n",
      "[2022-11-12 15:25:04,950] (INFO3): Epoch: 1, train loss: 30640.203125, val loss: 41723.3125, val metric: -42409.06640625\n",
      "[2022-11-12 15:25:05,117] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m finished. score = \u001b[1m-37519.40987923918\u001b[0m\n",
      "[2022-11-12 15:25:05,118] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:05,119] (INFO): Time left 596.23 secs\n",
      "\n",
      "[2022-11-12 15:25:05,119] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:25:05,121] (INFO): Blending: optimization starts with equal weights and score \u001b[1m-37525.02724130977\u001b[0m\n",
      "[2022-11-12 15:25:05,141] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-37519.40987923918\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:25:05,158] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-37519.40987923918\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:25:05,159] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:25:05,161] (INFO): \u001b[1mAutoml preset training completed in 3.81 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:25:05,161] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_5_TorchNN_snn_5) \n",
      "\n",
      "[2022-11-12 15:25:05,259] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:05,259] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:05,260] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1081.84it/s]\n",
      "[2022-11-12 15:25:05,447] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:05,448] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:05,448] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1030.16it/s]\n",
      "[2022-11-12 15:25:05,626] (INFO2): CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n",
      "[2022-11-12 15:25:05,648] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:25:05,650] (INFO): Task: multi:reg\n",
      "\n",
      "[2022-11-12 15:25:05,650] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:25:05,651] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:25:05,651] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:25:05,651] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:25:05,652] (INFO): \u001b[1mTrain data shape: (80, 110)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## multi:reg ############\n",
      "multi:reg isn`t supported in lgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:25:05,958] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:25:05,971] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.68 secs\n",
      "[2022-11-12 15:25:06,067] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m ...\n",
      "[2022-11-12 15:25:06,068] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:06,069] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:25:06,090] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:06,091] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:06,092] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1386.28): 100%|██████████| 3/3 [00:00<00:00, 403.48it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1191.56it/s]\n",
      "[2022-11-12 15:25:06,112] (INFO3): Epoch: 0, train loss: 1386.2750244140625, val loss: 1607.1688232421875, val metric: -154.9119415283203\n",
      "train (loss=1376.18): 100%|██████████| 3/3 [00:00<00:00, 440.47it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1096.45it/s]\n",
      "[2022-11-12 15:25:06,127] (INFO3): Epoch: 1, train loss: 1376.1763916015625, val loss: 1607.1591796875, val metric: -154.9110107421875\n",
      "[2022-11-12 15:25:06,286] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m =====\n",
      "[2022-11-12 15:25:06,308] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:06,309] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:06,309] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1530.32): 100%|██████████| 3/3 [00:00<00:00, 413.10it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1039.39it/s]\n",
      "[2022-11-12 15:25:06,330] (INFO3): Epoch: 0, train loss: 1530.3236083984375, val loss: 1410.8585205078125, val metric: -137.92210388183594\n",
      "train (loss=1512.35): 100%|██████████| 3/3 [00:00<00:00, 454.62it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 1053.76it/s]\n",
      "[2022-11-12 15:25:06,345] (INFO3): Epoch: 1, train loss: 1512.3482666015625, val loss: 1410.845703125, val metric: -137.92086791992188\n",
      "[2022-11-12 15:25:06,504] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m finished. score = \u001b[1m-146.4159433300809\u001b[0m\n",
      "[2022-11-12 15:25:06,505] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_linear_layer_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:06,510] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m ...\n",
      "[2022-11-12 15:25:06,511] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:06,512] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:25:06,534] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:06,535] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:06,535] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1409.6): 100%|██████████| 3/3 [00:00<00:00, 163.54it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 456.51it/s]\n",
      "[2022-11-12 15:25:06,581] (INFO3): Epoch: 0, train loss: 1409.6025390625, val loss: 1607.1783447265625, val metric: -154.9127197265625\n",
      "train (loss=1348.39): 100%|██████████| 3/3 [00:00<00:00, 185.27it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 461.72it/s]\n",
      "[2022-11-12 15:25:06,612] (INFO3): Epoch: 1, train loss: 1348.3914794921875, val loss: 1607.173828125, val metric: -154.9122772216797\n",
      "[2022-11-12 15:25:06,779] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m =====\n",
      "[2022-11-12 15:25:06,801] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:06,802] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:06,803] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1580.24): 100%|██████████| 3/3 [00:00<00:00, 165.91it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 465.24it/s]\n",
      "[2022-11-12 15:25:06,847] (INFO3): Epoch: 0, train loss: 1580.2398681640625, val loss: 1410.8756103515625, val metric: -137.9232635498047\n",
      "train (loss=1503.76): 100%|██████████| 3/3 [00:00<00:00, 185.21it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 461.00it/s]\n",
      "[2022-11-12 15:25:06,878] (INFO3): Epoch: 1, train loss: 1503.7601318359375, val loss: 1410.8675537109375, val metric: -137.9224395751953\n",
      "[2022-11-12 15:25:07,050] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m finished. score = \u001b[1m-146.4173523573593\u001b[0m\n",
      "[2022-11-12 15:25:07,051] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_mlp_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:07,056] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m ...\n",
      "[2022-11-12 15:25:07,057] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:07,058] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:25:07,079] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:07,080] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:07,080] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1388.22): 100%|██████████| 3/3 [00:00<00:00, 76.64it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 225.48it/s]\n",
      "[2022-11-12 15:25:07,174] (INFO3): Epoch: 0, train loss: 1388.2193603515625, val loss: 1607.17578125, val metric: -154.91250610351562\n",
      "train (loss=1332.29): 100%|██████████| 3/3 [00:00<00:00, 83.00it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 223.36it/s]\n",
      "[2022-11-12 15:25:07,240] (INFO3): Epoch: 1, train loss: 1332.289794921875, val loss: 1607.1751708984375, val metric: -154.9125518798828\n",
      "[2022-11-12 15:25:07,434] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m =====\n",
      "[2022-11-12 15:25:07,456] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:07,457] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:07,457] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1493.27): 100%|██████████| 3/3 [00:00<00:00, 76.61it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 223.74it/s]\n",
      "[2022-11-12 15:25:07,550] (INFO3): Epoch: 0, train loss: 1493.2708740234375, val loss: 1410.8748779296875, val metric: -137.92355346679688\n",
      "train (loss=1454.27): 100%|██████████| 3/3 [00:00<00:00, 84.01it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 225.99it/s]\n",
      "[2022-11-12 15:25:07,615] (INFO3): Epoch: 1, train loss: 1454.2703857421875, val loss: 1410.8724365234375, val metric: -137.9234161376953\n",
      "[2022-11-12 15:25:07,819] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m finished. score = \u001b[1m-146.41797338977614\u001b[0m\n",
      "[2022-11-12 15:25:07,820] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_2_TorchNN_dense_2\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:07,825] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m ...\n",
      "[2022-11-12 15:25:07,826] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'denselight', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:07,827] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:25:07,849] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:07,850] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:07,850] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1323.36): 100%|██████████| 3/3 [00:00<00:00, 168.91it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 434.85it/s]\n",
      "[2022-11-12 15:25:07,896] (INFO3): Epoch: 0, train loss: 1323.361572265625, val loss: 1607.1739501953125, val metric: -154.91213989257812\n",
      "train (loss=1348.3): 100%|██████████| 3/3 [00:00<00:00, 178.23it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 443.31it/s]\n",
      "[2022-11-12 15:25:07,929] (INFO3): Epoch: 1, train loss: 1348.3028564453125, val loss: 1607.1630859375, val metric: -154.9109344482422\n",
      "[2022-11-12 15:25:08,110] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m =====\n",
      "[2022-11-12 15:25:08,132] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:08,133] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:08,133] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1630.37): 100%|██████████| 3/3 [00:00<00:00, 174.13it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 441.32it/s]\n",
      "[2022-11-12 15:25:08,178] (INFO3): Epoch: 0, train loss: 1630.3720703125, val loss: 1410.86962890625, val metric: -137.9230499267578\n",
      "train (loss=1560.15): 100%|██████████| 3/3 [00:00<00:00, 178.83it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 440.33it/s]\n",
      "[2022-11-12 15:25:08,210] (INFO3): Epoch: 1, train loss: 1560.1497802734375, val loss: 1410.8558349609375, val metric: -137.92147827148438\n",
      "[2022-11-12 15:25:08,381] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m finished. score = \u001b[1m-146.41620827272692\u001b[0m\n",
      "[2022-11-12 15:25:08,382] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_3_TorchNN_denselight_3\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:08,387] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m ...\n",
      "[2022-11-12 15:25:08,388] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'resnet', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:08,389] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:25:08,410] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:08,411] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:08,412] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1360.59): 100%|██████████| 3/3 [00:00<00:00, 173.40it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 534.10it/s]\n",
      "[2022-11-12 15:25:08,451] (INFO3): Epoch: 0, train loss: 1360.5938720703125, val loss: 1607.17626953125, val metric: -154.9125213623047\n",
      "train (loss=1379.71): 100%|██████████| 3/3 [00:00<00:00, 179.12it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 544.17it/s]\n",
      "[2022-11-12 15:25:08,481] (INFO3): Epoch: 1, train loss: 1379.7144775390625, val loss: 1607.1748046875, val metric: -154.91236877441406\n",
      "[2022-11-12 15:25:08,650] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m =====\n",
      "[2022-11-12 15:25:08,672] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:08,672] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:08,673] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1565.74): 100%|██████████| 3/3 [00:00<00:00, 172.38it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 498.89it/s]\n",
      "[2022-11-12 15:25:08,713] (INFO3): Epoch: 0, train loss: 1565.7418212890625, val loss: 1410.8773193359375, val metric: -137.92361450195312\n",
      "train (loss=1541.53): 100%|██████████| 3/3 [00:00<00:00, 184.38it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 549.02it/s]\n",
      "[2022-11-12 15:25:08,743] (INFO3): Epoch: 1, train loss: 1541.5284423828125, val loss: 1410.8740234375, val metric: -137.92340087890625\n",
      "[2022-11-12 15:25:08,909] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m finished. score = \u001b[1m-146.41788595065628\u001b[0m\n",
      "[2022-11-12 15:25:08,910] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_4_TorchNN_resnet_4\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:08,915] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m ...\n",
      "[2022-11-12 15:25:08,916] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'snn', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 10, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__col_0', 'qntl_tr__fillnamed__fillinf__col_1', 'qntl_tr__fillnamed__fillinf__col_10', 'qntl_tr__fillnamed__fillinf__col_11', 'qntl_tr__fillnamed__fillinf__col_12', 'qntl_tr__fillnamed__fillinf__col_13', 'qntl_tr__fillnamed__fillinf__col_14', 'qntl_tr__fillnamed__fillinf__col_15', 'qntl_tr__fillnamed__fillinf__col_16', 'qntl_tr__fillnamed__fillinf__col_17', 'qntl_tr__fillnamed__fillinf__col_18', 'qntl_tr__fillnamed__fillinf__col_19', 'qntl_tr__fillnamed__fillinf__col_2', 'qntl_tr__fillnamed__fillinf__col_20', 'qntl_tr__fillnamed__fillinf__col_21', 'qntl_tr__fillnamed__fillinf__col_22', 'qntl_tr__fillnamed__fillinf__col_23', 'qntl_tr__fillnamed__fillinf__col_24', 'qntl_tr__fillnamed__fillinf__col_25', 'qntl_tr__fillnamed__fillinf__col_26', 'qntl_tr__fillnamed__fillinf__col_27', 'qntl_tr__fillnamed__fillinf__col_28', 'qntl_tr__fillnamed__fillinf__col_29', 'qntl_tr__fillnamed__fillinf__col_3', 'qntl_tr__fillnamed__fillinf__col_30', 'qntl_tr__fillnamed__fillinf__col_31', 'qntl_tr__fillnamed__fillinf__col_32', 'qntl_tr__fillnamed__fillinf__col_33', 'qntl_tr__fillnamed__fillinf__col_34', 'qntl_tr__fillnamed__fillinf__col_35', 'qntl_tr__fillnamed__fillinf__col_36', 'qntl_tr__fillnamed__fillinf__col_37', 'qntl_tr__fillnamed__fillinf__col_38', 'qntl_tr__fillnamed__fillinf__col_39', 'qntl_tr__fillnamed__fillinf__col_4', 'qntl_tr__fillnamed__fillinf__col_40', 'qntl_tr__fillnamed__fillinf__col_41', 'qntl_tr__fillnamed__fillinf__col_42', 'qntl_tr__fillnamed__fillinf__col_43', 'qntl_tr__fillnamed__fillinf__col_44', 'qntl_tr__fillnamed__fillinf__col_45', 'qntl_tr__fillnamed__fillinf__col_46', 'qntl_tr__fillnamed__fillinf__col_47', 'qntl_tr__fillnamed__fillinf__col_48', 'qntl_tr__fillnamed__fillinf__col_49', 'qntl_tr__fillnamed__fillinf__col_5', 'qntl_tr__fillnamed__fillinf__col_50', 'qntl_tr__fillnamed__fillinf__col_51', 'qntl_tr__fillnamed__fillinf__col_52', 'qntl_tr__fillnamed__fillinf__col_53', 'qntl_tr__fillnamed__fillinf__col_54', 'qntl_tr__fillnamed__fillinf__col_55', 'qntl_tr__fillnamed__fillinf__col_56', 'qntl_tr__fillnamed__fillinf__col_57', 'qntl_tr__fillnamed__fillinf__col_58', 'qntl_tr__fillnamed__fillinf__col_59', 'qntl_tr__fillnamed__fillinf__col_6', 'qntl_tr__fillnamed__fillinf__col_60', 'qntl_tr__fillnamed__fillinf__col_61', 'qntl_tr__fillnamed__fillinf__col_62', 'qntl_tr__fillnamed__fillinf__col_63', 'qntl_tr__fillnamed__fillinf__col_64', 'qntl_tr__fillnamed__fillinf__col_65', 'qntl_tr__fillnamed__fillinf__col_66', 'qntl_tr__fillnamed__fillinf__col_67', 'qntl_tr__fillnamed__fillinf__col_68', 'qntl_tr__fillnamed__fillinf__col_69', 'qntl_tr__fillnamed__fillinf__col_7', 'qntl_tr__fillnamed__fillinf__col_70', 'qntl_tr__fillnamed__fillinf__col_71', 'qntl_tr__fillnamed__fillinf__col_72', 'qntl_tr__fillnamed__fillinf__col_73', 'qntl_tr__fillnamed__fillinf__col_74', 'qntl_tr__fillnamed__fillinf__col_75', 'qntl_tr__fillnamed__fillinf__col_76', 'qntl_tr__fillnamed__fillinf__col_77', 'qntl_tr__fillnamed__fillinf__col_78', 'qntl_tr__fillnamed__fillinf__col_79', 'qntl_tr__fillnamed__fillinf__col_8', 'qntl_tr__fillnamed__fillinf__col_80', 'qntl_tr__fillnamed__fillinf__col_81', 'qntl_tr__fillnamed__fillinf__col_82', 'qntl_tr__fillnamed__fillinf__col_83', 'qntl_tr__fillnamed__fillinf__col_84', 'qntl_tr__fillnamed__fillinf__col_85', 'qntl_tr__fillnamed__fillinf__col_86', 'qntl_tr__fillnamed__fillinf__col_87', 'qntl_tr__fillnamed__fillinf__col_88', 'qntl_tr__fillnamed__fillinf__col_89', 'qntl_tr__fillnamed__fillinf__col_9', 'qntl_tr__fillnamed__fillinf__col_90', 'qntl_tr__fillnamed__fillinf__col_91', 'qntl_tr__fillnamed__fillinf__col_92', 'qntl_tr__fillnamed__fillinf__col_93', 'qntl_tr__fillnamed__fillinf__col_94', 'qntl_tr__fillnamed__fillinf__col_95', 'qntl_tr__fillnamed__fillinf__col_96', 'qntl_tr__fillnamed__fillinf__col_97', 'qntl_tr__fillnamed__fillinf__col_98', 'qntl_tr__fillnamed__fillinf__col_99'], 'cont_dim': 100, 'text_features': [], 'bias': array([14.03746576,  3.50116741, 13.60382973, 19.21111579, 32.21949593,\n",
      "        5.58611665, 13.65008146, -2.12210827,  8.13468841, 14.34978645])}\n",
      "[2022-11-12 15:25:08,917] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:25:08,939] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:08,940] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:08,940] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1389.97): 100%|██████████| 3/3 [00:00<00:00, 262.13it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 712.63it/s]\n",
      "[2022-11-12 15:25:08,973] (INFO3): Epoch: 0, train loss: 1389.9654541015625, val loss: 1607.1480712890625, val metric: -154.91018676757812\n",
      "train (loss=1345.29): 100%|██████████| 3/3 [00:00<00:00, 296.14it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 796.94it/s]\n",
      "[2022-11-12 15:25:08,993] (INFO3): Epoch: 1, train loss: 1345.2891845703125, val loss: 1607.1021728515625, val metric: -154.90599060058594\n",
      "[2022-11-12 15:25:09,157] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m =====\n",
      "[2022-11-12 15:25:09,179] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:09,180] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:09,180] (DEBUG): number of continuous features: 100 \n",
      "train (loss=1468.67): 100%|██████████| 3/3 [00:00<00:00, 260.79it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 749.65it/s]\n",
      "[2022-11-12 15:25:09,213] (INFO3): Epoch: 0, train loss: 1468.67333984375, val loss: 1410.8433837890625, val metric: -137.9213409423828\n",
      "train (loss=1542.02): 100%|██████████| 3/3 [00:00<00:00, 304.18it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 804.02it/s]\n",
      "[2022-11-12 15:25:09,233] (INFO3): Epoch: 1, train loss: 1542.0152587890625, val loss: 1410.8101806640625, val metric: -137.9187774658203\n",
      "[2022-11-12 15:25:09,406] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m finished. score = \u001b[1m-146.4123910479263\u001b[0m\n",
      "[2022-11-12 15:25:09,407] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_5_TorchNN_snn_5\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:25:09,408] (INFO): Time left 596.24 secs\n",
      "\n",
      "[2022-11-12 15:25:09,408] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:25:09,410] (INFO): Blending: optimization starts with equal weights and score \u001b[1m-146.41629243865765\u001b[0m\n",
      "[2022-11-12 15:25:09,438] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-146.4123910479263\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:25:09,460] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-146.4123910479263\u001b[0m, weights = \u001b[1m[0. 0. 0. 0. 0. 1.]\u001b[0m\n",
      "[2022-11-12 15:25:09,461] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:25:09,463] (INFO): \u001b[1mAutoml preset training completed in 3.81 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:25:09,464] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_5_TorchNN_snn_5) \n",
      "\n",
      "[2022-11-12 15:25:09,564] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:09,565] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:09,565] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1130.84it/s]\n",
      "[2022-11-12 15:25:09,749] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:25:09,750] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:25:09,750] (DEBUG): number of continuous features: 100 \n",
      "test: 100%|██████████| 2/2 [00:00<00:00, 1102.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_data_multireg(n_targets=10):\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression(n_targets=n_targets, random_state=1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    \n",
    "    RANDOM_STATE = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    train = pd.DataFrame(data=X_train, columns=['col_' + str(i) for i in range(X_train.shape[1])])\n",
    "    test = pd.DataFrame(data=X_test, columns=['col_' + str(i) for i in range(X_test.shape[1])])\n",
    "\n",
    "    test_cols = []\n",
    "    for i in range(y.shape[1]):\n",
    "        col = 'target_' + str(i)\n",
    "        train[col] = y_train[:, i]\n",
    "        test[col] = y_test[:, i]\n",
    "        test_cols.append(col)\n",
    "\n",
    "    return train, test, test_cols\n",
    "\n",
    "def get_data_multiclass(n_classes=10, rs=1):\n",
    "    from sklearn.datasets import make_classification\n",
    "    X, y = make_classification(n_classes=n_classes, n_informative=30, n_features=100, random_state=rs)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "\n",
    "    RANDOM_STATE = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    train = pd.DataFrame(data=X_train, columns=['col_' + str(i) for i in range(X_train.shape[1])])\n",
    "    test = pd.DataFrame(data=X_test, columns=['col_' + str(i) for i in range(X_test.shape[1])])\n",
    "\n",
    "    test_cols = []\n",
    "    for i in range(y.shape[1]):\n",
    "        col = 'target_' + str(i)\n",
    "        train[col] = y_train[:, i]\n",
    "        test[col] = y_test[:, i]\n",
    "        test_cols.append(col)\n",
    "    \n",
    "    return train, test, test_cols\n",
    "\n",
    "\n",
    "def get_data_reg():\n",
    "    return get_data_multireg(1)\n",
    "\n",
    "def get_data_binary(rs=10):\n",
    "    return get_data_multiclass(2, rs=rs)\n",
    "\n",
    "\n",
    "def get_data_multilabel(n_labels=10):\n",
    "    X = []\n",
    "    y = []\n",
    "    for l in range(n_labels):\n",
    "        train, test, _ = get_data_binary(rs=l)\n",
    "        X = train.values[:, :-1]\n",
    "        y.append(train.values[:, -1].flatten().tolist())\n",
    "    \n",
    "    y = np.array(y).T\n",
    "    \n",
    "    RANDOM_STATE = 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    train = pd.DataFrame(data=X_train, columns=['col_' + str(i) for i in range(X_train.shape[1])])\n",
    "    test = pd.DataFrame(data=X_test, columns=['col_' + str(i) for i in range(X_test.shape[1])])\n",
    "\n",
    "    test_cols = []\n",
    "    for i in range(y.shape[1]):\n",
    "        col = 'target_' + str(i)\n",
    "        train[col] = y_train[:, i]\n",
    "        test[col] = y_test[:, i]\n",
    "        test_cols.append(col)\n",
    "\n",
    "    return train, test, test_cols\n",
    "\n",
    "\n",
    "tasks_to_data = {\n",
    "    \"multilabel\": get_data_multilabel,\n",
    "    \"multiclass\": get_data_multiclass,\n",
    "    \"binary\": get_data_binary,\n",
    "    \"reg\": get_data_reg,\n",
    "    \"multi:reg\": get_data_multireg,\n",
    "}\n",
    "\n",
    "res = {}\n",
    "# def logloss(true, pred, sample_weight=None, **kwargs):\n",
    "#     mask = sample_weight > 0\n",
    "#     return (true[mask] == pred[mask]).mean()\n",
    "\n",
    "for task in tasks_to_data:\n",
    "    print(\"##########\", task, \"############\")\n",
    "    train, test, test_cols = tasks_to_data[task]()\n",
    "    \n",
    "    # train[\"weight\"] = np.random.randn(len(train))\n",
    "    roles = {'target': test_cols}\n",
    "    task = Task(task)#, metric=logloss, greater_is_better=False,\n",
    "                # loss=\"quantile\", loss_params={\"q\": 0.1})\n",
    "    \n",
    "    automl = TabularAutoML(\n",
    "        task=task,\n",
    "        timeout=600,\n",
    "        general_params={\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"linear_layer\",\n",
    "                    \"mlp\",\n",
    "                    \"dense\",\n",
    "                    \"denselight\",\n",
    "                    \"resnet\",\n",
    "                    \"snn\"\n",
    "                ],\n",
    "            ],\n",
    "            \"nested_cv\": False,\n",
    "            \"skip_conn\": False,\n",
    "        },\n",
    "        reader_params={\"cv\": 2},\n",
    "        nn_params={\n",
    "            \"n_epochs\": 2, \"bs\": 16, \"num_workers\": 0, \"path_to_save\": None,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    oof = automl.fit_predict(train, roles)\n",
    "    preds_te = automl.predict(test)\n",
    "    \n",
    "    res[task._name] = dict()\n",
    "    res[task._name][\"model\"] = automl\n",
    "    res[task._name][\"oof\"] = oof\n",
    "    res[task._name][\"preds_te\"] = preds_te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Игра с параметрами Tabular Preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_in,\n",
    "        n_out,\n",
    "        hidden_size=128,\n",
    "        drop_rate=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.features = nn.Sequential(OrderedDict([]))\n",
    "\n",
    "        self.features.add_module(\"norm\", nn.BatchNorm1d(n_in))\n",
    "        self.features.add_module(\"dense1\", nn.Linear(n_in, hidden_size))\n",
    "        self.features.add_module(\"act\", nn.SiLU())\n",
    "        self.features.add_module(\"dropout\", nn.Dropout(p=drop_rate))\n",
    "        self.features.add_module(\"dense2\", nn.Linear(hidden_size, n_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.features:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "def my_opt_space(trial: optuna.trial.Trial, estimated_n_trials, suggested_params):\n",
    "    # optionally\n",
    "    trial_values = copy(suggested_params)\n",
    "\n",
    "    trial_values[\"bs\"] = trial.suggest_categorical(\n",
    "        \"bs\", [2 ** i for i in range(6, 11)]\n",
    "    )\n",
    "    trial_values[\"hidden_size\"] = trial.suggest_categorical(\n",
    "        \"hidden_size\", [2 ** i for i in range(6, 11)]\n",
    "    )\n",
    "    trial_values[\"drop_rate\"] = trial.suggest_float(\n",
    "        \"drop_rate\", 0.0, 0.3\n",
    "    )\n",
    "    return trial_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"0\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"nn\",\n",
    "                    \"lgbm\",\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"n_epochs\": 2\n",
    "        }\n",
    "    },\n",
    "    \"1\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"dense\",\n",
    "                    \"lgbm\",\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "           \"n_epochs\": 2,\n",
    "        }\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"lgbm\",\n",
    "                    \"mlp\",\n",
    "                    \"dense\",\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"0\": {\"n_epochs\": 2},\n",
    "            \"1\": {\"n_epochs\": 5}\n",
    "        }\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"lgbm\",\n",
    "                    \"mlp_tuned\",\n",
    "                    \"dense\",\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"0\": {\"n_epochs\": 2},\n",
    "            \"1\": {\"n_epochs\": 5},\n",
    "            \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 3600,\n",
    "            \"fit_on_holdout\": True,\n",
    "        }\n",
    "        },\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"mlp_tuned\",\n",
    "                    \"dense_tuned\",\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"0\": {\"n_epochs\": 2},\n",
    "            \"1\": {\"n_epochs\": 5},\n",
    "            \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 3600,\n",
    "            \"fit_on_holdout\": True,\n",
    "        }\n",
    "        },\n",
    "    },\n",
    "    \"5\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    \"lgbm\",\n",
    "                    MLP\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"tuned\": True,\n",
    "            \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 3600,\n",
    "            \"fit_on_holdout\": True,\n",
    "        }\n",
    "        },\n",
    "    },\n",
    "    \"6\": {\n",
    "        \"general_params\": {\n",
    "            \"use_algos\": [\n",
    "                [\n",
    "                    # \"lgb,\n",
    "                    SimpleNet\n",
    "                ],\n",
    "            ],\n",
    "        },\n",
    "        \"nn_params\": {\n",
    "            \"tuned\": True,\n",
    "            \"optimization_search_space\": my_opt_space,\n",
    "            \"tuning_params\": {\n",
    "            \"max_tuning_iter\": 5,\n",
    "            \"max_tuning_time\": 3600,\n",
    "            \"fit_on_holdout\": True,\n",
    "        }\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:12,213] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:12,215] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:12,215] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:12,216] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:12,216] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:12,216] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:12,217] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:12,262] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:12,265] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.95 secs\n",
      "[2022-11-12 15:28:12,272] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m ... Time budget is 314.97 secs\n",
      "[2022-11-12 15:28:12,274] (INFO): A new study created in memory with name: no-name-45d48ece-c4fd-4850-90fe-262a70868da7\n",
      "[2022-11-12 15:28:12,278] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:12,279] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:12,279] (DEBUG): number of continuous features: 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "############ CONFIG ############\n",
      "{'general_params': {'use_algos': [['lgbm',\n",
      "                                   <class 'lightautoml.ml_algo.torch_based.nn_models.MLP'>]]},\n",
      " 'nn_params': {'tuned': True,\n",
      "               'tuning_params': {'fit_on_holdout': True,\n",
      "                                 'max_tuning_iter': 5,\n",
      "                                 'max_tuning_time': 3600}}}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:13,042] (INFO): Trial 0 finished with value: 0.5766060606060607 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.5766060606060607.\n",
      "[2022-11-12 15:28:13,046] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.5766060606060607 in 0:00:00.767212\n",
      "[2022-11-12 15:28:13,051] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:13,051] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:13,051] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:13,528] (INFO): Trial 1 finished with value: 0.5976242424242424 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 1 with value: 0.5976242424242424.\n",
      "[2022-11-12 15:28:13,532] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.5976242424242424 in 0:00:00.480910\n",
      "[2022-11-12 15:28:13,536] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:13,537] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:13,537] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:13,954] (INFO): Trial 2 finished with value: 0.458860606060606 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 1 with value: 0.5976242424242424.\n",
      "[2022-11-12 15:28:13,958] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.458860606060606 in 0:00:00.421225\n",
      "[2022-11-12 15:28:13,962] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:13,963] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:13,963] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:15,117] (INFO): Trial 3 finished with value: 0.594230303030303 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 1 with value: 0.5976242424242424.\n",
      "[2022-11-12 15:28:15,121] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.594230303030303 in 0:00:01.158408\n",
      "[2022-11-12 15:28:15,126] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:15,126] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:15,127] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:15,868] (INFO): Trial 4 finished with value: 0.5790545454545455 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 1 with value: 0.5976242424242424.\n",
      "[2022-11-12 15:28:15,873] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.5790545454545455 in 0:00:00.746264\n",
      "[2022-11-12 15:28:15,874] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m completed\n",
      "[2022-11-12 15:28:15,874] (INFO2): The set of hyperparameters \u001b[1m{'bs': 512, 'opt_params': {'lr': 5.415244119402538e-05, 'weight_decay': 0}}\u001b[0m\n",
      " achieve 0.5976 auc\n",
      "[2022-11-12 15:28:15,875] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m ...\n",
      "[2022-11-12 15:28:15,876] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': <class 'lightautoml.ml_algo.torch_based.nn_models.MLP'>, 'path_to_save': None, 'verbose_inside': None, 'verbose': None, 'n_epochs': 20, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 5.415244119402538e-05, 'weight_decay': 0}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': True, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'act_fun': 'ReLU', 'bert_name': None, 'bn_factor': 2, 'bs': 512, 'clip_grad': False, 'clip_grad_params': {}, 'compression': 0.5, 'dataset': 'UniversalDataset', 'deterministic': True, 'device': 'cuda:0', 'drop_rate': 0.1, 'emb_dropout': 0.1, 'emb_ratio': 3, 'growth_size': 256, 'hidden_size': [512, 512, 512], 'init_bias': True, 'input_bn': False, 'is_snap': False, 'lang': 'en', 'loss': None, 'loss_on_logits': True, 'loss_params': {}, 'max_emb_size': 256, 'max_length': 256, 'model': 'dense', 'multigpu': False, 'n_epochs': 20, 'n_out': None, 'num_workers': 0, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'path_to_save': './models/model', 'pin_memory': False, 'pooling': 'cls', 'random_state': 42, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'factor': 0.01, 'min_lr': 1e-05, 'patience': 10}, 'snap_params': {'early_stopping': True, 'k': 3, 'patience': 16, 'swa': True}, 'use_bn': True, 'use_cat': True, 'use_cont': True, 'use_dropout': True, 'use_noise': False, 'use_text': True, 'verbose': 1, 'verbose_inside': None, 'tuned': False}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'freeze_defaults': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:15,877] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m =====\n",
      "[2022-11-12 15:28:15,880] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:15,881] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:15,881] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:16,346] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m =====\n",
      "[2022-11-12 15:28:16,349] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:16,350] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:16,350] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:16,819] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m finished. score = \u001b[1m0.5722909090909091\u001b[0m\n",
      "[2022-11-12 15:28:16,820] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:16,821] (INFO): Time left 595.40 secs\n",
      "\n",
      "[2022-11-12 15:28:16,821] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:16,822] (INFO): \u001b[1mAutoml preset training completed in 4.60 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:16,822] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_0) \n",
      "\n",
      "[2022-11-12 15:28:16,831] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:16,832] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:16,832] (DEBUG): number of continuous features: 1 \n",
      "[2022-11-12 15:28:17,020] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:17,020] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:17,021] (DEBUG): number of continuous features: 1 \n"
     ]
    }
   ],
   "source": [
    "for _id, config in configs.items():\n",
    "    if _id != \"5\":\n",
    "        continue\n",
    "    \n",
    "    print(\"\\n\\n\\n\\n############ CONFIG ############\")\n",
    "    pprint(config)\n",
    "    print(\"################################\")\n",
    "    \n",
    "    _config = config\n",
    "    _config[\"nn_params\"] = {**_config[\"nn_params\"], \"path_to_save\": None, \"verbose\": None,}\n",
    "    automl = TabularAutoML(\n",
    "        debug=True,\n",
    "        task=task,\n",
    "        timeout=600,\n",
    "        reader_params={\"cv\": 2},\n",
    "        **_config\n",
    "    )\n",
    "\n",
    "    oof_pred = automl.fit_predict(train, roles=roles)\n",
    "    test_pred = automl.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] Stdout logging level is INFO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,568] (INFO): Stdout logging level is INFO.\n",
      "[2022-11-12 15:28:18,570] (INFO3): Model language mode: ru\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,570] (INFO): Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,571] (INFO): Start automl preset with listed constraints:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] - time: 3600.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,571] (INFO): - time: 3600.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,572] (INFO): - CPU: 4 cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,573] (INFO): - memory: 16 GB\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,574] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:18,614] (INFO3): Feats was rejected during automatic roles guess: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.96 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,617] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 3599.96 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:18] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:18,638] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m ...\n",
      "[2022-11-12 15:28:18,639] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 50, 'bert_name': 'cointegrated/rubert-tiny', 'pooling': 'mean', 'device': device(type='cuda', index=0), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'ru', 'deterministic': False, 'multigpu': False, 'random_state': 42, 'model': '_linear_layer', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False}, 'bs': 16, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 1e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 5, 'factor': 0.5, 'verbose': True}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'stop_by_metric': False, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['scaler__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': ['concated__bank__message'], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:18,643] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m =====\n",
      "[2022-11-12 15:28:22,237] (DEBUG): number of text features: 1 \n",
      "[2022-11-12 15:28:22,238] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:22,238] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.511838): 100%|██████████| 30/30 [00:01<00:00, 19.24it/s]\n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 28.51it/s]\n",
      "[2022-11-12 15:28:25,580] (INFO3): Epoch: 0, train loss: 0.5118376016616821, val loss: 0.5182452201843262, val metric: 0.7353260869565218\n",
      "train (loss=0.53042): 100%|██████████| 30/30 [00:01<00:00, 20.00it/s] \n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 28.16it/s]\n",
      "[2022-11-12 15:28:27,663] (INFO3): Epoch: 1, train loss: 0.5304203629493713, val loss: 0.517903745174408, val metric: 0.7857065217391305\n",
      "[2022-11-12 15:28:28,092] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m =====\n",
      "[2022-11-12 15:28:31,745] (DEBUG): number of text features: 1 \n",
      "[2022-11-12 15:28:31,746] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:31,746] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.511765): 100%|██████████| 30/30 [00:01<00:00, 19.03it/s]\n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 29.74it/s]\n",
      "[2022-11-12 15:28:35,087] (INFO3): Epoch: 0, train loss: 0.5117647051811218, val loss: 0.520179808139801, val metric: 0.6645901639344262\n",
      "train (loss=0.511433): 100%|██████████| 30/30 [00:01<00:00, 19.65it/s]\n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 29.52it/s]\n",
      "[2022-11-12 15:28:37,175] (INFO3): Epoch: 1, train loss: 0.5114332437515259, val loss: 0.5199509263038635, val metric: 0.6716939890710383\n",
      "[2022-11-12 15:28:37,609] (INFO2): ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m =====\n",
      "[2022-11-12 15:28:41,232] (DEBUG): number of text features: 1 \n",
      "[2022-11-12 15:28:41,234] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:41,234] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.535249): 100%|██████████| 30/30 [00:01<00:00, 19.32it/s]\n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 28.92it/s]\n",
      "[2022-11-12 15:28:44,535] (INFO3): Epoch: 0, train loss: 0.5352486371994019, val loss: 0.5201278924942017, val metric: 0.7313661202185793\n",
      "train (loss=0.523132): 100%|██████████| 30/30 [00:01<00:00, 19.73it/s]\n",
      "val: 100%|██████████| 15/15 [00:00<00:00, 29.65it/s]\n",
      "[2022-11-12 15:28:46,616] (INFO3): Epoch: 1, train loss: 0.5231319069862366, val loss: 0.5197635889053345, val metric: 0.7355191256830601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m finished. score = \u001b[1m0.7236848484848485\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,044] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m finished. score = \u001b[1m0.7236848484848485\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,045] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN\u001b[0m fitting and predicting completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] Time left 3571.53 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,047] (INFO): Time left 3571.53 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,048] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] \u001b[1mAutoml preset training completed in 28.48 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,049] (INFO): \u001b[1mAutoml preset training completed in 28.48 seconds\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:47] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,050] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/user/MKuznetsov/Tabular_nn/multi_nn_merge/LightAutoML_13062022/nlp_test/LightAutoML/data/bankiru_new_sample100k.csv\")\n",
    "df = df.sample(1000)\n",
    "train, test = train_test_split(df, test_size=300, random_state=42, stratify=df.is_good)\n",
    "\n",
    "roles = {'target': 'is_good',\n",
    "         'text': ['bank', 'message'],\n",
    "        }\n",
    "\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "automl = TabularNLPAutoML(task = task, \n",
    "                          timeout = 3600,\n",
    "                          gpu_ids = '0',\n",
    "                          general_params = {'use_algos': ['nn']},\n",
    "                          nn_params = {'lang': 'ru', 'bert_name': \"cointegrated/rubert-tiny\",\n",
    "                                       'pooling': 'mean', \n",
    "                                       'snap_params': { 'k': 1, 'early_stopping': True, 'patience': 1, 'swa': False},\n",
    "                                       'n_epochs': 2,\n",
    "                                       'num_workers': 0, \"path_to_save\": None,}, \n",
    "                          )\n",
    "\n",
    "oof_pred = automl.fit_predict(train, roles=roles, verbose=1) \n",
    "not_nan = np.any(~np.isnan(oof_pred.data), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilized таски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "############ CONFIG ############\n",
      "{'general_params': {'use_algos': [['nn', 'lgbm']]},\n",
      " 'nn_params': {'n_epochs': 2}}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:47,247] (INFO): Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[2022-11-12 15:28:47,248] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:47,248] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:47,248] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:47,249] (INFO): \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:47,249] (INFO): ==================================================\n",
      "[2022-11-12 15:28:47,251] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:47,251] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'default_params': {'random_state': 42}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:47,251] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,252] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 42}\n",
      "[2022-11-12 15:28:47,252] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,252] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 42}}\n",
      "[2022-11-12 15:28:47,253] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,253] (INFO3): Merged variant for general_params = {'use_algos': [['nn', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:47,262] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:47,263] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:47,263] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:47,263] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:47,264] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:47,264] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:47,265] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:47,305] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:47,308] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.95 secs\n",
      "[2022-11-12 15:28:47,316] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:47,317] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:47,317] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:47,320] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:47,321] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:47,321] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 44.86it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.14it/s]\n",
      "[2022-11-12 15:28:47,366] (INFO3): Epoch: 0, train loss: 0.5195797681808472, val loss: 0.5194292068481445, val metric: 0.5977212121212121\n",
      "train (loss=0.518639): 100%|██████████| 1/1 [00:00<00:00, 61.38it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.05it/s]\n",
      "[2022-11-12 15:28:47,397] (INFO3): Epoch: 1, train loss: 0.518638551235199, val loss: 0.5191497206687927, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:28:47,566] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:47,570] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:47,570] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:47,571] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 55.41it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.35it/s]\n",
      "[2022-11-12 15:28:47,610] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194867253303528, val metric: 0.5405575757575758\n",
      "train (loss=0.51833): 100%|██████████| 1/1 [00:00<00:00, 62.44it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.44it/s]\n",
      "[2022-11-12 15:28:47,641] (INFO3): Epoch: 1, train loss: 0.5183302760124207, val loss: 0.5193183422088623, val metric: 0.5536969696969698\n",
      "[2022-11-12 15:28:47,809] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5767515151515151\u001b[0m\n",
      "[2022-11-12 15:28:47,810] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:47,810] (INFO): Time left 599.45 secs\n",
      "\n",
      "[2022-11-12 15:28:47,811] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:47,811] (INFO): \u001b[1mAutoml preset training completed in 0.55 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:47,811] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:28:47,812] (INFO): ==================================================\n",
      "[2022-11-12 15:28:47,812] (INFO): ==================================================\n",
      "[2022-11-12 15:28:47,812] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:47,813] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'default_params': {'random_state': 43}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:47,813] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,814] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 43}\n",
      "[2022-11-12 15:28:47,814] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,814] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 43}}\n",
      "[2022-11-12 15:28:47,814] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:47,815] (INFO3): Merged variant for general_params = {'use_algos': [['nn', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:47,824] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:47,825] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:47,825] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:47,825] (INFO): - time: 599.43 seconds\n",
      "[2022-11-12 15:28:47,826] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:47,826] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:47,827] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:47,866] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:47,868] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.39 secs\n",
      "[2022-11-12 15:28:47,876] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:47,877] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:47,878] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:47,881] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:47,881] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:47,881] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.38it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.61it/s]\n",
      "[2022-11-12 15:28:47,920] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194525122642517, val metric: 0.5712484848484849\n",
      "train (loss=0.518413): 100%|██████████| 1/1 [00:00<00:00, 61.72it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 161.57it/s]\n",
      "[2022-11-12 15:28:47,951] (INFO3): Epoch: 1, train loss: 0.5184130072593689, val loss: 0.5192283987998962, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:28:48,118] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:48,122] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:48,122] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:48,123] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.85it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 157.09it/s]\n",
      "[2022-11-12 15:28:48,162] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194116830825806, val metric: 0.5976969696969696\n",
      "train (loss=0.518795): 100%|██████████| 1/1 [00:00<00:00, 61.54it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 149.65it/s]\n",
      "[2022-11-12 15:28:48,193] (INFO3): Epoch: 1, train loss: 0.5187949538230896, val loss: 0.519200325012207, val metric: 0.5976969696969696\n",
      "[2022-11-12 15:28:48,360] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5832666666666666\u001b[0m\n",
      "[2022-11-12 15:28:48,361] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:48,361] (INFO): Time left 598.90 secs\n",
      "\n",
      "[2022-11-12 15:28:48,362] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,362] (INFO): \u001b[1mAutoml preset training completed in 0.54 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,363] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:28:48,363] (INFO): ==================================================\n",
      "[2022-11-12 15:28:48,363] (INFO): ==================================================\n",
      "[2022-11-12 15:28:48,364] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:48,364] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'default_params': {'random_state': 44}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:48,364] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,365] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 44}\n",
      "[2022-11-12 15:28:48,365] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,365] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 44}}\n",
      "[2022-11-12 15:28:48,366] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,366] (INFO3): Merged variant for general_params = {'use_algos': [['nn', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:48,375] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:48,376] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:48,376] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:48,377] (INFO): - time: 598.88 seconds\n",
      "[2022-11-12 15:28:48,377] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:48,377] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:48,378] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,417] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:48,420] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 598.84 secs\n",
      "[2022-11-12 15:28:48,428] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:48,428] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:48,429] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:48,432] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:48,433] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:48,433] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.23it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.76it/s]\n",
      "[2022-11-12 15:28:48,472] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194708108901978, val metric: 0.607030303030303\n",
      "train (loss=0.51889): 100%|██████████| 1/1 [00:00<00:00, 61.38it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.67it/s]\n",
      "[2022-11-12 15:28:48,503] (INFO3): Epoch: 1, train loss: 0.5188902020454407, val loss: 0.5192679166793823, val metric: 0.6075636363636363\n",
      "[2022-11-12 15:28:48,671] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:48,674] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:48,675] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:48,675] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.18it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.50it/s]\n",
      "[2022-11-12 15:28:48,714] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194472670555115, val metric: 0.5645333333333333\n",
      "train (loss=0.518237): 100%|██████████| 1/1 [00:00<00:00, 61.33it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 162.29it/s]\n",
      "[2022-11-12 15:28:48,745] (INFO3): Epoch: 1, train loss: 0.5182373523712158, val loss: 0.5192034244537354, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:28:48,913] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5732545454545455\u001b[0m\n",
      "[2022-11-12 15:28:48,914] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:48,914] (INFO): Time left 598.35 secs\n",
      "\n",
      "[2022-11-12 15:28:48,915] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,915] (INFO): \u001b[1mAutoml preset training completed in 0.54 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,915] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:28:48,916] (INFO): ==================================================\n",
      "[2022-11-12 15:28:48,917] (INFO): ==================================================\n",
      "[2022-11-12 15:28:48,917] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:48,917] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'default_params': {'random_state': 45}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:48,918] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,918] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 45}\n",
      "[2022-11-12 15:28:48,918] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,919] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 45}}\n",
      "[2022-11-12 15:28:48,919] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:48,919] (INFO3): Merged variant for general_params = {'use_algos': [['nn', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:48,928] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:48,929] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:48,929] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:48,929] (INFO): - time: 598.33 seconds\n",
      "[2022-11-12 15:28:48,930] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:48,930] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:48,931] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:48,970] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:48,973] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 598.29 secs\n",
      "[2022-11-12 15:28:48,980] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:48,981] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:48,982] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:48,985] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:48,985] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:48,985] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.32it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.35it/s]\n",
      "[2022-11-12 15:28:49,025] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196248292922974, val metric: 0.424169696969697\n",
      "train (loss=0.519233): 100%|██████████| 1/1 [00:00<00:00, 61.09it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.86it/s]\n",
      "[2022-11-12 15:28:49,056] (INFO3): Epoch: 1, train loss: 0.5192331671714783, val loss: 0.5195826888084412, val metric: 0.5099151515151514\n",
      "[2022-11-12 15:28:49,228] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:49,232] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:49,233] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:49,233] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.75it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.23it/s]\n",
      "[2022-11-12 15:28:49,272] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195744633674622, val metric: 0.4940363636363636\n",
      "train (loss=0.517397): 100%|██████████| 1/1 [00:00<00:00, 63.08it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.03it/s]\n",
      "[2022-11-12 15:28:49,303] (INFO3): Epoch: 1, train loss: 0.5173972249031067, val loss: 0.5195797681808472, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:28:49,473] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5011757575757576\u001b[0m\n",
      "[2022-11-12 15:28:49,473] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:49,474] (INFO): Time left 597.79 secs\n",
      "\n",
      "[2022-11-12 15:28:49,474] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:49,475] (INFO): \u001b[1mAutoml preset training completed in 0.54 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:49,476] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:28:49,476] (INFO): ==================================================\n",
      "[2022-11-12 15:28:49,476] (INFO): ==================================================\n",
      "[2022-11-12 15:28:49,477] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:49,477] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'default_params': {'random_state': 46}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:49,477] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:49,478] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 46}\n",
      "[2022-11-12 15:28:49,478] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:49,478] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 46}}\n",
      "[2022-11-12 15:28:49,479] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:49,479] (INFO3): Merged variant for general_params = {'use_algos': [['nn', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:49,488] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:49,488] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:49,489] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:49,489] (INFO): - time: 597.77 seconds\n",
      "[2022-11-12 15:28:49,489] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:49,490] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:49,490] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:49,529] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:49,532] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 597.73 secs\n",
      "[2022-11-12 15:28:49,540] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:49,540] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:49,541] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:49,544] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:49,545] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:49,545] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.45it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.27it/s]\n",
      "[2022-11-12 15:28:49,584] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519507646560669, val metric: 0.5699636363636362\n",
      "train (loss=0.518826): 100%|██████████| 1/1 [00:00<00:00, 52.39it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 162.15it/s]\n",
      "[2022-11-12 15:28:49,617] (INFO3): Epoch: 1, train loss: 0.5188260078430176, val loss: 0.519360363483429, val metric: 0.5777212121212121\n",
      "[2022-11-12 15:28:49,787] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:49,790] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:49,791] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:49,791] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 58.38it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.05it/s]\n",
      "[2022-11-12 15:28:49,829] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194738507270813, val metric: 0.5449939393939394\n",
      "train (loss=0.518322): 100%|██████████| 1/1 [00:00<00:00, 62.72it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.50it/s]\n",
      "[2022-11-12 15:28:49,860] (INFO3): Epoch: 1, train loss: 0.5183219909667969, val loss: 0.5192884206771851, val metric: 0.5449939393939394\n",
      "[2022-11-12 15:28:50,029] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5612242424242424\u001b[0m\n",
      "[2022-11-12 15:28:50,030] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:50,030] (INFO): Time left 597.23 secs\n",
      "\n",
      "[2022-11-12 15:28:50,031] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:50,031] (INFO): \u001b[1mAutoml preset training completed in 0.54 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:50,031] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:28:50,032] (INFO): ==================================================\n",
      "[2022-11-12 15:28:50,042] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,043] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,043] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 225.60it/s]\n",
      "[2022-11-12 15:28:50,225] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,226] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,226] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 269.78it/s]\n",
      "[2022-11-12 15:28:50,423] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,424] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,424] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 268.52it/s]\n",
      "[2022-11-12 15:28:50,603] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,604] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,604] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 267.15it/s]\n",
      "[2022-11-12 15:28:50,792] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,792] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,793] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 258.64it/s]\n",
      "[2022-11-12 15:28:50,973] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:50,974] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:50,974] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 266.42it/s]\n",
      "[2022-11-12 15:28:51,164] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:51,164] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:51,165] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 267.63it/s]\n",
      "[2022-11-12 15:28:51,349] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:51,349] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:51,350] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 263.86it/s]\n",
      "[2022-11-12 15:28:51,562] (INFO): Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[2022-11-12 15:28:51,562] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:51,563] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:51,563] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:51,563] (INFO): \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:51,564] (INFO): ==================================================\n",
      "[2022-11-12 15:28:51,564] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:51,564] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'default_params': {'random_state': 42}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:51,565] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:51,565] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 42}\n",
      "[2022-11-12 15:28:51,565] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:51,566] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 42}}\n",
      "[2022-11-12 15:28:51,566] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:51,566] (INFO3): Merged variant for general_params = {'use_algos': [['dense', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:51,574] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:51,576] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:51,576] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:51,577] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:51,577] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:51,577] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:51,578] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:51,617] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:51,620] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.95 secs\n",
      "[2022-11-12 15:28:51,628] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[2022-11-12 15:28:51,629] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:51,629] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:51,632] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:51,633] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:51,633] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.18it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "############ CONFIG ############\n",
      "{'general_params': {'use_algos': [['dense', 'lgbm']]},\n",
      " 'nn_params': {'n_epochs': 2}}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:51,735] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195204615592957, val metric: 0.597769696969697\n",
      "train (loss=0.517228): 100%|██████████| 1/1 [00:00<00:00, 19.46it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s]\n",
      "[2022-11-12 15:28:51,814] (INFO3): Epoch: 1, train loss: 0.5172278881072998, val loss: 0.5194492936134338, val metric: 0.5872484848484849\n",
      "[2022-11-12 15:28:51,992] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:51,996] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:51,997] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:51,997] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.45it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.21it/s]\n",
      "[2022-11-12 15:28:52,094] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195225477218628, val metric: 0.5777696969696969\n",
      "train (loss=0.517174): 100%|██████████| 1/1 [00:00<00:00, 19.59it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 61.90it/s]\n",
      "[2022-11-12 15:28:52,173] (INFO3): Epoch: 1, train loss: 0.5171740055084229, val loss: 0.5194441676139832, val metric: 0.5777939393939394\n",
      "[2022-11-12 15:28:52,349] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.5846666666666667\u001b[0m\n",
      "[2022-11-12 15:28:52,350] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:52,350] (INFO): Time left 599.22 secs\n",
      "\n",
      "[2022-11-12 15:28:52,351] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:52,351] (INFO): \u001b[1mAutoml preset training completed in 0.77 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:52,351] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2022-11-12 15:28:52,352] (INFO): ==================================================\n",
      "[2022-11-12 15:28:52,352] (INFO): ==================================================\n",
      "[2022-11-12 15:28:52,353] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:52,353] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'default_params': {'random_state': 43}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:52,353] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:52,354] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 43}\n",
      "[2022-11-12 15:28:52,354] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:52,354] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 43}}\n",
      "[2022-11-12 15:28:52,355] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:52,355] (INFO3): Merged variant for general_params = {'use_algos': [['dense', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:52,364] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:52,365] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:52,365] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:52,365] (INFO): - time: 599.21 seconds\n",
      "[2022-11-12 15:28:52,366] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:52,366] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:52,367] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:52,406] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:52,408] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.17 secs\n",
      "[2022-11-12 15:28:52,416] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[2022-11-12 15:28:52,417] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:52,418] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:52,421] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:52,421] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:52,422] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.00it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.36it/s]\n",
      "[2022-11-12 15:28:52,516] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195221304893494, val metric: 0.5712242424242424\n",
      "train (loss=0.517692): 100%|██████████| 1/1 [00:00<00:00, 19.24it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.50it/s]\n",
      "[2022-11-12 15:28:52,595] (INFO3): Epoch: 1, train loss: 0.5176919102668762, val loss: 0.5194374918937683, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:28:52,765] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:52,769] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:52,769] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:52,770] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.95it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.09it/s]\n",
      "[2022-11-12 15:28:52,865] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195656418800354, val metric: 0.5387151515151515\n",
      "train (loss=0.517436): 100%|██████████| 1/1 [00:00<00:00, 19.15it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.74it/s]\n",
      "[2022-11-12 15:28:52,944] (INFO3): Epoch: 1, train loss: 0.5174357891082764, val loss: 0.5195164084434509, val metric: 0.5545454545454545\n",
      "[2022-11-12 15:28:53,115] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.5683757575757575\u001b[0m\n",
      "[2022-11-12 15:28:53,116] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:53,116] (INFO): Time left 598.46 secs\n",
      "\n",
      "[2022-11-12 15:28:53,117] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,118] (INFO): \u001b[1mAutoml preset training completed in 0.75 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,118] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2022-11-12 15:28:53,118] (INFO): ==================================================\n",
      "[2022-11-12 15:28:53,119] (INFO): ==================================================\n",
      "[2022-11-12 15:28:53,119] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:53,119] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'default_params': {'random_state': 44}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:53,121] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,121] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 44}\n",
      "[2022-11-12 15:28:53,121] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,122] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 44}}\n",
      "[2022-11-12 15:28:53,122] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,122] (INFO3): Merged variant for general_params = {'use_algos': [['dense', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:53,131] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:53,131] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:53,132] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:53,132] (INFO): - time: 598.44 seconds\n",
      "[2022-11-12 15:28:53,132] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:53,133] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:53,133] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,173] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:53,175] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 598.40 secs\n",
      "[2022-11-12 15:28:53,183] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[2022-11-12 15:28:53,183] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:53,184] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:53,187] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:53,188] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:53,188] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.94it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.64it/s]\n",
      "[2022-11-12 15:28:53,287] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195702910423279, val metric: 0.577939393939394\n",
      "train (loss=0.517459): 100%|██████████| 1/1 [00:00<00:00, 18.86it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.02it/s]\n",
      "[2022-11-12 15:28:53,367] (INFO3): Epoch: 1, train loss: 0.5174590945243835, val loss: 0.5195289254188538, val metric: 0.6138181818181818\n",
      "[2022-11-12 15:28:53,537] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:53,541] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:53,541] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:53,542] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.75it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 48.58it/s]\n",
      "[2022-11-12 15:28:53,642] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195195078849792, val metric: 0.5646545454545455\n",
      "train (loss=0.517439): 100%|██████████| 1/1 [00:00<00:00, 18.41it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.59it/s]\n",
      "[2022-11-12 15:28:53,723] (INFO3): Epoch: 1, train loss: 0.5174387693405151, val loss: 0.5194229483604431, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:28:53,893] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.582030303030303\u001b[0m\n",
      "[2022-11-12 15:28:53,893] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:53,894] (INFO): Time left 597.68 secs\n",
      "\n",
      "[2022-11-12 15:28:53,894] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,895] (INFO): \u001b[1mAutoml preset training completed in 0.76 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,895] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2022-11-12 15:28:53,896] (INFO): ==================================================\n",
      "[2022-11-12 15:28:53,896] (INFO): ==================================================\n",
      "[2022-11-12 15:28:53,896] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:53,897] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'default_params': {'random_state': 45}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:53,897] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,897] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 45}\n",
      "[2022-11-12 15:28:53,898] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,898] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 45}}\n",
      "[2022-11-12 15:28:53,898] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:53,899] (INFO3): Merged variant for general_params = {'use_algos': [['dense', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:53,908] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:53,908] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:53,909] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:53,909] (INFO): - time: 597.66 seconds\n",
      "[2022-11-12 15:28:53,909] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:53,910] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:53,910] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:53,949] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:53,952] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 597.62 secs\n",
      "[2022-11-12 15:28:53,959] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[2022-11-12 15:28:53,960] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:53,961] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:53,964] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:53,964] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:53,964] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.22it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.24it/s]\n",
      "[2022-11-12 15:28:54,058] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196776390075684, val metric: 0.32913939393939395\n",
      "train (loss=0.518915): 100%|██████████| 1/1 [00:00<00:00, 18.75it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.72it/s]\n",
      "[2022-11-12 15:28:54,138] (INFO3): Epoch: 1, train loss: 0.5189151763916016, val loss: 0.5198241472244263, val metric: 0.3443878787878788\n",
      "[2022-11-12 15:28:54,330] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:54,335] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:54,335] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:54,335] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.24it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.67it/s]\n",
      "[2022-11-12 15:28:54,433] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195885300636292, val metric: 0.4940363636363636\n",
      "train (loss=0.515092): 100%|██████████| 1/1 [00:00<00:00, 18.29it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.23it/s]\n",
      "[2022-11-12 15:28:54,515] (INFO3): Epoch: 1, train loss: 0.5150918364524841, val loss: 0.519609808921814, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:28:54,692] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.45775151515151513\u001b[0m\n",
      "[2022-11-12 15:28:54,693] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:54,693] (INFO): Time left 596.88 secs\n",
      "\n",
      "[2022-11-12 15:28:54,694] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:54,694] (INFO): \u001b[1mAutoml preset training completed in 0.78 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:54,695] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2022-11-12 15:28:54,695] (INFO): ==================================================\n",
      "[2022-11-12 15:28:54,696] (INFO): ==================================================\n",
      "[2022-11-12 15:28:54,696] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:54,697] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'default_params': {'random_state': 46}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:54,697] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:54,697] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 46}\n",
      "[2022-11-12 15:28:54,698] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:54,698] (INFO3): Merged variant for nn_params = {'n_epochs': 2, 'path_to_save': None, 'default_params': {'random_state': 46}}\n",
      "[2022-11-12 15:28:54,699] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:54,700] (INFO3): Merged variant for general_params = {'use_algos': [['dense', 'lgbm']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:54,708] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:54,709] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:54,709] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:54,709] (INFO): - time: 596.86 seconds\n",
      "[2022-11-12 15:28:54,710] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:54,710] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:54,711] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:54,749] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:54,752] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 596.82 secs\n",
      "[2022-11-12 15:28:54,759] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[2022-11-12 15:28:54,760] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:54,761] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:54,764] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:54,764] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:54,765] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.96it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.49it/s]\n",
      "[2022-11-12 15:28:54,859] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195084810256958, val metric: 0.6283636363636362\n",
      "train (loss=0.51836): 100%|██████████| 1/1 [00:00<00:00, 19.47it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 54.85it/s]\n",
      "[2022-11-12 15:28:54,940] (INFO3): Epoch: 1, train loss: 0.5183604955673218, val loss: 0.5194426774978638, val metric: 0.6281939393939394\n",
      "[2022-11-12 15:28:55,116] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m =====\n",
      "[2022-11-12 15:28:55,120] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:55,120] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:55,120] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.51it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 61.56it/s]\n",
      "[2022-11-12 15:28:55,213] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195421576499939, val metric: 0.5449939393939394\n",
      "train (loss=0.516177): 100%|██████████| 1/1 [00:00<00:00, 19.76it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.29it/s]\n",
      "[2022-11-12 15:28:55,291] (INFO3): Epoch: 1, train loss: 0.5161771774291992, val loss: 0.5194854736328125, val metric: 0.5449939393939394\n",
      "[2022-11-12 15:28:55,489] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.5752606060606061\u001b[0m\n",
      "[2022-11-12 15:28:55,490] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:55,491] (INFO): Time left 596.08 secs\n",
      "\n",
      "[2022-11-12 15:28:55,491] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:55,492] (INFO): \u001b[1mAutoml preset training completed in 0.78 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:55,492] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2022-11-12 15:28:55,492] (INFO): ==================================================\n",
      "[2022-11-12 15:28:55,503] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:55,503] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:55,504] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 117.80it/s]\n",
      "[2022-11-12 15:28:55,695] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:55,696] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:55,696] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 125.31it/s]\n",
      "[2022-11-12 15:28:55,892] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:55,893] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:55,893] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 125.23it/s]\n",
      "[2022-11-12 15:28:56,079] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:56,080] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:56,080] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 125.00it/s]\n",
      "[2022-11-12 15:28:56,291] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:56,291] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:56,292] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.43it/s]\n",
      "[2022-11-12 15:28:56,479] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:56,480] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:56,480] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 122.68it/s]\n",
      "[2022-11-12 15:28:56,696] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:56,696] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:56,697] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 122.87it/s]\n",
      "[2022-11-12 15:28:56,887] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:56,888] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:56,888] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 122.54it/s]\n",
      "[2022-11-12 15:28:57,118] (INFO): Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[2022-11-12 15:28:57,119] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:57,119] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:57,120] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:57,120] (INFO): \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:57,120] (INFO): ==================================================\n",
      "[2022-11-12 15:28:57,121] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:57,121] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'default_params': {'random_state': 42}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:57,121] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:57,122] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 42}\n",
      "[2022-11-12 15:28:57,122] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:57,123] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'path_to_save': None, 'default_params': {'random_state': 42}}\n",
      "[2022-11-12 15:28:57,124] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:57,125] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:57,134] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:57,135] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:57,135] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:57,135] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:28:57,136] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:57,136] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:57,137] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:57,176] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:57,178] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.95 secs\n",
      "[2022-11-12 15:28:57,186] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:57,187] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:57,187] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:57,190] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:57,191] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:57,191] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 52.45it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 164.12it/s]\n",
      "[2022-11-12 15:28:57,231] (INFO3): Epoch: 0, train loss: 0.5195797681808472, val loss: 0.5194292068481445, val metric: 0.5977212121212121\n",
      "train (loss=0.518639): 100%|██████████| 1/1 [00:00<00:00, 60.05it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 165.07it/s]\n",
      "[2022-11-12 15:28:57,262] (INFO3): Epoch: 1, train loss: 0.518638551235199, val loss: 0.5191497206687927, val metric: 0.5977212121212121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "############ CONFIG ############\n",
      "{'general_params': {'use_algos': [['lgbm', 'mlp', 'dense']]},\n",
      " 'nn_params': {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}}}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-12 15:28:57,445] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:57,449] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:57,450] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:57,450] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 51.28it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 136.67it/s]\n",
      "[2022-11-12 15:28:57,492] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194867253303528, val metric: 0.5405575757575758\n",
      "train (loss=0.51833): 100%|██████████| 1/1 [00:00<00:00, 58.29it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 153.58it/s]\n",
      "[2022-11-12 15:28:57,523] (INFO3): Epoch: 1, train loss: 0.5183302760124207, val loss: 0.5193183422088623, val metric: 0.5536969696969698\n",
      "[2022-11-12 15:28:57,685] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5767515151515151\u001b[0m\n",
      "[2022-11-12 15:28:57,686] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:57,687] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:28:57,688] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:57,689] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:28:57,692] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:57,692] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:57,693] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.67it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.54it/s]\n",
      "[2022-11-12 15:28:57,791] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195204615592957, val metric: 0.597769696969697\n",
      "train (loss=0.517228): 100%|██████████| 1/1 [00:00<00:00, 18.28it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s]\n",
      "[2022-11-12 15:28:57,873] (INFO3): Epoch: 1, train loss: 0.5172278881072998, val loss: 0.5194492936134338, val metric: 0.5872484848484849\n",
      "train (loss=0.514541): 100%|██████████| 1/1 [00:00<00:00, 18.15it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.45it/s]\n",
      "[2022-11-12 15:28:57,955] (INFO3): Epoch: 2, train loss: 0.5145406723022461, val loss: 0.5193597674369812, val metric: 0.598690909090909\n",
      "train (loss=0.512141): 100%|██████████| 1/1 [00:00<00:00, 18.40it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.81it/s]\n",
      "[2022-11-12 15:28:58,037] (INFO3): Epoch: 3, train loss: 0.5121414661407471, val loss: 0.5192506909370422, val metric: 0.5977212121212121\n",
      "train (loss=0.506889): 100%|██████████| 1/1 [00:00<00:00, 18.56it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.71it/s]\n",
      "[2022-11-12 15:28:58,119] (INFO3): Epoch: 4, train loss: 0.5068886876106262, val loss: 0.5191373229026794, val metric: 0.5977454545454546\n",
      "[2022-11-12 15:28:58,288] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:28:58,292] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:58,292] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:58,293] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.69it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.88it/s]\n",
      "[2022-11-12 15:28:58,391] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195225477218628, val metric: 0.5777696969696969\n",
      "train (loss=0.517174): 100%|██████████| 1/1 [00:00<00:00, 18.40it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.65it/s]\n",
      "[2022-11-12 15:28:58,472] (INFO3): Epoch: 1, train loss: 0.5171740055084229, val loss: 0.5194441676139832, val metric: 0.5777939393939394\n",
      "train (loss=0.514202): 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.42it/s]\n",
      "[2022-11-12 15:28:58,554] (INFO3): Epoch: 2, train loss: 0.5142015814781189, val loss: 0.5193322896957397, val metric: 0.5777939393939394\n",
      "train (loss=0.510669): 100%|██████████| 1/1 [00:00<00:00, 18.36it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.93it/s]\n",
      "[2022-11-12 15:28:58,636] (INFO3): Epoch: 3, train loss: 0.5106688141822815, val loss: 0.5191878080368042, val metric: 0.5777939393939394\n",
      "train (loss=0.506303): 100%|██████████| 1/1 [00:00<00:00, 18.35it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.17it/s]\n",
      "[2022-11-12 15:28:58,719] (INFO3): Epoch: 4, train loss: 0.5063034296035767, val loss: 0.5190219283103943, val metric: 0.5733818181818182\n",
      "[2022-11-12 15:28:58,891] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5767333333333333\u001b[0m\n",
      "[2022-11-12 15:28:58,891] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:58,892] (INFO): Time left 598.24 secs\n",
      "\n",
      "[2022-11-12 15:28:58,892] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:58,895] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5790060606060606\u001b[0m\n",
      "[2022-11-12 15:28:58,916] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5849939393939394\u001b[0m, weights = \u001b[1m[0.7549502  0.24504977]\u001b[0m\n",
      "[2022-11-12 15:28:58,937] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5849939393939394\u001b[0m, weights = \u001b[1m[0.7549502  0.24504977]\u001b[0m\n",
      "[2022-11-12 15:28:58,937] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:28:58,938] (INFO): \u001b[1mAutoml preset training completed in 1.80 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:58,939] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.75495 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) +\n",
      "\t 0.24505 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:28:58,939] (INFO): ==================================================\n",
      "[2022-11-12 15:28:58,940] (INFO): ==================================================\n",
      "[2022-11-12 15:28:58,940] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:28:58,940] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'default_params': {'random_state': 43}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:28:58,941] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:58,941] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 43}\n",
      "[2022-11-12 15:28:58,941] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:58,941] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'path_to_save': None, 'default_params': {'random_state': 43}}\n",
      "[2022-11-12 15:28:58,942] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:28:58,942] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:28:58,951] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:28:58,952] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:28:58,952] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:28:58,952] (INFO): - time: 598.18 seconds\n",
      "[2022-11-12 15:28:58,953] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:28:58,953] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:28:58,954] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:28:58,992] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:28:58,995] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 598.14 secs\n",
      "[2022-11-12 15:28:59,002] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:28:59,003] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:59,004] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:59,006] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:59,007] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:59,007] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.29it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 164.93it/s]\n",
      "[2022-11-12 15:28:59,046] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194525122642517, val metric: 0.5712484848484849\n",
      "train (loss=0.518413): 100%|██████████| 1/1 [00:00<00:00, 61.06it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 164.10it/s]\n",
      "[2022-11-12 15:28:59,076] (INFO3): Epoch: 1, train loss: 0.5184130072593689, val loss: 0.5192283987998962, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:28:59,239] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:28:59,242] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:59,243] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:59,243] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.52it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 161.01it/s]\n",
      "[2022-11-12 15:28:59,282] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194116830825806, val metric: 0.5976969696969696\n",
      "train (loss=0.518795): 100%|██████████| 1/1 [00:00<00:00, 61.14it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 173.52it/s]\n",
      "[2022-11-12 15:28:59,312] (INFO3): Epoch: 1, train loss: 0.5187949538230896, val loss: 0.519200325012207, val metric: 0.5976969696969696\n",
      "[2022-11-12 15:28:59,475] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5832666666666666\u001b[0m\n",
      "[2022-11-12 15:28:59,475] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:28:59,476] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:28:59,477] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:28:59,478] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:28:59,481] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:28:59,482] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:28:59,482] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.74it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s]\n",
      "[2022-11-12 15:28:59,580] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195221304893494, val metric: 0.5712242424242424\n",
      "train (loss=0.517692): 100%|██████████| 1/1 [00:00<00:00, 18.50it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.61it/s]\n",
      "[2022-11-12 15:28:59,661] (INFO3): Epoch: 1, train loss: 0.5176919102668762, val loss: 0.5194374918937683, val metric: 0.5712484848484849\n",
      "train (loss=0.515502): 100%|██████████| 1/1 [00:00<00:00, 18.44it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.95it/s]\n",
      "[2022-11-12 15:28:59,742] (INFO3): Epoch: 2, train loss: 0.5155020356178284, val loss: 0.5193321108818054, val metric: 0.5712484848484849\n",
      "train (loss=0.512497): 100%|██████████| 1/1 [00:00<00:00, 18.15it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.25it/s]\n",
      "[2022-11-12 15:28:59,824] (INFO3): Epoch: 3, train loss: 0.5124971866607666, val loss: 0.519190788269043, val metric: 0.5712484848484849\n",
      "train (loss=0.510455): 100%|██████████| 1/1 [00:00<00:00, 18.42it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.17it/s]\n",
      "[2022-11-12 15:28:59,906] (INFO3): Epoch: 4, train loss: 0.5104547739028931, val loss: 0.5190282464027405, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:00,077] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:00,081] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:00,081] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:00,082] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.77it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.65it/s]\n",
      "[2022-11-12 15:29:00,180] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195656418800354, val metric: 0.5387151515151515\n",
      "train (loss=0.517436): 100%|██████████| 1/1 [00:00<00:00, 18.41it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.62it/s]\n",
      "[2022-11-12 15:29:00,262] (INFO3): Epoch: 1, train loss: 0.5174357891082764, val loss: 0.5195164084434509, val metric: 0.5545454545454545\n",
      "train (loss=0.514027): 100%|██████████| 1/1 [00:00<00:00, 20.10it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.38it/s]\n",
      "[2022-11-12 15:29:00,338] (INFO3): Epoch: 2, train loss: 0.5140268206596375, val loss: 0.5194510817527771, val metric: 0.5585454545454546\n",
      "train (loss=0.510927): 100%|██████████| 1/1 [00:00<00:00, 20.08it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.11it/s]\n",
      "[2022-11-12 15:29:00,415] (INFO3): Epoch: 3, train loss: 0.5109272599220276, val loss: 0.5193652510643005, val metric: 0.5611878787878788\n",
      "train (loss=0.509275): 100%|██████████| 1/1 [00:00<00:00, 20.23it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.35it/s]\n",
      "[2022-11-12 15:29:00,493] (INFO3): Epoch: 4, train loss: 0.509275496006012, val loss: 0.5192763209342957, val metric: 0.560630303030303\n",
      "[2022-11-12 15:29:00,662] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5528848484848485\u001b[0m\n",
      "[2022-11-12 15:29:00,663] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:00,663] (INFO): Time left 596.47 secs\n",
      "\n",
      "[2022-11-12 15:29:00,664] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:00,666] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5653151515151515\u001b[0m\n",
      "[2022-11-12 15:29:00,688] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5832666666666666\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:00,699] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5832666666666666\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:00,699] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:00,700] (INFO): \u001b[1mAutoml preset training completed in 1.75 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:00,701] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:29:00,701] (INFO): ==================================================\n",
      "[2022-11-12 15:29:00,702] (INFO): ==================================================\n",
      "[2022-11-12 15:29:00,702] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:00,702] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'default_params': {'random_state': 44}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:00,703] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:00,703] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 44}\n",
      "[2022-11-12 15:29:00,703] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:00,704] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'path_to_save': None, 'default_params': {'random_state': 44}}\n",
      "[2022-11-12 15:29:00,704] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:00,704] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:00,713] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:00,714] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:00,714] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:00,715] (INFO): - time: 596.42 seconds\n",
      "[2022-11-12 15:29:00,715] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:00,715] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:00,716] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:00,754] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:00,756] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 596.38 secs\n",
      "[2022-11-12 15:29:00,764] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:29:00,765] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:00,765] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:00,768] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:00,769] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:00,769] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 59.31it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.80it/s]\n",
      "[2022-11-12 15:29:00,807] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194708108901978, val metric: 0.607030303030303\n",
      "train (loss=0.51889): 100%|██████████| 1/1 [00:00<00:00, 64.84it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 165.17it/s]\n",
      "[2022-11-12 15:29:00,836] (INFO3): Epoch: 1, train loss: 0.5188902020454407, val loss: 0.5192679166793823, val metric: 0.6075636363636363\n",
      "[2022-11-12 15:29:01,001] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:01,004] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:01,005] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:01,005] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 59.52it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.39it/s]\n",
      "[2022-11-12 15:29:01,043] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194472670555115, val metric: 0.5645333333333333\n",
      "train (loss=0.518237): 100%|██████████| 1/1 [00:00<00:00, 54.65it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 165.81it/s]\n",
      "[2022-11-12 15:29:01,075] (INFO3): Epoch: 1, train loss: 0.5182373523712158, val loss: 0.5192034244537354, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:29:01,241] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5732545454545455\u001b[0m\n",
      "[2022-11-12 15:29:01,242] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:01,243] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:01,243] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:01,244] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:01,247] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:01,248] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:01,248] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.97it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.26it/s]\n",
      "[2022-11-12 15:29:01,342] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195702910423279, val metric: 0.577939393939394\n",
      "train (loss=0.517459): 100%|██████████| 1/1 [00:00<00:00, 17.44it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.41it/s]\n",
      "[2022-11-12 15:29:01,426] (INFO3): Epoch: 1, train loss: 0.5174590945243835, val loss: 0.5195289254188538, val metric: 0.6138181818181818\n",
      "train (loss=0.514439): 100%|██████████| 1/1 [00:00<00:00, 19.92it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.58it/s]\n",
      "[2022-11-12 15:29:01,504] (INFO3): Epoch: 2, train loss: 0.5144389867782593, val loss: 0.5194674730300903, val metric: 0.6056242424242424\n",
      "train (loss=0.511586): 100%|██████████| 1/1 [00:00<00:00, 20.15it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.98it/s]\n",
      "[2022-11-12 15:29:01,581] (INFO3): Epoch: 3, train loss: 0.511585533618927, val loss: 0.5194090604782104, val metric: 0.6070787878787879\n",
      "train (loss=0.507587): 100%|██████████| 1/1 [00:00<00:00, 19.89it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.71it/s]\n",
      "[2022-11-12 15:29:01,659] (INFO3): Epoch: 4, train loss: 0.5075871348381042, val loss: 0.5193563103675842, val metric: 0.6058666666666667\n",
      "[2022-11-12 15:29:01,827] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:01,831] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:01,832] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:01,832] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.12it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.36it/s]\n",
      "[2022-11-12 15:29:01,925] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195195078849792, val metric: 0.5646545454545455\n",
      "train (loss=0.517439): 100%|██████████| 1/1 [00:00<00:00, 19.59it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s]\n",
      "[2022-11-12 15:29:02,004] (INFO3): Epoch: 1, train loss: 0.5174387693405151, val loss: 0.5194229483604431, val metric: 0.5645333333333333\n",
      "train (loss=0.513859): 100%|██████████| 1/1 [00:00<00:00, 19.86it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.13it/s]\n",
      "[2022-11-12 15:29:02,081] (INFO3): Epoch: 2, train loss: 0.5138586163520813, val loss: 0.5192946195602417, val metric: 0.5645333333333333\n",
      "train (loss=0.510632): 100%|██████████| 1/1 [00:00<00:00, 19.74it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.41it/s]\n",
      "[2022-11-12 15:29:02,160] (INFO3): Epoch: 3, train loss: 0.5106315612792969, val loss: 0.519133985042572, val metric: 0.5645333333333333\n",
      "train (loss=0.50673): 100%|██████████| 1/1 [00:00<00:00, 19.48it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.29it/s]\n",
      "[2022-11-12 15:29:02,239] (INFO3): Epoch: 4, train loss: 0.5067295432090759, val loss: 0.5189236402511597, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:29:02,409] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5649818181818181\u001b[0m\n",
      "[2022-11-12 15:29:02,410] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:02,411] (INFO): Time left 594.72 secs\n",
      "\n",
      "[2022-11-12 15:29:02,411] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:02,414] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5692060606060606\u001b[0m\n",
      "[2022-11-12 15:29:02,435] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5720424242424242\u001b[0m, weights = \u001b[1m[0.8306462  0.16935381]\u001b[0m\n",
      "[2022-11-12 15:29:02,456] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5720424242424242\u001b[0m, weights = \u001b[1m[0.8306462  0.16935381]\u001b[0m\n",
      "[2022-11-12 15:29:02,456] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:02,457] (INFO): \u001b[1mAutoml preset training completed in 1.74 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:02,458] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.83065 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) +\n",
      "\t 0.16935 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:02,458] (INFO): ==================================================\n",
      "[2022-11-12 15:29:02,458] (INFO): ==================================================\n",
      "[2022-11-12 15:29:02,459] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:02,459] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'default_params': {'random_state': 45}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:02,459] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:02,460] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 45}\n",
      "[2022-11-12 15:29:02,461] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:02,461] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'path_to_save': None, 'default_params': {'random_state': 45}}\n",
      "[2022-11-12 15:29:02,461] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:02,462] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:02,470] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:02,471] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:02,471] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:02,471] (INFO): - time: 594.66 seconds\n",
      "[2022-11-12 15:29:02,472] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:02,472] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:02,473] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:02,511] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:02,514] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 594.62 secs\n",
      "[2022-11-12 15:29:02,521] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:29:02,522] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:02,522] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:02,525] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:02,526] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:02,526] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.21it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.96it/s]\n",
      "[2022-11-12 15:29:02,565] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196248292922974, val metric: 0.424169696969697\n",
      "train (loss=0.519233): 100%|██████████| 1/1 [00:00<00:00, 65.01it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 167.74it/s]\n",
      "[2022-11-12 15:29:02,594] (INFO3): Epoch: 1, train loss: 0.5192331671714783, val loss: 0.5195826888084412, val metric: 0.5099151515151514\n",
      "[2022-11-12 15:29:02,774] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:02,780] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:02,781] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:02,781] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 58.39it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.79it/s]\n",
      "[2022-11-12 15:29:02,819] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195744633674622, val metric: 0.4940363636363636\n",
      "train (loss=0.517397): 100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 162.38it/s]\n",
      "[2022-11-12 15:29:02,848] (INFO3): Epoch: 1, train loss: 0.5173972249031067, val loss: 0.5195797681808472, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:29:03,021] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5011757575757576\u001b[0m\n",
      "[2022-11-12 15:29:03,022] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:03,023] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:03,024] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:03,025] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:03,028] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:03,028] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:03,029] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.25it/s]\n",
      "[2022-11-12 15:29:03,123] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196776390075684, val metric: 0.32913939393939395\n",
      "train (loss=0.518915): 100%|██████████| 1/1 [00:00<00:00, 19.90it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.95it/s]\n",
      "[2022-11-12 15:29:03,200] (INFO3): Epoch: 1, train loss: 0.5189151763916016, val loss: 0.5198241472244263, val metric: 0.3443878787878788\n",
      "train (loss=0.516958): 100%|██████████| 1/1 [00:00<00:00, 19.67it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 65.20it/s]\n",
      "[2022-11-12 15:29:03,278] (INFO3): Epoch: 2, train loss: 0.5169576406478882, val loss: 0.5199907422065735, val metric: 0.3515878787878788\n",
      "train (loss=0.515543): 100%|██████████| 1/1 [00:00<00:00, 20.02it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s]\n",
      "[2022-11-12 15:29:03,350] (INFO3): Epoch: 3, train loss: 0.5155426859855652, val loss: 0.5202139019966125, val metric: 0.3594181818181818\n",
      "train (loss=0.515668): 100%|██████████| 1/1 [00:00<00:00, 20.12it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.46it/s]\n",
      "[2022-11-12 15:29:03,421] (INFO3): Epoch: 4, train loss: 0.5156683325767517, val loss: 0.5204893946647644, val metric: 0.36785454545454543\n",
      "[2022-11-12 15:29:03,595] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:03,598] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:03,599] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:03,599] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.24it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.93it/s]\n",
      "[2022-11-12 15:29:03,693] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195885300636292, val metric: 0.4940363636363636\n",
      "train (loss=0.515092): 100%|██████████| 1/1 [00:00<00:00, 19.54it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.95it/s]\n",
      "[2022-11-12 15:29:03,771] (INFO3): Epoch: 1, train loss: 0.5150918364524841, val loss: 0.519609808921814, val metric: 0.4940363636363636\n",
      "train (loss=0.509013): 100%|██████████| 1/1 [00:00<00:00, 19.13it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.73it/s]\n",
      "[2022-11-12 15:29:03,850] (INFO3): Epoch: 2, train loss: 0.5090129971504211, val loss: 0.5196492075920105, val metric: 0.4940363636363636\n",
      "train (loss=0.500459): 100%|██████████| 1/1 [00:00<00:00, 20.17it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.19it/s]\n",
      "[2022-11-12 15:29:03,921] (INFO3): Epoch: 3, train loss: 0.5004587173461914, val loss: 0.5197163820266724, val metric: 0.4940363636363636\n",
      "train (loss=0.495848): 100%|██████████| 1/1 [00:00<00:00, 20.39it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.82it/s]\n",
      "[2022-11-12 15:29:03,991] (INFO3): Epoch: 4, train loss: 0.49584847688674927, val loss: 0.5198343396186829, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:29:04,165] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.45718181818181824\u001b[0m\n",
      "[2022-11-12 15:29:04,166] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:04,166] (INFO): Time left 592.96 secs\n",
      "\n",
      "[2022-11-12 15:29:04,167] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:04,169] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.4755212121212121\u001b[0m\n",
      "[2022-11-12 15:29:04,190] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5011757575757576\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:04,201] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5011757575757576\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:04,202] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:04,203] (INFO): \u001b[1mAutoml preset training completed in 1.73 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:04,204] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2022-11-12 15:29:04,204] (INFO): ==================================================\n",
      "[2022-11-12 15:29:04,204] (INFO): ==================================================\n",
      "[2022-11-12 15:29:04,205] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:04,205] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'default_params': {'random_state': 46}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:04,205] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:04,206] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 46}\n",
      "[2022-11-12 15:29:04,206] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:04,206] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'path_to_save': None, 'default_params': {'random_state': 46}}\n",
      "[2022-11-12 15:29:04,207] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:04,207] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:04,216] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:04,217] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:04,217] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:04,218] (INFO): - time: 592.91 seconds\n",
      "[2022-11-12 15:29:04,218] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:04,218] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:04,219] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:04,257] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:04,260] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 592.87 secs\n",
      "[2022-11-12 15:29:04,267] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[2022-11-12 15:29:04,268] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:04,269] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:04,272] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:04,272] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:04,273] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 59.11it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 157.31it/s]\n",
      "[2022-11-12 15:29:04,311] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519507646560669, val metric: 0.5699636363636362\n",
      "train (loss=0.518826): 100%|██████████| 1/1 [00:00<00:00, 64.87it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 167.08it/s]\n",
      "[2022-11-12 15:29:04,341] (INFO3): Epoch: 1, train loss: 0.5188260078430176, val loss: 0.519360363483429, val metric: 0.5777212121212121\n",
      "[2022-11-12 15:29:04,519] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
      "[2022-11-12 15:29:04,523] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:04,523] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:04,523] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 59.78it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.87it/s]\n",
      "[2022-11-12 15:29:04,561] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194738507270813, val metric: 0.5449939393939394\n",
      "train (loss=0.518322): 100%|██████████| 1/1 [00:00<00:00, 63.12it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 161.51it/s]\n",
      "[2022-11-12 15:29:04,591] (INFO3): Epoch: 1, train loss: 0.5183219909667969, val loss: 0.5192884206771851, val metric: 0.5449939393939394\n",
      "[2022-11-12 15:29:04,765] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.5612242424242424\u001b[0m\n",
      "[2022-11-12 15:29:04,766] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:04,767] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:04,768] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:04,769] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:04,772] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:04,772] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:04,773] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 19.28it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.85it/s]\n",
      "[2022-11-12 15:29:04,866] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195084810256958, val metric: 0.6283636363636362\n",
      "train (loss=0.51836): 100%|██████████| 1/1 [00:00<00:00, 19.47it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.04it/s]\n",
      "[2022-11-12 15:29:04,945] (INFO3): Epoch: 1, train loss: 0.5183604955673218, val loss: 0.5194426774978638, val metric: 0.6281939393939394\n",
      "train (loss=0.517569): 100%|██████████| 1/1 [00:00<00:00, 19.51it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 64.12it/s]\n",
      "[2022-11-12 15:29:05,023] (INFO3): Epoch: 2, train loss: 0.5175685882568359, val loss: 0.5193743705749512, val metric: 0.6263030303030303\n",
      "train (loss=0.515923): 100%|██████████| 1/1 [00:00<00:00, 17.28it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 55.39it/s]\n",
      "[2022-11-12 15:29:05,111] (INFO3): Epoch: 3, train loss: 0.515923261642456, val loss: 0.5192907452583313, val metric: 0.621430303030303\n",
      "train (loss=0.514292): 100%|██████████| 1/1 [00:00<00:00, 16.48it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 54.17it/s]\n",
      "[2022-11-12 15:29:05,202] (INFO3): Epoch: 4, train loss: 0.5142917037010193, val loss: 0.519208550453186, val metric: 0.6077333333333333\n",
      "[2022-11-12 15:29:05,383] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:05,387] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:05,387] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:05,387] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 16.10it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 56.44it/s]\n",
      "[2022-11-12 15:29:05,493] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195421576499939, val metric: 0.5449939393939394\n",
      "train (loss=0.516177): 100%|██████████| 1/1 [00:00<00:00, 16.18it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 57.20it/s]\n",
      "[2022-11-12 15:29:05,584] (INFO3): Epoch: 1, train loss: 0.5161771774291992, val loss: 0.5194854736328125, val metric: 0.5449939393939394\n",
      "train (loss=0.510938): 100%|██████████| 1/1 [00:00<00:00, 16.25it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 56.56it/s]\n",
      "[2022-11-12 15:29:05,674] (INFO3): Epoch: 2, train loss: 0.5109382271766663, val loss: 0.519408106803894, val metric: 0.5449939393939394\n",
      "train (loss=0.506052): 100%|██████████| 1/1 [00:00<00:00, 16.38it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 55.69it/s]\n",
      "[2022-11-12 15:29:05,765] (INFO3): Epoch: 3, train loss: 0.5060521364212036, val loss: 0.5193051099777222, val metric: 0.5449939393939394\n",
      "train (loss=0.502016): 100%|██████████| 1/1 [00:00<00:00, 16.44it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 53.53it/s]\n",
      "[2022-11-12 15:29:05,857] (INFO3): Epoch: 4, train loss: 0.5020161867141724, val loss: 0.5191867351531982, val metric: 0.5449939393939394\n",
      "[2022-11-12 15:29:06,037] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5652\u001b[0m\n",
      "[2022-11-12 15:29:06,038] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:06,039] (INFO): Time left 591.09 secs\n",
      "\n",
      "[2022-11-12 15:29:06,039] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:06,042] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5651999999999999\u001b[0m\n",
      "[2022-11-12 15:29:06,063] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5655878787878788\u001b[0m, weights = \u001b[1m[0.57615244 0.42384756]\u001b[0m\n",
      "[2022-11-12 15:29:06,083] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5655878787878788\u001b[0m, weights = \u001b[1m[0.57615244 0.42384756]\u001b[0m\n",
      "[2022-11-12 15:29:06,084] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:06,085] (INFO): \u001b[1mAutoml preset training completed in 1.87 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:06,085] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.57615 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) +\n",
      "\t 0.42385 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:06,086] (INFO): ==================================================\n",
      "[2022-11-12 15:29:06,096] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:06,096] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:06,096] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 277.79it/s]\n",
      "[2022-11-12 15:29:06,276] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:06,277] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:06,277] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 285.27it/s]\n",
      "[2022-11-12 15:29:06,449] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:06,449] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:06,450] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.11it/s]\n",
      "[2022-11-12 15:29:06,637] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:06,638] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:06,639] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 115.76it/s]\n",
      "[2022-11-12 15:29:06,839] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:06,839] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:06,840] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 262.19it/s]\n",
      "[2022-11-12 15:29:07,024] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,025] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,025] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 267.60it/s]\n",
      "[2022-11-12 15:29:07,211] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,211] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,211] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 267.00it/s]\n",
      "[2022-11-12 15:29:07,379] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,380] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,380] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 277.71it/s]\n",
      "[2022-11-12 15:29:07,554] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,555] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,555] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 121.47it/s]\n",
      "[2022-11-12 15:29:07,747] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,747] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,747] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.26it/s]\n",
      "[2022-11-12 15:29:07,955] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:07,956] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:07,956] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 249.42it/s]\n",
      "[2022-11-12 15:29:08,141] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:08,142] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:08,142] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 268.38it/s]\n",
      "[2022-11-12 15:29:08,359] (INFO): Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[2022-11-12 15:29:08,359] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:29:08,360] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:08,360] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:08,361] (INFO): \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:08,361] (INFO): ==================================================\n",
      "[2022-11-12 15:29:08,361] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:08,362] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'default_params': {'random_state': 42}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:08,362] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:08,362] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 42}\n",
      "[2022-11-12 15:29:08,363] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:08,363] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'tuning_params': {'max_tuning_iter': 5, 'max_tuning_time': 3600, 'fit_on_holdout': True}, 'path_to_save': None, 'default_params': {'random_state': 42}}\n",
      "[2022-11-12 15:29:08,363] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:08,364] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp_tuned', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:08,372] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:08,374] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:08,374] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:08,375] (INFO): - time: 600.00 seconds\n",
      "[2022-11-12 15:29:08,375] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:08,375] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:08,376] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:08,416] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:08,418] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 599.95 secs\n",
      "[2022-11-12 15:29:08,425] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ... Time budget is 171.80 secs\n",
      "[2022-11-12 15:29:08,427] (INFO): A new study created in memory with name: no-name-4204075d-3af0-4621-9df7-99fddcfc5a34\n",
      "[2022-11-12 15:29:08,431] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:08,431] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:08,432] (DEBUG): number of continuous features: 1 \n",
      "train (loss=1.46627): 100%|██████████| 3/3 [00:00<00:00, 81.51it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 331.90it/s]\n",
      "[2022-11-12 15:29:08,494] (INFO3): Epoch: 0, train loss: 1.4662727117538452, val loss: 6.256591320037842, val metric: 0.39243636363636364\n",
      "train (loss=2.5669):   0%|          | 0/3 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "############ CONFIG ############\n",
      "{'general_params': {'use_algos': [['lgbm', 'mlp_tuned', 'dense']]},\n",
      " 'nn_params': {'0': {'n_epochs': 2},\n",
      "               '1': {'n_epochs': 5},\n",
      "               'tuning_params': {'fit_on_holdout': True,\n",
      "                                 'max_tuning_iter': 5,\n",
      "                                 'max_tuning_time': 3600}}}\n",
      "################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (loss=3.62826): 100%|██████████| 3/3 [00:00<00:00, 90.39it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 330.65it/s]\n",
      "[2022-11-12 15:29:08,544] (INFO3): Epoch: 1, train loss: 3.6282565593719482, val loss: 3.1632421016693115, val metric: 0.5029090909090909\n",
      "[2022-11-12 15:29:08,715] (INFO): Trial 0 finished with value: 0.5029090909090909 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.5029090909090909.\n",
      "[2022-11-12 15:29:08,719] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.5029090909090909 in 0:00:00.287404\n",
      "[2022-11-12 15:29:08,723] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:08,724] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:08,724] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 53.76it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 157.21it/s]\n",
      "[2022-11-12 15:29:08,764] (INFO3): Epoch: 0, train loss: 0.5195797681808472, val loss: 0.5195525884628296, val metric: 0.5977212121212121\n",
      "train (loss=0.519407): 100%|██████████| 1/1 [00:00<00:00, 62.65it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 162.33it/s]\n",
      "[2022-11-12 15:29:08,794] (INFO3): Epoch: 1, train loss: 0.5194066166877747, val loss: 0.5195175409317017, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:29:08,971] (INFO): Trial 1 finished with value: 0.5977212121212121 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 1 with value: 0.5977212121212121.\n",
      "[2022-11-12 15:29:08,975] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.5977212121212121 in 0:00:00.251216\n",
      "[2022-11-12 15:29:08,979] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:08,980] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:08,980] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.78it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.17it/s]\n",
      "[2022-11-12 15:29:09,019] (INFO3): Epoch: 0, train loss: 0.5195797681808472, val loss: 0.5192608833312988, val metric: 0.5977212121212121\n",
      "train (loss=0.51759): 100%|██████████| 1/1 [00:00<00:00, 60.82it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.33it/s]\n",
      "[2022-11-12 15:29:09,049] (INFO3): Epoch: 1, train loss: 0.5175901055335999, val loss: 0.5184292197227478, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:29:09,220] (INFO): Trial 2 finished with value: 0.5977212121212121 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 1 with value: 0.5977212121212121.\n",
      "[2022-11-12 15:29:09,224] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.5977212121212121 in 0:00:00.245002\n",
      "[2022-11-12 15:29:09,234] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:09,235] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:09,235] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.506372): 100%|██████████| 6/6 [00:00<00:00, 94.99it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 438.46it/s]\n",
      "[2022-11-12 15:29:09,328] (INFO3): Epoch: 0, train loss: 0.5063723921775818, val loss: 0.5255374908447266, val metric: 0.5977212121212121\n",
      "train (loss=0.536827): 100%|██████████| 6/6 [00:00<00:00, 101.00it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 434.88it/s]\n",
      "[2022-11-12 15:29:09,410] (INFO3): Epoch: 1, train loss: 0.5368265509605408, val loss: 0.525424063205719, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:29:09,613] (INFO): Trial 3 finished with value: 0.5977212121212121 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 1 with value: 0.5977212121212121.\n",
      "[2022-11-12 15:29:09,617] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.5977212121212121 in 0:00:00.387514\n",
      "[2022-11-12 15:29:09,621] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:09,621] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:09,622] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.519361): 100%|██████████| 3/3 [00:00<00:00, 84.29it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 328.06it/s]\n",
      "[2022-11-12 15:29:09,681] (INFO3): Epoch: 0, train loss: 0.5193607211112976, val loss: 0.524254322052002, val metric: 0.5977212121212121\n",
      "train (loss=0.516649): 100%|██████████| 3/3 [00:00<00:00, 89.13it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 331.29it/s]\n",
      "[2022-11-12 15:29:09,733] (INFO3): Epoch: 1, train loss: 0.5166487097740173, val loss: 0.5241952538490295, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:29:09,905] (INFO): Trial 4 finished with value: 0.5977212121212121 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 1 with value: 0.5977212121212121.\n",
      "[2022-11-12 15:29:09,909] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.5977212121212121 in 0:00:00.287354\n",
      "[2022-11-12 15:29:09,909] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m completed\n",
      "[2022-11-12 15:29:09,910] (INFO2): The set of hyperparameters \u001b[1m{'bs': 512, 'opt_params': {'lr': 5.415244119402538e-05, 'weight_decay': 0}}\u001b[0m\n",
      " achieve 0.5977 auc\n",
      "[2022-11-12 15:29:09,910] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ...\n",
      "[2022-11-12 15:29:09,911] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 5.415244119402538e-05, 'weight_decay': 0}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:09,912] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:09,915] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:09,916] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:09,916] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.32it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.19it/s]\n",
      "[2022-11-12 15:29:09,955] (INFO3): Epoch: 0, train loss: 0.5195797681808472, val loss: 0.5195525884628296, val metric: 0.5977212121212121\n",
      "train (loss=0.519407): 100%|██████████| 1/1 [00:00<00:00, 61.83it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 164.23it/s]\n",
      "[2022-11-12 15:29:09,986] (INFO3): Epoch: 1, train loss: 0.5194066166877747, val loss: 0.5195175409317017, val metric: 0.5977212121212121\n",
      "[2022-11-12 15:29:10,156] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:10,159] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:10,160] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:10,161] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 56.20it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 157.54it/s]\n",
      "[2022-11-12 15:29:10,200] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519562840461731, val metric: 0.5403636363636364\n",
      "train (loss=0.519349): 100%|██████████| 1/1 [00:00<00:00, 62.46it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.92it/s]\n",
      "[2022-11-12 15:29:10,230] (INFO3): Epoch: 1, train loss: 0.5193490982055664, val loss: 0.5195413827896118, val metric: 0.5440484848484848\n",
      "[2022-11-12 15:29:10,401] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m finished. score = \u001b[1m0.5694181818181818\u001b[0m\n",
      "[2022-11-12 15:29:10,402] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:10,403] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:10,403] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 42}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:10,404] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:10,408] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:10,408] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:10,409] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.13it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 61.06it/s]\n",
      "[2022-11-12 15:29:10,508] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195204615592957, val metric: 0.597769696969697\n",
      "train (loss=0.517228): 100%|██████████| 1/1 [00:00<00:00, 17.32it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.65it/s]\n",
      "[2022-11-12 15:29:10,596] (INFO3): Epoch: 1, train loss: 0.5172278881072998, val loss: 0.5194492936134338, val metric: 0.5872484848484849\n",
      "train (loss=0.514541): 100%|██████████| 1/1 [00:00<00:00, 19.44it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.34it/s]\n",
      "[2022-11-12 15:29:10,675] (INFO3): Epoch: 2, train loss: 0.5145406723022461, val loss: 0.5193597674369812, val metric: 0.598690909090909\n",
      "train (loss=0.512141): 100%|██████████| 1/1 [00:00<00:00, 19.71it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.13it/s]\n",
      "[2022-11-12 15:29:10,755] (INFO3): Epoch: 3, train loss: 0.5121414661407471, val loss: 0.5192506909370422, val metric: 0.5977212121212121\n",
      "train (loss=0.506889): 100%|██████████| 1/1 [00:00<00:00, 19.82it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.98it/s]\n",
      "[2022-11-12 15:29:10,834] (INFO3): Epoch: 4, train loss: 0.5068886876106262, val loss: 0.5191373229026794, val metric: 0.5977454545454546\n",
      "[2022-11-12 15:29:11,040] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:11,044] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:11,044] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:11,045] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.40it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.29it/s]\n",
      "[2022-11-12 15:29:11,141] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195225477218628, val metric: 0.5777696969696969\n",
      "train (loss=0.517174): 100%|██████████| 1/1 [00:00<00:00, 19.91it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.65it/s]\n",
      "[2022-11-12 15:29:11,220] (INFO3): Epoch: 1, train loss: 0.5171740055084229, val loss: 0.5194441676139832, val metric: 0.5777939393939394\n",
      "train (loss=0.514202): 100%|██████████| 1/1 [00:00<00:00, 19.52it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 61.73it/s]\n",
      "[2022-11-12 15:29:11,299] (INFO3): Epoch: 2, train loss: 0.5142015814781189, val loss: 0.5193322896957397, val metric: 0.5777939393939394\n",
      "train (loss=0.510669): 100%|██████████| 1/1 [00:00<00:00, 19.26it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s]\n",
      "[2022-11-12 15:29:11,378] (INFO3): Epoch: 3, train loss: 0.5106688141822815, val loss: 0.5191878080368042, val metric: 0.5777939393939394\n",
      "train (loss=0.506303): 100%|██████████| 1/1 [00:00<00:00, 20.10it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.86it/s]\n",
      "[2022-11-12 15:29:11,456] (INFO3): Epoch: 4, train loss: 0.5063034296035767, val loss: 0.5190219283103943, val metric: 0.5733818181818182\n",
      "[2022-11-12 15:29:11,636] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5767333333333333\u001b[0m\n",
      "[2022-11-12 15:29:11,637] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:11,637] (INFO): Time left 596.74 secs\n",
      "\n",
      "[2022-11-12 15:29:11,638] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:11,640] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5767454545454546\u001b[0m\n",
      "[2022-11-12 15:29:11,662] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.577169696969697\u001b[0m, weights = \u001b[1m[0.19461489 0.8053851 ]\u001b[0m\n",
      "[2022-11-12 15:29:11,683] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.577169696969697\u001b[0m, weights = \u001b[1m[0.19461489 0.8053851 ]\u001b[0m\n",
      "[2022-11-12 15:29:11,683] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:11,685] (INFO): \u001b[1mAutoml preset training completed in 3.31 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:11,685] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.19461 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0) +\n",
      "\t 0.80539 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:11,685] (INFO): ==================================================\n",
      "[2022-11-12 15:29:11,686] (INFO): ==================================================\n",
      "[2022-11-12 15:29:11,686] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:11,686] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'default_params': {'random_state': 43}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:11,687] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:11,687] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 43}\n",
      "[2022-11-12 15:29:11,687] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:11,689] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'tuning_params': {'max_tuning_iter': 5, 'max_tuning_time': 3600, 'fit_on_holdout': True}, 'path_to_save': None, 'default_params': {'random_state': 43}}\n",
      "[2022-11-12 15:29:11,689] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:11,689] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp_tuned', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:11,698] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:11,699] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:11,699] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:11,699] (INFO): - time: 596.67 seconds\n",
      "[2022-11-12 15:29:11,700] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:11,700] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:11,700] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:11,739] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:11,742] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 596.63 secs\n",
      "[2022-11-12 15:29:11,749] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ... Time budget is 170.85 secs\n",
      "[2022-11-12 15:29:11,750] (INFO): A new study created in memory with name: no-name-b98903f5-e9b4-4b94-9399-ec6695fcf026\n",
      "[2022-11-12 15:29:11,754] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:11,755] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:11,755] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.964941): 100%|██████████| 3/3 [00:00<00:00, 86.12it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 333.10it/s]\n",
      "[2022-11-12 15:29:11,813] (INFO3): Epoch: 0, train loss: 0.9649407267570496, val loss: 8.620024681091309, val metric: 0.4\n",
      "train (loss=5.12951): 100%|██████████| 3/3 [00:00<00:00, 92.33it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 335.83it/s]\n",
      "[2022-11-12 15:29:11,862] (INFO3): Epoch: 1, train loss: 5.129507064819336, val loss: 1.6397603750228882, val metric: 0.575709090909091\n",
      "[2022-11-12 15:29:12,026] (INFO): Trial 0 finished with value: 0.575709090909091 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.575709090909091.\n",
      "[2022-11-12 15:29:12,029] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.575709090909091 in 0:00:00.275026\n",
      "[2022-11-12 15:29:12,034] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:12,035] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:12,035] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 58.33it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 158.20it/s]\n",
      "[2022-11-12 15:29:12,073] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195567011833191, val metric: 0.5712242424242425\n",
      "train (loss=0.519364): 100%|██████████| 1/1 [00:00<00:00, 65.05it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 163.99it/s]\n",
      "[2022-11-12 15:29:12,102] (INFO3): Epoch: 1, train loss: 0.5193644762039185, val loss: 0.5195275545120239, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:12,282] (INFO): Trial 1 finished with value: 0.5712484848484849 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 0 with value: 0.575709090909091.\n",
      "[2022-11-12 15:29:12,285] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.5712484848484849 in 0:00:00.251286\n",
      "[2022-11-12 15:29:12,290] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:12,290] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:12,291] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.91it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 157.19it/s]\n",
      "[2022-11-12 15:29:12,329] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5193134546279907, val metric: 0.5712484848484849\n",
      "train (loss=0.517123): 100%|██████████| 1/1 [00:00<00:00, 62.27it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 162.42it/s]\n",
      "[2022-11-12 15:29:12,359] (INFO3): Epoch: 1, train loss: 0.5171230435371399, val loss: 0.5186690092086792, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:12,533] (INFO): Trial 2 finished with value: 0.5712484848484849 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 0 with value: 0.575709090909091.\n",
      "[2022-11-12 15:29:12,536] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.5712484848484849 in 0:00:00.246384\n",
      "[2022-11-12 15:29:12,541] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:12,541] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:12,541] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.517822): 100%|██████████| 6/6 [00:00<00:00, 94.34it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 383.80it/s]\n",
      "[2022-11-12 15:29:12,636] (INFO3): Epoch: 0, train loss: 0.5178222060203552, val loss: 0.5217161178588867, val metric: 0.5712484848484849\n",
      "train (loss=0.517528): 100%|██████████| 6/6 [00:00<00:00, 92.23it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 384.83it/s]\n",
      "[2022-11-12 15:29:12,726] (INFO3): Epoch: 1, train loss: 0.5175278782844543, val loss: 0.521630048751831, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:12,891] (INFO): Trial 3 finished with value: 0.5712484848484849 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 0 with value: 0.575709090909091.\n",
      "[2022-11-12 15:29:12,895] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.5712484848484849 in 0:00:00.353693\n",
      "[2022-11-12 15:29:12,899] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:12,900] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:12,900] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.516843): 100%|██████████| 3/3 [00:00<00:00, 80.32it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 306.54it/s]\n",
      "[2022-11-12 15:29:12,963] (INFO3): Epoch: 0, train loss: 0.5168428421020508, val loss: 0.5193653702735901, val metric: 0.5712484848484849\n",
      "train (loss=0.51902): 100%|██████████| 3/3 [00:00<00:00, 83.72it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 303.76it/s]\n",
      "[2022-11-12 15:29:13,017] (INFO3): Epoch: 1, train loss: 0.5190203785896301, val loss: 0.51931232213974, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:13,183] (INFO): Trial 4 finished with value: 0.5712484848484849 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 0 with value: 0.575709090909091.\n",
      "[2022-11-12 15:29:13,187] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.5712484848484849 in 0:00:00.287754\n",
      "[2022-11-12 15:29:13,188] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m completed\n",
      "[2022-11-12 15:29:13,188] (INFO2): The set of hyperparameters \u001b[1m{'bs': 128, 'opt_params': {'lr': 0.029154431891537533, 'weight_decay': 0}}\u001b[0m\n",
      " achieve 0.5757 auc\n",
      "[2022-11-12 15:29:13,189] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ...\n",
      "[2022-11-12 15:29:13,190] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 128, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 0.029154431891537533, 'weight_decay': 0}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:13,191] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:13,194] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:13,195] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:13,195] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.964941): 100%|██████████| 3/3 [00:00<00:00, 80.54it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 306.17it/s]\n",
      "[2022-11-12 15:29:13,258] (INFO3): Epoch: 0, train loss: 0.9649407267570496, val loss: 8.620024681091309, val metric: 0.4\n",
      "train (loss=5.12951): 100%|██████████| 3/3 [00:00<00:00, 84.66it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 304.54it/s]\n",
      "[2022-11-12 15:29:13,311] (INFO3): Epoch: 1, train loss: 5.129507064819336, val loss: 1.6397603750228882, val metric: 0.575709090909091\n",
      "[2022-11-12 15:29:13,476] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:13,480] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:13,480] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:13,481] (DEBUG): number of continuous features: 1 \n",
      "train (loss=1.75834): 100%|██████████| 3/3 [00:00<00:00, 80.06it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 301.63it/s]\n",
      "[2022-11-12 15:29:13,543] (INFO3): Epoch: 0, train loss: 1.7583450078964233, val loss: 3.8944854736328125, val metric: 0.40225454545454553\n",
      "train (loss=8.1026): 100%|██████████| 3/3 [00:00<00:00, 80.94it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 302.95it/s]\n",
      "[2022-11-12 15:29:13,599] (INFO3): Epoch: 1, train loss: 8.102596282958984, val loss: 5.683197021484375, val metric: 0.5557333333333333\n",
      "[2022-11-12 15:29:13,764] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m finished. score = \u001b[1m0.546860606060606\u001b[0m\n",
      "[2022-11-12 15:29:13,765] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:13,766] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:13,767] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 43}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:13,767] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:13,771] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:13,771] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:13,772] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.47it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 58.32it/s]\n",
      "[2022-11-12 15:29:13,870] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195221304893494, val metric: 0.5712242424242424\n",
      "train (loss=0.517692): 100%|██████████| 1/1 [00:00<00:00, 18.53it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.95it/s]\n",
      "[2022-11-12 15:29:13,953] (INFO3): Epoch: 1, train loss: 0.5176919102668762, val loss: 0.5194374918937683, val metric: 0.5712484848484849\n",
      "train (loss=0.515502): 100%|██████████| 1/1 [00:00<00:00, 18.50it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.31it/s]\n",
      "[2022-11-12 15:29:14,036] (INFO3): Epoch: 2, train loss: 0.5155020356178284, val loss: 0.5193321108818054, val metric: 0.5712484848484849\n",
      "train (loss=0.512497): 100%|██████████| 1/1 [00:00<00:00, 18.42it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.36it/s]\n",
      "[2022-11-12 15:29:14,120] (INFO3): Epoch: 3, train loss: 0.5124971866607666, val loss: 0.519190788269043, val metric: 0.5712484848484849\n",
      "train (loss=0.510455): 100%|██████████| 1/1 [00:00<00:00, 18.99it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.25it/s]\n",
      "[2022-11-12 15:29:14,202] (INFO3): Epoch: 4, train loss: 0.5104547739028931, val loss: 0.5190282464027405, val metric: 0.5712484848484849\n",
      "[2022-11-12 15:29:14,379] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:14,383] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:14,384] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:14,384] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.36it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.32it/s]\n",
      "[2022-11-12 15:29:14,483] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195656418800354, val metric: 0.5387151515151515\n",
      "train (loss=0.517436): 100%|██████████| 1/1 [00:00<00:00, 18.65it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.29it/s]\n",
      "[2022-11-12 15:29:14,565] (INFO3): Epoch: 1, train loss: 0.5174357891082764, val loss: 0.5195164084434509, val metric: 0.5545454545454545\n",
      "train (loss=0.514027): 100%|██████████| 1/1 [00:00<00:00, 18.83it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.76it/s]\n",
      "[2022-11-12 15:29:14,647] (INFO3): Epoch: 2, train loss: 0.5140268206596375, val loss: 0.5194510817527771, val metric: 0.5585454545454546\n",
      "train (loss=0.510927): 100%|██████████| 1/1 [00:00<00:00, 18.84it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.67it/s]\n",
      "[2022-11-12 15:29:14,730] (INFO3): Epoch: 3, train loss: 0.5109272599220276, val loss: 0.5193652510643005, val metric: 0.5611878787878788\n",
      "train (loss=0.509275): 100%|██████████| 1/1 [00:00<00:00, 18.95it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.53it/s]\n",
      "[2022-11-12 15:29:14,813] (INFO3): Epoch: 4, train loss: 0.509275496006012, val loss: 0.5192763209342957, val metric: 0.560630303030303\n",
      "[2022-11-12 15:29:14,991] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5528848484848485\u001b[0m\n",
      "[2022-11-12 15:29:14,992] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:14,993] (INFO): Time left 593.38 secs\n",
      "\n",
      "[2022-11-12 15:29:14,993] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:14,996] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5484424242424242\u001b[0m\n",
      "[2022-11-12 15:29:15,019] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5505696969696969\u001b[0m, weights = \u001b[1m[0.25402814 0.74597186]\u001b[0m\n",
      "[2022-11-12 15:29:15,042] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5505696969696969\u001b[0m, weights = \u001b[1m[0.25402814 0.74597186]\u001b[0m\n",
      "[2022-11-12 15:29:15,042] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:15,043] (INFO): \u001b[1mAutoml preset training completed in 3.34 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:15,044] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.25403 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0) +\n",
      "\t 0.74597 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:15,044] (INFO): ==================================================\n",
      "[2022-11-12 15:29:15,045] (INFO): ==================================================\n",
      "[2022-11-12 15:29:15,045] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:15,046] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'nn_params': {'default_params': {'random_state': 44}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:15,046] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:15,046] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 44}\n",
      "[2022-11-12 15:29:15,047] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:15,047] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'tuning_params': {'max_tuning_iter': 5, 'max_tuning_time': 3600, 'fit_on_holdout': True}, 'path_to_save': None, 'default_params': {'random_state': 44}}\n",
      "[2022-11-12 15:29:15,047] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:15,048] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp_tuned', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:15,057] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:15,058] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:15,058] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:15,058] (INFO): - time: 593.31 seconds\n",
      "[2022-11-12 15:29:15,059] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:15,059] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:15,060] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:15,100] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:15,103] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 593.27 secs\n",
      "[2022-11-12 15:29:15,110] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ... Time budget is 169.89 secs\n",
      "[2022-11-12 15:29:15,112] (INFO): A new study created in memory with name: no-name-de20330c-3af4-40b8-9ea7-e41d258e6586\n",
      "[2022-11-12 15:29:15,116] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:15,117] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:15,117] (DEBUG): number of continuous features: 1 \n",
      "train (loss=1.02406): 100%|██████████| 3/3 [00:00<00:00, 79.55it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 299.92it/s]\n",
      "[2022-11-12 15:29:15,180] (INFO3): Epoch: 0, train loss: 1.0240612030029297, val loss: 6.720970153808594, val metric: 0.3914666666666667\n",
      "train (loss=6.49348): 100%|██████████| 3/3 [00:00<00:00, 80.54it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 293.91it/s]\n",
      "[2022-11-12 15:29:15,236] (INFO3): Epoch: 1, train loss: 6.493479251861572, val loss: 3.4096977710723877, val metric: 0.47721212121212114\n",
      "[2022-11-12 15:29:15,424] (INFO): Trial 0 finished with value: 0.47721212121212114 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.47721212121212114.\n",
      "[2022-11-12 15:29:15,428] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.47721212121212114 in 0:00:00.311041\n",
      "[2022-11-12 15:29:15,432] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:15,433] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:15,433] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 55.04it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 151.15it/s]\n",
      "[2022-11-12 15:29:15,474] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195600986480713, val metric: 0.6069333333333333\n",
      "train (loss=0.519452): 100%|██████████| 1/1 [00:00<00:00, 58.35it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 154.00it/s]\n",
      "[2022-11-12 15:29:15,506] (INFO3): Epoch: 1, train loss: 0.5194524526596069, val loss: 0.5195342302322388, val metric: 0.6065454545454545\n",
      "[2022-11-12 15:29:15,686] (INFO): Trial 1 finished with value: 0.6065454545454545 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 1 with value: 0.6065454545454545.\n",
      "[2022-11-12 15:29:15,690] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.6065454545454545 in 0:00:00.257957\n",
      "[2022-11-12 15:29:15,695] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:15,695] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:15,696] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.87it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 153.44it/s]\n",
      "[2022-11-12 15:29:15,735] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519351601600647, val metric: 0.607030303030303\n",
      "train (loss=0.518134): 100%|██████████| 1/1 [00:00<00:00, 59.84it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.23it/s]\n",
      "[2022-11-12 15:29:15,767] (INFO3): Epoch: 1, train loss: 0.5181341767311096, val loss: 0.5187487602233887, val metric: 0.6084848484848485\n",
      "[2022-11-12 15:29:15,944] (INFO): Trial 2 finished with value: 0.6084848484848485 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 2 with value: 0.6084848484848485.\n",
      "[2022-11-12 15:29:15,947] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.6084848484848485 in 0:00:00.252626\n",
      "[2022-11-12 15:29:15,952] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:15,952] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:15,953] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.53319): 100%|██████████| 6/6 [00:00<00:00, 85.78it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 375.46it/s]\n",
      "[2022-11-12 15:29:16,055] (INFO3): Epoch: 0, train loss: 0.5331904888153076, val loss: 0.5294005274772644, val metric: 0.6082181818181818\n",
      "train (loss=0.52152): 100%|██████████| 6/6 [00:00<00:00, 90.80it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 382.90it/s]\n",
      "[2022-11-12 15:29:16,146] (INFO3): Epoch: 1, train loss: 0.5215204358100891, val loss: 0.5293195843696594, val metric: 0.6063757575757576\n",
      "[2022-11-12 15:29:16,348] (INFO): Trial 3 finished with value: 0.6063757575757576 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 2 with value: 0.6084848484848485.\n",
      "[2022-11-12 15:29:16,352] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.6063757575757576 in 0:00:00.399894\n",
      "[2022-11-12 15:29:16,357] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:16,357] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:16,358] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.523006): 100%|██████████| 3/3 [00:00<00:00, 77.78it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 293.92it/s]\n",
      "[2022-11-12 15:29:16,423] (INFO3): Epoch: 0, train loss: 0.523006021976471, val loss: 0.5279322266578674, val metric: 0.6084848484848485\n",
      "train (loss=0.527752): 100%|██████████| 3/3 [00:00<00:00, 75.18it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 292.93it/s]\n",
      "[2022-11-12 15:29:16,482] (INFO3): Epoch: 1, train loss: 0.5277517437934875, val loss: 0.5278807878494263, val metric: 0.6084848484848485\n",
      "[2022-11-12 15:29:16,669] (INFO): Trial 4 finished with value: 0.6084848484848485 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 2 with value: 0.6084848484848485.\n",
      "[2022-11-12 15:29:16,673] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.6084848484848485 in 0:00:00.316222\n",
      "[2022-11-12 15:29:16,674] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m completed\n",
      "[2022-11-12 15:29:16,675] (INFO2): The set of hyperparameters \u001b[1m{'bs': 1024, 'opt_params': {'lr': 0.0006672367170464204, 'weight_decay': 2.9204338471814107e-05}}\u001b[0m\n",
      " achieve 0.6085 auc\n",
      "[2022-11-12 15:29:16,675] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ...\n",
      "[2022-11-12 15:29:16,676] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 1024, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 0.0006672367170464204, 'weight_decay': 2.9204338471814107e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:16,677] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:16,681] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:16,681] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:16,681] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 55.43it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 147.59it/s]\n",
      "[2022-11-12 15:29:16,727] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519351601600647, val metric: 0.607030303030303\n",
      "train (loss=0.518134): 100%|██████████| 1/1 [00:00<00:00, 52.32it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 141.11it/s]\n",
      "[2022-11-12 15:29:16,763] (INFO3): Epoch: 1, train loss: 0.5181341767311096, val loss: 0.5187487602233887, val metric: 0.6084848484848485\n",
      "[2022-11-12 15:29:17,044] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:17,049] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:17,049] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:17,050] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 52.82it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 150.07it/s]\n",
      "[2022-11-12 15:29:17,092] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5193017721176147, val metric: 0.5645333333333333\n",
      "train (loss=0.516746): 100%|██████████| 1/1 [00:00<00:00, 56.88it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 154.61it/s]\n",
      "[2022-11-12 15:29:17,125] (INFO3): Epoch: 1, train loss: 0.516746461391449, val loss: 0.5185851454734802, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:29:17,333] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m finished. score = \u001b[1m0.5737757575757576\u001b[0m\n",
      "[2022-11-12 15:29:17,334] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:17,335] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:17,335] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 44}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:17,336] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:17,340] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:17,340] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:17,341] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.76it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.65it/s]\n",
      "[2022-11-12 15:29:17,442] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195702910423279, val metric: 0.577939393939394\n",
      "train (loss=0.517459): 100%|██████████| 1/1 [00:00<00:00, 17.43it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.53it/s]\n",
      "[2022-11-12 15:29:17,529] (INFO3): Epoch: 1, train loss: 0.5174590945243835, val loss: 0.5195289254188538, val metric: 0.6138181818181818\n",
      "train (loss=0.514439): 100%|██████████| 1/1 [00:00<00:00, 17.95it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s]\n",
      "[2022-11-12 15:29:17,614] (INFO3): Epoch: 2, train loss: 0.5144389867782593, val loss: 0.5194674730300903, val metric: 0.6056242424242424\n",
      "train (loss=0.511586): 100%|██████████| 1/1 [00:00<00:00, 18.21it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.00it/s]\n",
      "[2022-11-12 15:29:17,699] (INFO3): Epoch: 3, train loss: 0.511585533618927, val loss: 0.5194090604782104, val metric: 0.6070787878787879\n",
      "train (loss=0.507587): 100%|██████████| 1/1 [00:00<00:00, 18.50it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.05it/s]\n",
      "[2022-11-12 15:29:17,785] (INFO3): Epoch: 4, train loss: 0.5075871348381042, val loss: 0.5193563103675842, val metric: 0.6058666666666667\n",
      "[2022-11-12 15:29:17,970] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:17,974] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:17,974] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:17,975] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.17it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s]\n",
      "[2022-11-12 15:29:18,074] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195195078849792, val metric: 0.5646545454545455\n",
      "train (loss=0.517439): 100%|██████████| 1/1 [00:00<00:00, 18.33it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.33it/s]\n",
      "[2022-11-12 15:29:18,159] (INFO3): Epoch: 1, train loss: 0.5174387693405151, val loss: 0.5194229483604431, val metric: 0.5645333333333333\n",
      "train (loss=0.513859): 100%|██████████| 1/1 [00:00<00:00, 18.36it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 58.96it/s]\n",
      "[2022-11-12 15:29:18,244] (INFO3): Epoch: 2, train loss: 0.5138586163520813, val loss: 0.5192946195602417, val metric: 0.5645333333333333\n",
      "train (loss=0.510632): 100%|██████████| 1/1 [00:00<00:00, 18.63it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 60.17it/s]\n",
      "[2022-11-12 15:29:18,327] (INFO3): Epoch: 3, train loss: 0.5106315612792969, val loss: 0.519133985042572, val metric: 0.5645333333333333\n",
      "train (loss=0.50673): 100%|██████████| 1/1 [00:00<00:00, 18.81it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 58.74it/s]\n",
      "[2022-11-12 15:29:18,411] (INFO3): Epoch: 4, train loss: 0.5067295432090759, val loss: 0.5189236402511597, val metric: 0.5645333333333333\n",
      "[2022-11-12 15:29:18,597] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5649818181818181\u001b[0m\n",
      "[2022-11-12 15:29:18,598] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:18,598] (INFO): Time left 589.77 secs\n",
      "\n",
      "[2022-11-12 15:29:18,599] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:18,602] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5717636363636363\u001b[0m\n",
      "[2022-11-12 15:29:18,624] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5732545454545455\u001b[0m, weights = \u001b[1m[0.9442719  0.05572809]\u001b[0m\n",
      "[2022-11-12 15:29:18,647] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5732545454545455\u001b[0m, weights = \u001b[1m[0.9442719  0.05572809]\u001b[0m\n",
      "[2022-11-12 15:29:18,648] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:18,649] (INFO): \u001b[1mAutoml preset training completed in 3.59 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:18,649] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.94427 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0) +\n",
      "\t 0.05573 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:18,650] (INFO): ==================================================\n",
      "[2022-11-12 15:29:18,650] (INFO): ==================================================\n",
      "[2022-11-12 15:29:18,651] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:18,651] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'nn_params': {'default_params': {'random_state': 45}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:18,651] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:18,652] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 45}\n",
      "[2022-11-12 15:29:18,652] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:18,652] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'tuning_params': {'max_tuning_iter': 5, 'max_tuning_time': 3600, 'fit_on_holdout': True}, 'path_to_save': None, 'default_params': {'random_state': 45}}\n",
      "[2022-11-12 15:29:18,653] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:18,653] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp_tuned', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:18,662] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:18,663] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:18,664] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:18,664] (INFO): - time: 589.71 seconds\n",
      "[2022-11-12 15:29:18,664] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:18,665] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:18,665] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:18,706] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:18,709] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 589.66 secs\n",
      "[2022-11-12 15:29:18,717] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ... Time budget is 168.85 secs\n",
      "[2022-11-12 15:29:18,718] (INFO): A new study created in memory with name: no-name-d1fa4204-b08f-42f7-95b2-37b26a9dc1ea\n",
      "[2022-11-12 15:29:18,722] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:18,723] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:18,723] (DEBUG): number of continuous features: 1 \n",
      "train (loss=1.57785): 100%|██████████| 3/3 [00:00<00:00, 83.40it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 325.50it/s]\n",
      "[2022-11-12 15:29:18,783] (INFO3): Epoch: 0, train loss: 1.5778518915176392, val loss: 4.035219669342041, val metric: 0.5380848484848485\n",
      "train (loss=6.06846): 100%|██████████| 3/3 [00:00<00:00, 88.40it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 320.78it/s]\n",
      "[2022-11-12 15:29:18,834] (INFO3): Epoch: 1, train loss: 6.068458557128906, val loss: 2.7489230632781982, val metric: 0.4053333333333333\n",
      "[2022-11-12 15:29:19,022] (INFO): Trial 0 finished with value: 0.4053333333333333 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.4053333333333333.\n",
      "[2022-11-12 15:29:19,025] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.4053333333333333 in 0:00:00.303089\n",
      "[2022-11-12 15:29:19,030] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:19,030] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:19,031] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 57.73it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.30it/s]\n",
      "[2022-11-12 15:29:19,069] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195879340171814, val metric: 0.4243393939393939\n",
      "train (loss=0.519516): 100%|██████████| 1/1 [00:00<00:00, 61.23it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 164.02it/s]\n",
      "[2022-11-12 15:29:19,100] (INFO3): Epoch: 1, train loss: 0.5195164084434509, val loss: 0.5195847153663635, val metric: 0.49818181818181817\n",
      "[2022-11-12 15:29:19,288] (INFO): Trial 1 finished with value: 0.49818181818181817 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 1 with value: 0.49818181818181817.\n",
      "[2022-11-12 15:29:19,291] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.49818181818181817 in 0:00:00.261516\n",
      "[2022-11-12 15:29:19,296] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:19,297] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:19,297] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 59.33it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 159.98it/s]\n",
      "[2022-11-12 15:29:19,335] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196757912635803, val metric: 0.42397575757575756\n",
      "train (loss=0.518841): 100%|██████████| 1/1 [00:00<00:00, 61.59it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.13it/s]\n",
      "[2022-11-12 15:29:19,366] (INFO3): Epoch: 1, train loss: 0.5188410878181458, val loss: 0.5195048451423645, val metric: 0.5191272727272727\n",
      "[2022-11-12 15:29:19,551] (INFO): Trial 2 finished with value: 0.5191272727272727 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 2 with value: 0.5191272727272727.\n",
      "[2022-11-12 15:29:19,554] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.5191272727272727 in 0:00:00.258471\n",
      "[2022-11-12 15:29:19,559] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:19,559] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:19,560] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.506446): 100%|██████████| 6/6 [00:00<00:00, 96.20it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 428.26it/s]\n",
      "[2022-11-12 15:29:19,654] (INFO3): Epoch: 0, train loss: 0.5064457058906555, val loss: 0.5333368182182312, val metric: 0.31936969696969697\n",
      "train (loss=0.525554): 100%|██████████| 6/6 [00:00<00:00, 98.54it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 432.85it/s]\n",
      "[2022-11-12 15:29:19,737] (INFO3): Epoch: 1, train loss: 0.5255538821220398, val loss: 0.5333520770072937, val metric: 0.4201939393939394\n",
      "[2022-11-12 15:29:19,916] (INFO): Trial 3 finished with value: 0.4201939393939394 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 2 with value: 0.5191272727272727.\n",
      "[2022-11-12 15:29:19,920] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.4201939393939394 in 0:00:00.360848\n",
      "[2022-11-12 15:29:19,925] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:19,925] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:19,926] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.519459): 100%|██████████| 3/3 [00:00<00:00, 73.51it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 315.71it/s]\n",
      "[2022-11-12 15:29:19,991] (INFO3): Epoch: 0, train loss: 0.5194593071937561, val loss: 0.5243471264839172, val metric: 0.31936969696969697\n",
      "train (loss=0.516964): 100%|██████████| 3/3 [00:00<00:00, 84.16it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 324.65it/s]\n",
      "[2022-11-12 15:29:20,045] (INFO3): Epoch: 1, train loss: 0.5169642567634583, val loss: 0.5243525505065918, val metric: 0.3192969696969697\n",
      "[2022-11-12 15:29:20,256] (INFO): Trial 4 finished with value: 0.3192969696969697 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 2 with value: 0.5191272727272727.\n",
      "[2022-11-12 15:29:20,260] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.3192969696969697 in 0:00:00.334944\n",
      "[2022-11-12 15:29:20,261] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m completed\n",
      "[2022-11-12 15:29:20,261] (INFO2): The set of hyperparameters \u001b[1m{'bs': 1024, 'opt_params': {'lr': 0.0006672367170464204, 'weight_decay': 2.9204338471814107e-05}}\u001b[0m\n",
      " achieve 0.5191 auc\n",
      "[2022-11-12 15:29:20,262] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ...\n",
      "[2022-11-12 15:29:20,263] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 1024, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 0.0006672367170464204, 'weight_decay': 2.9204338471814107e-05}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:20,264] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:20,267] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:20,268] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:20,268] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 41.25it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 155.83it/s]\n",
      "[2022-11-12 15:29:20,315] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196757912635803, val metric: 0.42397575757575756\n",
      "train (loss=0.518841): 100%|██████████| 1/1 [00:00<00:00, 60.03it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.61it/s]\n",
      "[2022-11-12 15:29:20,346] (INFO3): Epoch: 1, train loss: 0.5188410878181458, val loss: 0.5195048451423645, val metric: 0.5191272727272727\n",
      "[2022-11-12 15:29:20,548] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:20,552] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:20,552] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:20,552] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 58.97it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 151.50it/s]\n",
      "[2022-11-12 15:29:20,591] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195710062980652, val metric: 0.4940363636363636\n",
      "train (loss=0.514928): 100%|██████████| 1/1 [00:00<00:00, 59.25it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 160.30it/s]\n",
      "[2022-11-12 15:29:20,622] (INFO3): Epoch: 1, train loss: 0.5149281024932861, val loss: 0.5196409225463867, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:29:20,798] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m finished. score = \u001b[1m0.5055333333333333\u001b[0m\n",
      "[2022-11-12 15:29:20,799] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:20,800] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:20,800] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 45}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:20,802] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:20,805] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:20,805] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:20,806] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 18.04it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 59.74it/s]\n",
      "[2022-11-12 15:29:20,905] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5196776390075684, val metric: 0.32913939393939395\n",
      "train (loss=0.518915): 100%|██████████| 1/1 [00:00<00:00, 18.26it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.58it/s]\n",
      "[2022-11-12 15:29:20,987] (INFO3): Epoch: 1, train loss: 0.5189151763916016, val loss: 0.5198241472244263, val metric: 0.3443878787878788\n",
      "train (loss=0.516958): 100%|██████████| 1/1 [00:00<00:00, 19.19it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.49it/s]\n",
      "[2022-11-12 15:29:21,066] (INFO3): Epoch: 2, train loss: 0.5169576406478882, val loss: 0.5199907422065735, val metric: 0.3515878787878788\n",
      "train (loss=0.515543): 100%|██████████| 1/1 [00:00<00:00, 19.67it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.11it/s]\n",
      "[2022-11-12 15:29:21,139] (INFO3): Epoch: 3, train loss: 0.5155426859855652, val loss: 0.5202139019966125, val metric: 0.3594181818181818\n",
      "train (loss=0.515668): 100%|██████████| 1/1 [00:00<00:00, 18.86it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.95it/s]\n",
      "[2022-11-12 15:29:21,215] (INFO3): Epoch: 4, train loss: 0.5156683325767517, val loss: 0.5204893946647644, val metric: 0.36785454545454543\n",
      "[2022-11-12 15:29:21,416] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:21,419] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:21,420] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:21,420] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.65it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.52it/s]\n",
      "[2022-11-12 15:29:21,518] (INFO3): Epoch: 0, train loss: 0.5195798873901367, val loss: 0.5195885300636292, val metric: 0.4940363636363636\n",
      "train (loss=0.515092): 100%|██████████| 1/1 [00:00<00:00, 19.81it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.03it/s]\n",
      "[2022-11-12 15:29:21,596] (INFO3): Epoch: 1, train loss: 0.5150918364524841, val loss: 0.519609808921814, val metric: 0.4940363636363636\n",
      "train (loss=0.509013): 100%|██████████| 1/1 [00:00<00:00, 17.72it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.96it/s]\n",
      "[2022-11-12 15:29:21,680] (INFO3): Epoch: 2, train loss: 0.5090129971504211, val loss: 0.5196492075920105, val metric: 0.4940363636363636\n",
      "train (loss=0.500459): 100%|██████████| 1/1 [00:00<00:00, 18.22it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.66it/s]\n",
      "[2022-11-12 15:29:21,757] (INFO3): Epoch: 3, train loss: 0.5004587173461914, val loss: 0.5197163820266724, val metric: 0.4940363636363636\n",
      "train (loss=0.495848): 100%|██████████| 1/1 [00:00<00:00, 16.49it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.40it/s]\n",
      "[2022-11-12 15:29:21,839] (INFO3): Epoch: 4, train loss: 0.49584847688674927, val loss: 0.5198343396186829, val metric: 0.4940363636363636\n",
      "[2022-11-12 15:29:22,126] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.45718181818181824\u001b[0m\n",
      "[2022-11-12 15:29:22,127] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:22,128] (INFO): Time left 586.24 secs\n",
      "\n",
      "[2022-11-12 15:29:22,128] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:22,135] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.48771515151515155\u001b[0m\n",
      "[2022-11-12 15:29:22,156] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5055333333333333\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:22,167] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5055333333333333\u001b[0m, weights = \u001b[1m[1. 0.]\u001b[0m\n",
      "[2022-11-12 15:29:22,167] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:22,169] (INFO): \u001b[1mAutoml preset training completed in 3.50 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:22,170] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0) \n",
      "\n",
      "[2022-11-12 15:29:22,170] (INFO): ==================================================\n",
      "[2022-11-12 15:29:22,171] (INFO): ==================================================\n",
      "[2022-11-12 15:29:22,171] (INFO): Start 0 automl preset configuration:\n",
      "[2022-11-12 15:29:22,171] (INFO): \u001b[1mexample.yaml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'nn_params': {'default_params': {'random_state': 46}}, 'general_params': {'return_all_predictions': False}}\n",
      "[2022-11-12 15:29:22,172] (INFO3): Found reader_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:22,172] (INFO3): Merged variant for reader_params = {'cv': 2, 'random_state': 46}\n",
      "[2022-11-12 15:29:22,172] (INFO3): Found nn_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:22,173] (INFO3): Merged variant for nn_params = {'0': {'n_epochs': 2}, '1': {'n_epochs': 5}, 'tuning_params': {'max_tuning_iter': 5, 'max_tuning_time': 3600, 'fit_on_holdout': True}, 'path_to_save': None, 'default_params': {'random_state': 46}}\n",
      "[2022-11-12 15:29:22,173] (INFO3): Found general_params in kwargs, need to combine\n",
      "[2022-11-12 15:29:22,173] (INFO3): Merged variant for general_params = {'use_algos': [['lgbm', 'mlp_tuned', 'dense']], 'return_all_predictions': False}\n",
      "[2022-11-12 15:29:22,183] (INFO): Stdout logging level is ERROR.\n",
      "[2022-11-12 15:29:22,184] (INFO): Task: binary\n",
      "\n",
      "[2022-11-12 15:29:22,185] (INFO): Start automl preset with listed constraints:\n",
      "[2022-11-12 15:29:22,185] (INFO): - time: 586.19 seconds\n",
      "[2022-11-12 15:29:22,186] (INFO): - CPU: 4 cores\n",
      "[2022-11-12 15:29:22,186] (INFO): - memory: 16 GB\n",
      "\n",
      "[2022-11-12 15:29:22,187] (INFO): \u001b[1mTrain data shape: (700, 4)\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:22,227] (INFO3): Feats was rejected during automatic roles guess: []\n",
      "[2022-11-12 15:29:22,230] (INFO): Layer \u001b[1m1\u001b[0m train process start. Time left 586.14 secs\n",
      "[2022-11-12 15:29:22,237] (INFO): Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ... Time budget is 167.85 secs\n",
      "[2022-11-12 15:29:22,238] (INFO): A new study created in memory with name: no-name-db9cb86e-39fc-4b3b-81c2-452832aa0606\n",
      "[2022-11-12 15:29:22,243] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:22,243] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:22,244] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.85266): 100%|██████████| 3/3 [00:00<00:00, 77.44it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 317.19it/s]\n",
      "[2022-11-12 15:29:22,307] (INFO3): Epoch: 0, train loss: 0.8526596426963806, val loss: 21.999155044555664, val metric: 0.6095030303030303\n",
      "train (loss=6.25144): 100%|██████████| 3/3 [00:00<00:00, 80.97it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 325.21it/s]\n",
      "[2022-11-12 15:29:22,362] (INFO3): Epoch: 1, train loss: 6.251444339752197, val loss: 5.725087642669678, val metric: 0.6125090909090909\n",
      "[2022-11-12 15:29:22,585] (INFO): Trial 0 finished with value: 0.6125090909090909 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533}. Best is trial 0 with value: 0.6125090909090909.\n",
      "[2022-11-12 15:29:22,589] (INFO3): \u001b[1mTrial 1\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 0.029154431891537533} scored 0.6125090909090909 in 0:00:00.346132\n",
      "[2022-11-12 15:29:22,594] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:22,594] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:22,595] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 54.11it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 155.92it/s]\n",
      "[2022-11-12 15:29:22,634] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.519566535949707, val metric: 0.5698909090909091\n",
      "train (loss=0.51944): 100%|██████████| 1/1 [00:00<00:00, 57.32it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 161.54it/s]\n",
      "[2022-11-12 15:29:22,666] (INFO3): Epoch: 1, train loss: 0.5194399952888489, val loss: 0.5195493102073669, val metric: 0.5701818181818181\n",
      "[2022-11-12 15:29:22,854] (INFO): Trial 1 finished with value: 0.5701818181818181 and parameters: {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05}. Best is trial 0 with value: 0.6125090909090909.\n",
      "[2022-11-12 15:29:22,857] (INFO3): \u001b[1mTrial 2\u001b[0m with hyperparameters {'bs': 512, 'weight_decay_bin': 0, 'lr': 5.415244119402538e-05} scored 0.5701818181818181 in 0:00:00.263598\n",
      "[2022-11-12 15:29:22,862] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:22,862] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:22,863] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 48.18it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 154.81it/s]\n",
      "[2022-11-12 15:29:22,906] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5194295048713684, val metric: 0.5708121212121212\n",
      "train (loss=0.518009): 100%|██████████| 1/1 [00:00<00:00, 55.08it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 167.08it/s]\n",
      "[2022-11-12 15:29:22,939] (INFO3): Epoch: 1, train loss: 0.5180085897445679, val loss: 0.5189720988273621, val metric: 0.5914909090909091\n",
      "[2022-11-12 15:29:23,157] (INFO): Trial 2 finished with value: 0.5914909090909091 and parameters: {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204}. Best is trial 0 with value: 0.6125090909090909.\n",
      "[2022-11-12 15:29:23,162] (INFO3): \u001b[1mTrial 3\u001b[0m with hyperparameters {'bs': 1024, 'weight_decay_bin': 1, 'weight_decay': 2.9204338471814107e-05, 'lr': 0.0006672367170464204} scored 0.5914909090909091 in 0:00:00.298606\n",
      "[2022-11-12 15:29:23,167] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:23,168] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:23,168] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.510213): 100%|██████████| 6/6 [00:00<00:00, 87.37it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 433.74it/s]\n",
      "[2022-11-12 15:29:23,266] (INFO3): Epoch: 0, train loss: 0.5102128386497498, val loss: 0.5294001698493958, val metric: 0.5979878787878787\n",
      "train (loss=0.513761): 100%|██████████| 6/6 [00:00<00:00, 92.60it/s]\n",
      "val: 100%|██████████| 6/6 [00:00<00:00, 414.42it/s]\n",
      "[2022-11-12 15:29:23,354] (INFO3): Epoch: 1, train loss: 0.5137609839439392, val loss: 0.5293468832969666, val metric: 0.572630303030303\n",
      "[2022-11-12 15:29:23,551] (INFO): Trial 3 finished with value: 0.572630303030303 and parameters: {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05}. Best is trial 0 with value: 0.6125090909090909.\n",
      "[2022-11-12 15:29:23,555] (INFO3): \u001b[1mTrial 4\u001b[0m with hyperparameters {'bs': 64, 'weight_decay_bin': 0, 'lr': 1.8205657658407255e-05} scored 0.572630303030303 in 0:00:00.388161\n",
      "[2022-11-12 15:29:23,560] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:23,560] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:23,561] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.520623): 100%|██████████| 3/3 [00:00<00:00, 75.55it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 329.60it/s]\n",
      "[2022-11-12 15:29:23,624] (INFO3): Epoch: 0, train loss: 0.5206230282783508, val loss: 0.5206038951873779, val metric: 0.6063272727272728\n",
      "train (loss=0.517985): 100%|██████████| 3/3 [00:00<00:00, 82.35it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 330.11it/s]\n",
      "[2022-11-12 15:29:23,678] (INFO3): Epoch: 1, train loss: 0.5179853439331055, val loss: 0.5205668807029724, val metric: 0.5775757575757576\n",
      "[2022-11-12 15:29:23,856] (INFO): Trial 4 finished with value: 0.5775757575757576 and parameters: {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05}. Best is trial 0 with value: 0.6125090909090909.\n",
      "[2022-11-12 15:29:23,860] (INFO3): \u001b[1mTrial 5\u001b[0m with hyperparameters {'bs': 128, 'weight_decay_bin': 0, 'lr': 3.077180271250682e-05} scored 0.5775757575757576 in 0:00:00.300208\n",
      "[2022-11-12 15:29:23,861] (INFO): Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m completed\n",
      "[2022-11-12 15:29:23,861] (INFO2): The set of hyperparameters \u001b[1m{'bs': 128, 'opt_params': {'lr': 0.029154431891537533, 'weight_decay': 0}}\u001b[0m\n",
      " achieve 0.6125 auc\n",
      "[2022-11-12 15:29:23,862] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m ...\n",
      "[2022-11-12 15:29:23,863] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 2, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 128, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'lr': 0.029154431891537533, 'weight_decay': 0}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '1': {'n_epochs': 5}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:23,864] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:23,867] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:23,868] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:23,868] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.85266): 100%|██████████| 3/3 [00:00<00:00, 77.29it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 327.48it/s]\n",
      "[2022-11-12 15:29:23,931] (INFO3): Epoch: 0, train loss: 0.8526596426963806, val loss: 21.999155044555664, val metric: 0.6095030303030303\n",
      "train (loss=6.25144): 100%|██████████| 3/3 [00:00<00:00, 80.49it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 322.18it/s]\n",
      "[2022-11-12 15:29:23,986] (INFO3): Epoch: 1, train loss: 6.251444339752197, val loss: 5.725087642669678, val metric: 0.6125090909090909\n",
      "[2022-11-12 15:29:24,162] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m =====\n",
      "[2022-11-12 15:29:24,166] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:24,166] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:24,167] (DEBUG): number of continuous features: 1 \n",
      "train (loss=1.01844): 100%|██████████| 3/3 [00:00<00:00, 77.69it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 321.63it/s]\n",
      "[2022-11-12 15:29:24,230] (INFO3): Epoch: 0, train loss: 1.0184396505355835, val loss: 9.146644592285156, val metric: 0.4422060606060606\n",
      "train (loss=8.2822): 100%|██████████| 3/3 [00:00<00:00, 80.61it/s]\n",
      "val: 100%|██████████| 3/3 [00:00<00:00, 312.16it/s]\n",
      "[2022-11-12 15:29:24,285] (INFO3): Epoch: 1, train loss: 8.28220272064209, val loss: 3.699559450149536, val metric: 0.5461333333333334\n",
      "[2022-11-12 15:29:24,472] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m finished. score = \u001b[1m0.5764787878787878\u001b[0m\n",
      "[2022-11-12 15:29:24,473] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:24,474] (INFO): Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m ...\n",
      "[2022-11-12 15:29:24,475] (DEBUG): Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': True, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'dense', 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 5, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 16, 'swa': True}, 'bs': 512, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': <class 'torch.optim.adam.Adam'>, 'opt_params': {'weight_decay': 0, 'lr': 0.0003}, 'sch': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'scheduler_params': {'patience': 10, 'factor': 0.01, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': <class 'lightautoml.text.nn_model.UniversalDataset'>, 'tuned': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 512, 512], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': <class 'torch.nn.modules.activation.ReLU'>, 'use_noise': False, 'use_bn': True, '0': {'n_epochs': 2}, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 5, 'max_tuning_time': 3600}, 'default_params': {'random_state': 46}, 'device_ids': None, 'cat_features': [], 'cat_dims': [], 'cont_features': ['qntl_tr__fillnamed__fillinf__num_views'], 'cont_dim': 1, 'text_features': [], 'bias': array([-1.29928298])}\n",
      "[2022-11-12 15:29:24,475] (INFO2): ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:24,479] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:24,479] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:24,480] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 14.57it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s]\n",
      "[2022-11-12 15:29:24,595] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195084810256958, val metric: 0.6283636363636362\n",
      "train (loss=0.51836): 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s]\n",
      "[2022-11-12 15:29:24,692] (INFO3): Epoch: 1, train loss: 0.5183604955673218, val loss: 0.5194426774978638, val metric: 0.6281939393939394\n",
      "train (loss=0.517569): 100%|██████████| 1/1 [00:00<00:00, 16.28it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.31it/s]\n",
      "[2022-11-12 15:29:24,781] (INFO3): Epoch: 2, train loss: 0.5175685882568359, val loss: 0.5193743705749512, val metric: 0.6263030303030303\n",
      "train (loss=0.515923): 100%|██████████| 1/1 [00:00<00:00, 17.63it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.59it/s]\n",
      "[2022-11-12 15:29:24,866] (INFO3): Epoch: 3, train loss: 0.515923261642456, val loss: 0.5192907452583313, val metric: 0.621430303030303\n",
      "train (loss=0.514292): 100%|██████████| 1/1 [00:00<00:00, 18.13it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.42it/s]\n",
      "[2022-11-12 15:29:24,949] (INFO3): Epoch: 4, train loss: 0.5142917037010193, val loss: 0.519208550453186, val metric: 0.6077333333333333\n",
      "[2022-11-12 15:29:25,143] (INFO2): ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m =====\n",
      "[2022-11-12 15:29:25,147] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:25,147] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:25,148] (DEBUG): number of continuous features: 1 \n",
      "train (loss=0.51958): 100%|██████████| 1/1 [00:00<00:00, 17.58it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.50it/s]\n",
      "[2022-11-12 15:29:25,246] (INFO3): Epoch: 0, train loss: 0.5195798277854919, val loss: 0.5195421576499939, val metric: 0.5449939393939394\n",
      "train (loss=0.516177): 100%|██████████| 1/1 [00:00<00:00, 18.25it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 63.31it/s]\n",
      "[2022-11-12 15:29:25,328] (INFO3): Epoch: 1, train loss: 0.5161771774291992, val loss: 0.5194854736328125, val metric: 0.5449939393939394\n",
      "train (loss=0.510938): 100%|██████████| 1/1 [00:00<00:00, 18.55it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "[2022-11-12 15:29:25,409] (INFO3): Epoch: 2, train loss: 0.5109382271766663, val loss: 0.519408106803894, val metric: 0.5449939393939394\n",
      "train (loss=0.506052): 100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 62.36it/s]\n",
      "[2022-11-12 15:29:25,493] (INFO3): Epoch: 3, train loss: 0.5060521364212036, val loss: 0.5193051099777222, val metric: 0.5449939393939394\n",
      "train (loss=0.502016): 100%|██████████| 1/1 [00:00<00:00, 15.84it/s]\n",
      "val: 100%|██████████| 1/1 [00:00<00:00, 51.64it/s]\n",
      "[2022-11-12 15:29:25,590] (INFO3): Epoch: 4, train loss: 0.5020161867141724, val loss: 0.5191867351531982, val metric: 0.5449939393939394\n",
      "[2022-11-12 15:29:25,887] (INFO): Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m finished. score = \u001b[1m0.5652\u001b[0m\n",
      "[2022-11-12 15:29:25,888] (INFO): \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_dense_1\u001b[0m fitting and predicting completed\n",
      "[2022-11-12 15:29:25,889] (INFO): Time left 582.48 secs\n",
      "\n",
      "[2022-11-12 15:29:25,889] (INFO): \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:25,893] (INFO): Blending: optimization starts with equal weights and score \u001b[1m0.5582787878787878\u001b[0m\n",
      "[2022-11-12 15:29:25,914] (INFO): Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.5597333333333333\u001b[0m, weights = \u001b[1m[0.618034   0.38196602]\u001b[0m\n",
      "[2022-11-12 15:29:25,934] (INFO): Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.5597333333333333\u001b[0m, weights = \u001b[1m[0.618034   0.38196602]\u001b[0m\n",
      "[2022-11-12 15:29:25,935] (INFO): Blending: no score update. Terminated\n",
      "\n",
      "[2022-11-12 15:29:25,936] (INFO): \u001b[1mAutoml preset training completed in 3.75 seconds\u001b[0m\n",
      "\n",
      "[2022-11-12 15:29:25,937] (INFO): Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.61803 * (2 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_TorchNN_mlp_tuned_0) +\n",
      "\t 0.38197 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_dense_1) \n",
      "\n",
      "[2022-11-12 15:29:25,937] (INFO): ==================================================\n",
      "[2022-11-12 15:29:25,948] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:25,948] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:25,949] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 256.97it/s]\n",
      "[2022-11-12 15:29:26,173] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:26,174] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:26,174] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 273.00it/s]\n",
      "[2022-11-12 15:29:26,358] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:26,359] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:26,359] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 120.44it/s]\n",
      "[2022-11-12 15:29:26,562] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:26,562] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:26,563] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 122.95it/s]\n",
      "[2022-11-12 15:29:26,772] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:26,772] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:26,773] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 3/3 [00:00<00:00, 558.30it/s]\n",
      "[2022-11-12 15:29:26,951] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:26,952] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:26,952] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 3/3 [00:00<00:00, 549.95it/s]\n",
      "[2022-11-12 15:29:27,131] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:27,132] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:27,133] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.89it/s]\n",
      "[2022-11-12 15:29:27,329] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:27,330] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:27,330] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.42it/s]\n",
      "[2022-11-12 15:29:27,542] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:27,543] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:27,543] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 273.76it/s]\n",
      "[2022-11-12 15:29:27,719] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:27,720] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:27,720] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 270.74it/s]\n",
      "[2022-11-12 15:29:27,901] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:27,901] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:27,902] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 109.10it/s]\n",
      "[2022-11-12 15:29:28,101] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:28,101] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:28,102] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 124.01it/s]\n",
      "[2022-11-12 15:29:28,314] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:28,314] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:28,315] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 258.16it/s]\n",
      "[2022-11-12 15:29:28,508] (DEBUG): number of text features: 0 \n",
      "[2022-11-12 15:29:28,509] (DEBUG): number of categorical features: 0 \n",
      "[2022-11-12 15:29:28,510] (DEBUG): number of continuous features: 1 \n",
      "test: 100%|██████████| 1/1 [00:00<00:00, 270.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for id, config in configs.items():\n",
    "    if int(id) > 3:\n",
    "        continue\n",
    "    \n",
    "    print(\"\\n\\n\\n\\n############ CONFIG ############\")\n",
    "    pprint(config)\n",
    "    print(\"################################\")\n",
    "    \n",
    "    path = \"/home/user/MKuznetsov/Tabular_nn/multi_nn_merge/LightAutoML_13062022/nlp_test/LightAutoML/temp/lama_master_preset/LightAutoML/lightautoml/automl/presets/tabular_configs/\"\n",
    "    with open(path + \"conf_6_sel_type_1_tuning_full_no_int_lgbm.yml\", \"rb\") as f:\n",
    "        yml_config = yaml.full_load(f)\n",
    "    \n",
    "    for k, v in config.items():\n",
    "        if k in yml_config:\n",
    "            yml_config[k].update(v)\n",
    "        else:\n",
    "            yml_config[k] = v\n",
    "    \n",
    "    yml_config[\"nn_params\"].update({\"path_to_save\": None})\n",
    "    \n",
    "    yml_config = {**yml_config, \"nn_pipeline_params\": {}}\n",
    "    with open(path + \"example.yaml\", mode=\"wb\") as file:\n",
    "        yaml.dump(yml_config, file, encoding=\"utf-8\")\n",
    "    \n",
    "    automl = TabularUtilizedAutoML(\n",
    "        debug=True,\n",
    "        task=task,\n",
    "        timeout=600,\n",
    "        reader_params={\"cv\": 2},\n",
    "        configs_list=[path + \"example.yaml\"],\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    oof_pred = automl.fit_predict(train, roles=roles)\n",
    "    test_pred = automl.predict(test)\n",
    "    \n",
    "    os.remove(path + \"example.yaml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('misha-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "627859947abf2d56f3b996a2b10f55a84515683130af72b4b7e3159c07acb31d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
